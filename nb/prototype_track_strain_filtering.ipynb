{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from lib.pandas_util import idxwhere, aligned_index, align_indexes, invert_mapping\n",
    "import lib.thisproject.data\n",
    "import matplotlib as mpl\n",
    "import lib.plot\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from tempfile import mkstemp\n",
    "import time\n",
    "import subprocess\n",
    "from itertools import chain\n",
    "import os\n",
    "from itertools import product\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import lib.thisproject.data\n",
    "\n",
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written using ChatGPT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def logit_space(start, end, num=50, endpoint=True, base=10.0):\n",
    "    \"\"\"\n",
    "    Return numbers spaced evenly on a logit scale.\n",
    "\n",
    "    Parameters:\n",
    "        start (float): The starting value for the range (0 < start < 1).\n",
    "        end (float): The ending value for the range (0 < end < 1).\n",
    "        num (int, optional): Number of points in the output array. Default is 50.\n",
    "        endpoint (bool, optional): If True, `end` is the last value in the range. If False,\n",
    "                                   `end` is not included. Default is True.\n",
    "        base (float, optional): The base of the logit space. Default is 10.0.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of `num` equally spaced values on the logit scale.\n",
    "    \"\"\"\n",
    "    if not (0 < start < 1) or not (0 < end < 1):\n",
    "        raise ValueError(\"Start and end values must be in the (0, 1) interval.\")\n",
    "    if num <= 0:\n",
    "        raise ValueError(\"Number of points (num) must be positive.\")\n",
    "    if base <= 1.0:\n",
    "        raise ValueError(\"Base must be greater than 1.0 for logit space.\")\n",
    "\n",
    "    # Convert the start and end values to the logit scale\n",
    "    start_logit = np.log(start / (1 - start))\n",
    "    end_logit = np.log(end / (1 - end))\n",
    "\n",
    "    # Generate the logit space values\n",
    "    logit_values = np.logspace(start_logit, end_logit, num=num, endpoint=endpoint, base=base)\n",
    "\n",
    "    # Convert the logit space values back to the original scale\n",
    "    output_values = logit_values / (1 + logit_values)\n",
    "\n",
    "    return output_values\n",
    "\n",
    "# Example usage:\n",
    "start_val = 0.1\n",
    "end_val = 0.9\n",
    "num_points = 100\n",
    "\n",
    "logit_space_values = logit_space(start_val, end_val, num=num_points)\n",
    "print(logit_space_values)\n",
    "\n",
    "plt.plot(logit_space_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.dpi'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy = lib.thisproject.data.load_species_taxonomy(\"ref/gtpro/species_taxonomy_ext.tsv\")\n",
    "species_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes_meta = (\n",
    "    pd.read_table('ref/midasdb_uhgg/genomes.tsv', index_col='genome')\n",
    "    .rename_axis(index='genome_id')\n",
    "    .rename(lambda s: 'UHGG' + s[len(\"GUT_GENOME\"):])\n",
    ")\n",
    "genomes_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_meta = (\n",
    "    pd.read_table('ref/uhgg_genomes_all_4644.tsv', dtype={'species': str}, index_col='Genome')\n",
    "    .rename_axis(index='genome_id')\n",
    "    .rename(lambda s: 'UHGG' + s[len(\"GUT_GENOME\"):])\n",
    "    .join(genomes_meta)\n",
    ")\n",
    "reference_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - How many samples\n",
    "group = 'xjin_ucfmt_hmp2'  # But drop xjin_ samples\n",
    "\n",
    "sample_list = pd.read_table('meta/mgen_group.tsv')[lambda x: (x.mgen_group == group) & (~x.mgen_id.str.startswith('xjin_'))].mgen_id.to_list()\n",
    "assert len(sample_list) == len(set(sample_list))\n",
    "len(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - How many species analyzed\n",
    "species_list1 = pd.read_table('meta/species_group.tsv')[lambda x: (x.species_group_id == group)].species_id.to_list()\n",
    "assert len(species_list1) == len(set(species_list1))\n",
    "len(species_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - How many species found in xjin_ucfmt_hmp2?\n",
    "# TODO: Remind myself of what my species filters were.\n",
    "species_list2 = [str(x) for x in lib.pandas_util.read_list('data/group/xjin_ucfmt_hmp2/r.proc.gtpro.horizontal_coverage.select_species.list')]\n",
    "len(species_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - For each species:\n",
    "species_id = '102506'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - How many species-x-samples pairs at sufficient depth (1x)\n",
    "species_depth = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.species_depth.tsv', names=['sample', 'depth'], index_col=['sample']).depth.reindex(sample_list, fill_value=0)\n",
    "sample_list2 = idxwhere((species_depth > 1))\n",
    "len(sample_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - How many strains were these collapsed into (with at least 1x depth)\n",
    "strain_frac = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv', index_col=['sample', 'strain']).community.unstack('strain').loc[sample_list2].rename(columns=str)\n",
    "strain_depth = (strain_frac.T * species_depth.loc[sample_list2]).T\n",
    "strain_list = idxwhere((strain_depth > 1).any())\n",
    "len(strain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - How many of these had at least one \"pure\" sample\n",
    "strain_list2 = idxwhere((strain_frac[strain_list] > 0.95).any())\n",
    "len(strain_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - How many passed \"species gene frac\" threshold?\n",
    "strain_meta = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95_ss-all_t-30_thresh-corr100-depth250.strain_meta.tsv', index_col='strain').rename(str)\n",
    "strain_list3 = idxwhere(strain_meta.reindex(strain_list2, fill_value=0).species_gene_frac > 0.9)\n",
    "len(strain_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   - How many passed gene count filtering? (These are our final numbers)\n",
    "x = strain_meta.loc[strain_list3].num_genes\n",
    "_df, _loc, _scale = sp.stats.t.fit(x.values, fix_df=2)\n",
    "_dist0 = sp.stats.t(_df, _loc, _scale)\n",
    "_dist1 = sp.stats.norm(_loc, _scale)\n",
    "thresh_max_num_uhgg_genes = _dist1.ppf(0.999)\n",
    "thresh_min_num_uhgg_genes = _dist1.ppf(0.001)\n",
    "\n",
    "strain_list4 = idxwhere((x > thresh_min_num_uhgg_genes) & (x < thresh_max_num_uhgg_genes))\n",
    "len(strain_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_counts = {}\n",
    "strain_details = []\n",
    "\n",
    "for species_id in tqdm(species_list2):\n",
    "    #   - How many species-x-samples pairs at sufficient depth (1x)\n",
    "    species_depth = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv', names=['sample', 'depth'], index_col=['sample']).depth.reindex(sample_list, fill_value=0)\n",
    "    sample_list2 = idxwhere((species_depth > 0.05))\n",
    "    \n",
    "    #   - How many strains were these collapsed into (with at least 1x depth)\n",
    "    try:\n",
    "        strain_frac = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv', index_col=['sample', 'strain']).community.unstack('strain').reindex(sample_list2, fill_value=0)\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"SFacts output missing for {species_id}.\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    strain_list0 = idxwhere((strain_frac > 0.5).any())\n",
    "    strain_depth = (strain_frac.T * species_depth.loc[sample_list2]).T    \n",
    "    #   - How many of these had at least one \"pure\" sample\n",
    "    strain_list1 = idxwhere((strain_frac[strain_list0] > 0.95).any())\n",
    "    \n",
    "    try:\n",
    "        strain_meta = pd.read_table(f'data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95_ss-all_t-30_thresh-corr100-depth250.strain_meta.tsv', index_col='strain').loc[strain_list1]\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"SPGC output missing for {species_id}.\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    #   - How many of these had a total depth of >1x?\n",
    "    strain_list2 = idxwhere(strain_meta.sum_depth > 1)  # \n",
    "\n",
    "    #   - How many passed \"species gene frac\" threshold?\n",
    "    strain_list3 = idxwhere(strain_meta.reindex(strain_list2, fill_value=0).species_gene_frac > 0.9)\n",
    "    \n",
    "    #   - How many passed gene count filtering? (These are our final numbers)\n",
    "    x0 = strain_meta.loc[strain_list3].num_genes  # Use only high quality strains to create distribution.\n",
    "    x1 = strain_meta.num_genes  # Assess all strains.\n",
    "    if len(x0) < 1:\n",
    "        strain_list4 = []\n",
    "    else:\n",
    "        _df, _loc, _scale = sp.stats.t.fit(x0.values, fix_df=2)\n",
    "        _dist0 = sp.stats.t(_df, _loc, _scale)\n",
    "        _dist1 = sp.stats.norm(_loc, _scale)\n",
    "        thresh_max_num_uhgg_genes = _dist1.ppf(0.999)\n",
    "        thresh_min_num_uhgg_genes = _dist1.ppf(0.001)\n",
    "        strain_list4 = idxwhere((x1 > thresh_min_num_uhgg_genes) & (x1 < thresh_max_num_uhgg_genes))\n",
    "\n",
    "    species_strain_counts[species_id] = pd.Series(dict(\n",
    "        num_species_samples=len(sample_list2),  # Species depth >1x\n",
    "        num_inferred_strains=len(strain_list0),  # \"Inferred\" means >50% in at least one sample.\n",
    "        num_strains_with_pure_sample=len(strain_list1),  # At least one \"pure\" sample\n",
    "        num_strains_with_sufficient_depth=len(strain_list2),  # >1x depth across all samples  # NOTE: This includes xjin samples.\n",
    "        num_complete_spgc=len(strain_list3),  # Species gene frac >90%\n",
    "        num_passing_spgc=len(set(strain_list3) & set(strain_list4)),  # Not a gene count outlier.\n",
    "    ))\n",
    "    strain_details.append(\n",
    "        pd.DataFrame(index=strain_list0)\n",
    "        .join(strain_meta)\n",
    "        .assign(\n",
    "            species=species_id,\n",
    "            strain=lambda x: x.index,\n",
    "            has_inference=lambda x: x.index.isin(strain_list0),\n",
    "            has_pure_sample=lambda x: x.index.isin(strain_list1),\n",
    "            has_sufficient_depth=lambda x: x.index.isin(strain_list2),\n",
    "            has_species_genes=lambda x: x.index.isin(strain_list3),\n",
    "            has_reasonable_gene_count=lambda x: x.index.isin(strain_list4),\n",
    "            has_species_genes_and_reasonable_gene_count=lambda x: x.has_species_genes & x.has_reasonable_gene_count,\n",
    "        )\n",
    "    )\n",
    "species_strain_counts = pd.DataFrame(species_strain_counts).T\n",
    "strain_details = pd.concat(strain_details).set_index(['species', 'strain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_details[['has_inference', 'has_pure_sample', 'has_sufficient_depth', 'has_species_genes', 'has_reasonable_gene_count', 'has_species_genes_and_reasonable_gene_count']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_counts.groupby(species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)).sum().sort_values('num_passing_spgc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy[lambda x: x.c__ == 'c__Coriobacteriia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_counts.groupby(species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)).sum()#.sort_values('num_passing_spgc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_strain_counts\n",
    "    .groupby(\n",
    "        # species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)\n",
    "        species_taxonomy.apply(lambda x: x.p__, axis=1)\n",
    "    )\n",
    "    .sum()\n",
    "    .sort_values('num_passing_spgc', ascending=False)\n",
    "    .T\n",
    ")\n",
    "_palette = lib.plot.construct_ordered_palette(d.columns, cm='rainbow')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 6))\n",
    "for taxon in d.columns:\n",
    "    ax.plot(d[taxon], c=_palette[taxon], label=taxon, lw=3, alpha=0.8)\n",
    "# d.plot(kind='line')\n",
    "ax.set_yscale('symlog', linthresh=1)\n",
    "ax.set_ylim(1)\n",
    "lib.plot.rotate_xticklabels()\n",
    "ax.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_strain_counts\n",
    "    .groupby(\n",
    "        # species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)\n",
    "        species_taxonomy.apply(lambda x: x.p__, axis=1)\n",
    "    )\n",
    "    .sum()\n",
    "    .sort_values('num_passing_spgc', ascending=False)\n",
    "    .assign(phylum=lambda x: x.index.to_series().str[len('p__'):])\n",
    "    .set_index('phylum')\n",
    "    .drop(columns=['num_species_samples'])\n",
    ")\n",
    "_palette = lib.plot.construct_ordered_palette(d.columns, cm='Spectral')\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "for level in d.columns:\n",
    "    plt.bar(d.index, d[level], color=_palette[level])\n",
    "\n",
    "    \n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "# plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.ylim(0.1)\n",
    "plt.yticks(np.logspace(0, 5, num=6), minor=False)\n",
    "plt.yticks([], minor=True)\n",
    "lib.plot.rotate_xticklabels(rotation=25)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_rename_levels = dict(\n",
    "    num_species_samples='Species-Sample Pairs',  # Species depth >1x\n",
    "    num_inferred_strains='Strains Inferred',  # \"Inferred\" means >50% in at least one sample.\n",
    "    num_strains_with_pure_sample='+ Pure Samples (>95%)',  # At least one \"pure\" sample\n",
    "    num_strains_with_sufficient_depth='+ Sufficient Depth (>1x)',  # >1x depth across all samples  # NOTE: This includes xjin samples.\n",
    "    num_complete_spgc='+ High \"Completeness\" (>90%)',  # Species gene frac >90%\n",
    "    num_passing_spgc='+ Appropriate Gene Count',  # Not a gene count outlier.\n",
    ")\n",
    "for level in d.columns:\n",
    "    ax.bar(d.index, 0, color=_palette[level], label=_rename_levels[level])\n",
    "ax.legend()\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# for level, height in zip(_palette, reversed(np.linspace(0, 1, num=len(_palette) + 1))):\n",
    "#     ax.bar(0, height, color=_palette[level])\n",
    "#     ax.annotate(level, xy=(0, height), ha='center', va='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_strain_counts\n",
    "    .groupby(\n",
    "        species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)\n",
    "        # species_taxonomy.apply(lambda x: x.p__, axis=1)\n",
    "    )\n",
    "    .sum()\n",
    "    .sort_values('num_passing_spgc', ascending=False)\n",
    ")\n",
    "_palette = lib.plot.construct_ordered_palette(d.columns, cm='Spectral')\n",
    "\n",
    "for level in d.columns:\n",
    "    plt.bar(d.index, d[level], color=_palette[level], label=level)\n",
    "\n",
    "# for level in reversed(d.columns):\n",
    "#     plt.bar(d.index, 0, color=_palette[level], label=level)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.ylim(0.1)\n",
    "plt.yticks(np.logspace(0, 5, num=6), minor=False)\n",
    "plt.yticks([], minor=True)\n",
    "lib.plot.rotate_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values('num_passing_spgc', ascending=False).head(20).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _species_list = ['100022', '102506', '102492']\n",
    "# taxon_list = species_taxonomy.loc[_species_list].taxonomy_string\n",
    "\n",
    "d = (\n",
    "    species_strain_counts.groupby(\n",
    "        # species_taxonomy.apply(lambda x: x.p__ + ';' + x.c__, axis=1)\n",
    "        species_taxonomy.taxonomy_string\n",
    "    )\n",
    "    .sum()\n",
    "    .sort_values(\"num_passing_spgc\", ascending=False)\n",
    ")\n",
    "taxon_list = d.sort_values(\"num_species_samples\", ascending=False).head(40).index\n",
    "_palette = lib.plot.construct_ordered_palette(d.columns, cm=\"rainbow\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "for level in d.columns:\n",
    "    plt.bar(taxon_list, d.loc[taxon_list, level], color=_palette[level], label=level)\n",
    "\n",
    "# for level in reversed(d.columns):\n",
    "#     plt.bar(d.index, 0, color=_palette[level], label=level)\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.yscale(\"symlog\", linthresh=1, linscale=0.1)\n",
    "plt.ylim(0.1)\n",
    "plt.yticks(np.logspace(0, 5, num=6), minor=False)\n",
    "plt.yticks([], minor=True)\n",
    "lib.plot.rotate_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy[species_taxonomy.s__.str.contains('fragilis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_strain_counts\n",
    "    .join(\n",
    "        reference_meta.groupby('species').Genome_type.value_counts().unstack(fill_value=0).rename(str)\n",
    "    )\n",
    "    .join(species_taxonomy)\n",
    ")\n",
    "\n",
    "d.sort_values('num_species_samples', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_strain_counts\n",
    "    .join(\n",
    "        reference_meta.groupby('species').Genome_type.value_counts().unstack(fill_value=0).rename(str)\n",
    "    )\n",
    "    .join(species_taxonomy)\n",
    "    .sort_values('num_passing_spgc')\n",
    "    # .set_index('taxonomy_string')\n",
    "    [['num_passing_spgc', 'Isolate', 'MAG']]\n",
    ")\n",
    "\n",
    "taxon_list = d.sort_values('num_passing_spgc', ascending=False).head(40).index\n",
    "# _palette = lib.plot.construct_ordered_palette(d.columns, cm='rainbow')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "d.loc[taxon_list].plot.bar(ax=ax)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins = np.logspace(-2, 4, num=50)\n",
    "ybins = np.linspace(0, 1, num=50)\n",
    "\n",
    "plt.hist2d(\n",
    "    'sum_depth',\n",
    "    'species_gene_frac',\n",
    "    data=strain_details,\n",
    "    bins=(xbins, ybins),\n",
    "    norm=mpl.colors.PowerNorm(1/2),\n",
    "    cmap='magma_r',\n",
    "    cmin=1,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Total Core Genome Depth')\n",
    "plt.ylabel('Species Gene Fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.scatter(\n",
    "    \"max_depth\",\n",
    "    \"sum_depth\",\n",
    "    data=strain_details.assign(\n",
    "        one_minus_species_gene_frac=lambda x: 1 - x.species_gene_frac\n",
    "    ),\n",
    "    s=1,\n",
    "    c=\"one_minus_species_gene_frac\",\n",
    "    norm=mpl.colors.SymLogNorm(0.1),\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "d = strain_details[['max_depth', 'sum_depth', 'has_reasonable_gene_count']].dropna()\n",
    "\n",
    "# scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.scatter('max_depth', 'sum_depth', data=d, s=1, c='has_reasonable_gene_count')\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.scatter(\n",
    "    \"sum_depth\",\n",
    "    \"num_sample\",\n",
    "    data=strain_details.assign(\n",
    "        one_minus_species_gene_frac=lambda x: 1 - x.species_gene_frac\n",
    "    ),\n",
    "    s=1,\n",
    "    c=\"one_minus_species_gene_frac\",\n",
    "    norm=mpl.colors.SymLogNorm(0.1),\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_inpath=\"meta/hmp2/mgen.tsv\"\n",
    "preparation_inpath=\"meta/hmp2/preparation.tsv\"\n",
    "stool_inpath=\"meta/hmp2/stool.tsv\"\n",
    "subject_inpath=\"meta/hmp2/subject.tsv\"\n",
    "\n",
    "mgen = pd.read_table(mgen_inpath, index_col='library_id')\n",
    "preparation = pd.read_table(preparation_inpath, index_col='preparation_id')\n",
    "stool = pd.read_table(stool_inpath, index_col='stool_id')\n",
    "subject = pd.read_table(subject_inpath, index_col='subject_id')\n",
    "\n",
    "mgen_meta = mgen.join(preparation, on='preparation_id', lsuffix='_mgen', rsuffix='_preparation').join(stool, on='stool_id').join(subject, on='subject_id')\n",
    "mgen_meta.subject_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frac_from_hmp2 = []\n",
    "\n",
    "# for species_id in tqdm(species_list2):\n",
    "for species_id in tqdm(species_list2):\n",
    "    #   - How many species-x-samples pairs at sufficient depth (1x)\n",
    "    species_depth = pd.read_table(\n",
    "        f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    "        names=[\"sample\", \"depth\"],\n",
    "        index_col=[\"sample\"],\n",
    "    ).depth.reindex(sample_list, fill_value=0)\n",
    "\n",
    "    #   - How many strains were these collapsed into (with at least 1x depth)\n",
    "    try:\n",
    "        strain_frac = pd.read_table(\n",
    "            f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv\",\n",
    "            index_col=[\"sample\", \"strain\"],\n",
    "        ).community.unstack(\"strain\")\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"SFacts output missing for {species_id}.\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        _frac, _meta = align_indexes(strain_frac, mgen_meta)\n",
    "    except AssertionError:\n",
    "        print(set(strain_frac.index) & set(mgen_meta.index))\n",
    "        print(f\"No HMP2 samples found in strain table for {species_id}.\")\n",
    "        continue\n",
    "\n",
    "    all_frac_from_hmp2.append(_frac.rename(columns=lambda x: f\"{species_id}_{x}\"))\n",
    "\n",
    "all_frac_from_hmp2 = pd.concat(all_frac_from_hmp2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_found, _meta = align_indexes(all_frac_from_hmp2.fillna(0) > 0.25, mgen_meta)\n",
    "\n",
    "different_subject = sp.spatial.distance.pdist(\n",
    "    _meta[['subject_id']],\n",
    "    metric=lambda x, y: x != y,\n",
    ").astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_all_species = sp.spatial.distance.pdist(strain_found, metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, num=100)\n",
    "plt.hist(jaccard_all_species[different_subject], density=True, bins=bins)\n",
    "plt.hist(jaccard_all_species[~different_subject], density=True, bins=bins)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a distance, so squareform will be wrong along the diagonal\n",
    "shared_strains_cdmat = sp.spatial.distance.pdist(strain_found, metric=lambda x, y: (x & y).sum())\n",
    "shared_strains_dmat = pd.DataFrame(sp.spatial.distance.squareform(shared_strains_cdmat) + np.diag(strain_found.sum(1)), index=all_frac_from_hmp2.index, columns=all_frac_from_hmp2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = shared_strains_dmat\n",
    "sns.clustermap(d, norm=mpl.colors.PowerNorm(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 200)\n",
    "\n",
    "x = pd.Series(different_subject)\n",
    "y = pd.Series(shared_strains_cdmat)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.15)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.hist(y[x], alpha=0.7, bins=bins, density=True, label='Different Subject')\n",
    "    ax.hist(y[~x], alpha=0.7, bins=bins, density=True, label='Same Subject')\n",
    "\n",
    "ax1.set_ylim(bottom=0.2, top=0.23)\n",
    "ax2.set_ylim(bottom=0, top=0.03)\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "ax2.set_xlabel('Shared Strains')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Shared Strains (count)')\n",
    "plt.ylabel('Density')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 1, (x).sum()), y[x].sort_values().values)\n",
    "plt.plot(np.linspace(0, 1, (~x).sum()), y[~x].sort_values().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(shared_strains_cdmat)\n",
    "x = pd.Series(different_subject)\n",
    "\n",
    "y[~x].quantile([0.05, 0.25, 0.5, 0.75, 0.95]), y[x].quantile([0.05, 0.25, 0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most strains are found in only one subject.\n",
    "bins = np.arange(1, 40)\n",
    "plt.hist((all_frac_from_hmp2 > 0.5).groupby(mgen_meta.subject_id).any().sum(), bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "\n",
    "# How many strains are found at >thresh% in any sample?\n",
    "observed_strain_list = idxwhere((all_frac_from_hmp2 > thresh).any())\n",
    "print(len(observed_strain_list))\n",
    "# How many of these are found above this thresh in more than one sample:\n",
    "multi_sample_observed_strain_list = idxwhere((all_frac_from_hmp2 > thresh).sum() > 1)\n",
    "print(len(multi_sample_observed_strain_list))\n",
    "# How many of these are found above this thresh in more than one subject?\n",
    "multi_subject_observed_strain_list = idxwhere((all_frac_from_hmp2 > thresh).groupby(mgen_meta.subject_id).any().sum() > 1)\n",
    "print(len(multi_subject_observed_strain_list))\n",
    "# What is the distribution of number of subjects in multi-sample strains?\n",
    "\n",
    "x = (all_frac_from_hmp2[multi_sample_observed_strain_list] > thresh).groupby(mgen_meta.subject_id).any().sum()\n",
    "\n",
    "plt.hist(x, bins=np.linspace(0, 40, num=41), density=True)\n",
    "# plt.yscale('log')\n",
    "x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_specificity = {}\n",
    "\n",
    "# for species_id in tqdm(species_list2):\n",
    "for species_id in tqdm(species_list2):\n",
    "    #   - How many species-x-samples pairs at sufficient depth (1x)\n",
    "    species_depth = pd.read_table(\n",
    "        f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gene99-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    "        names=[\"sample\", \"depth\"],\n",
    "        index_col=[\"sample\"],\n",
    "    ).depth.reindex(sample_list, fill_value=0)\n",
    "\n",
    "    #   - How many strains were these collapsed into (with at least 1x depth)\n",
    "    try:\n",
    "        strain_frac = pd.read_table(\n",
    "            f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv\",\n",
    "            index_col=[\"sample\", \"strain\"],\n",
    "        ).community.unstack(\"strain\")\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"SFacts output missing for {species_id}.\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        _frac, _meta = align_indexes(strain_frac, mgen_meta)\n",
    "    except AssertionError:\n",
    "        print(set(strain_frac.index) & set(mgen_meta.index))\n",
    "        print(f\"No HMP2 samples found in strain table for {species_id}.\")\n",
    "        continue\n",
    "\n",
    "    num_subjects = len(_meta.subject_id.unique())\n",
    "\n",
    "    share_no_strains = sp.spatial.distance.pdist(\n",
    "        (_frac > 0.05), metric=lambda x, y: (x * y).sum() == 0\n",
    "    )\n",
    "    different_subject = sp.spatial.distance.pdist(\n",
    "        _meta[['subject_id']],\n",
    "        metric=lambda x, y: x != y,\n",
    "    )\n",
    "    contingency = (\n",
    "        pd.DataFrame(\n",
    "            dict(\n",
    "                subject=pd.Series(different_subject).astype(bool).map({True: 'different', False: 'same'}),\n",
    "                share_strains=pd.Series(share_no_strains).astype(bool).map({True: 'none_shared', False: 'shared'}),\n",
    "            )\n",
    "        )\n",
    "        .value_counts()\n",
    "        .reindex(\n",
    "            [('same', 'shared'), ('same', 'none_shared'), ('different', 'shared'), ('different', 'none_shared')], fill_value=0\n",
    "        )\n",
    "    )\n",
    "    contingency_pc = contingency.unstack() + 1\n",
    "    odds_ratio_pc = (\n",
    "        contingency_pc.loc['same', 'shared'] / contingency_pc.loc['same', 'none_shared']\n",
    "    ) / (contingency_pc.loc['different', 'shared'] / contingency_pc.loc['different', 'none_shared'])\n",
    "    species_strain_specificity[species_id] = pd.concat(\n",
    "        [\n",
    "            contingency,\n",
    "            pd.Series(dict(odds_ratio_pc=odds_ratio_pc, num_samples=_frac.shape[0], num_subjects=num_subjects)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "species_strain_specificity = pd.DataFrame(species_strain_specificity).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('num_samples', 'log_odds_ratio_pc', data=species_strain_specificity.assign(log_odds_ratio_pc=lambda x: np.log2(x.odds_ratio_pc)))\n",
    "plt.xscale('log')\n",
    "plt.axhline(0, lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_specificity.sort_values('num_samples', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_specificity.sort_values('odds_ratio_pc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_depth_from_hmp2 = []\n",
    "\n",
    "# for species_id in tqdm(species_list2):\n",
    "for species_id in tqdm(species_list2):\n",
    "    #   - How many species-x-samples pairs at sufficient depth (1x)\n",
    "    species_depth = pd.read_table(\n",
    "        f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gene99-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    "        names=[\"sample\", \"depth\"],\n",
    "        index_col=[\"sample\"],\n",
    "    ).depth.reindex(sample_list, fill_value=0)\n",
    "\n",
    "    #   - How many strains were these collapsed into (with at least 1x depth)\n",
    "    try:\n",
    "        strain_frac = pd.read_table(\n",
    "            f\"data/group/xjin_ucfmt_hmp2/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv\",\n",
    "            index_col=[\"sample\", \"strain\"],\n",
    "        ).community.unstack(\"strain\")\n",
    "    except FileNotFoundError as err:\n",
    "        print(f\"SFacts output missing for {species_id}.\")\n",
    "        print(err)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        _frac, _meta, _species_depth = align_indexes(strain_frac, mgen_meta, species_depth)\n",
    "    except AssertionError:\n",
    "        print(set(strain_frac.index) & set(mgen_meta.index))\n",
    "        print(f\"No HMP2 samples found in strain table for {species_id}.\")\n",
    "        continue\n",
    "\n",
    "    _depth = _frac.multiply(_species_depth, axis=0)\n",
    "\n",
    "    all_depth_from_hmp2.append(_depth.rename(columns=lambda x: f\"{species_id}_{x}\"))\n",
    "\n",
    "all_depth_from_hmp2 = pd.concat(all_depth_from_hmp2, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = lib.pandas_util.align_indexes(all_species_depth.sum(1), all_depth_from_hmp2.sum(1))\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strain_frac = all_depth_from_hmp2.divide(all_depth_from_hmp2.sum(1), axis=0)\n",
    "\n",
    "# Not a distance, so squareform will be wrong along the diagonal\n",
    "shared_strains_bc_cdmat = sp.spatial.distance.pdist(all_strain_frac, metric='braycurtis')\n",
    "shared_strains_bc_dmat = pd.DataFrame(sp.spatial.distance.squareform(shared_strains_bc_cdmat), index=all_strain_frac.index, columns=all_strain_frac.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(shared_strains_bc_dmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_meta = mgen_meta.loc[all_strain_frac.index]\n",
    "_diff_subject = sp.spatial.distance.pdist(\n",
    "    _meta[['subject_id']],\n",
    "    metric=lambda x, y: x != y,\n",
    ").astype(bool)\n",
    "\n",
    "assert _meta.subject_id.value_counts().map(lambda x: x * (x - 1) / 2).sum() == (~_diff_subject).sum()\n",
    "\n",
    "bins = np.linspace(0, 1, num=11)\n",
    "plt.hist(shared_strains_bc_cdmat[_diff_subject], density=True, bins=bins, alpha=0.6)\n",
    "plt.hist(shared_strains_bc_cdmat[~_diff_subject], density=True, bins=bins, alpha=0.6)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "(\n",
    "    np.quantile(shared_strains_bc_cdmat[_diff_subject], q),\n",
    "    np.quantile(shared_strains_bc_cdmat[~_diff_subject], q),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_strains_jacc_cdmat = sp.spatial.distance.pdist(all_strain_frac > 0.001, metric='jaccard')\n",
    "shared_strains_jacc_dmat = pd.DataFrame(sp.spatial.distance.squareform(shared_strains_bc_cdmat), index=all_strain_frac.index, columns=all_strain_frac.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_drop_samples = idxwhere(all_depth_from_hmp2.sum(1) < 50)\n",
    "\n",
    "filt_all_strain_frac, _meta = align_indexes(all_depth_from_hmp2.divide(all_depth_from_hmp2.sum(1), axis=0).drop(_drop_samples), mgen_meta)\n",
    "\n",
    "# Not a distance, so squareform will be wrong along the diagonal\n",
    "filt_shared_strains_cdmat = sp.spatial.distance.pdist(filt_all_strain_frac > 0.0001, metric=lambda x, y: (x & y).sum())\n",
    "filt_shared_strains_dmat = pd.DataFrame(sp.spatial.distance.squareform(filt_shared_strains_cdmat) + np.diag((filt_all_strain_frac > 0.001).sum(1)), index=filt_all_strain_frac.index, columns=filt_all_strain_frac.index)\n",
    "different_subject_cdmat = sp.spatial.distance.pdist(\n",
    "    _meta[['subject_id']],\n",
    "    metric=lambda x, y: x != y,\n",
    ").astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 80, num=80)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.15)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.hist(filt_shared_strains_cdmat[different_subject_cdmat], density=True, alpha=0.6, bins=bins, label='Different Subject')\n",
    "    ax.hist(filt_shared_strains_cdmat[~different_subject_cdmat], density=True, alpha=0.6, bins=bins, label='Same Subject')\n",
    "\n",
    "ax1.set_ylim(bottom=0.8, top=0.94)\n",
    "ax2.set_ylim(bottom=0, top=0.1)\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "ax2.set_xlabel('Shared Strains')\n",
    "ax1.legend()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_specificity.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = species_strain_specificity.assign(\n",
    "    frac_same_subject_with_shared_strains=lambda x: x[('same', 'shared')] / (x[('same', 'shared')] + x[('same', 'none_shared')]),\n",
    "    frac_diff_subject_with_shared_strains=lambda x: x[('different', 'shared')] / (x[('different', 'shared')] + x[('different', 'none_shared')]),\n",
    "    num_subjects_x_10=lambda x: x.num_subjects * 10,\n",
    ")\n",
    "\n",
    "d1 = d0.dropna(subset=[\"frac_same_subject_with_shared_strains\", \"frac_diff_subject_with_shared_strains\"])[lambda x: x.num_subjects > 2].sort_values('num_subjects', ascending=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "cbar_artist = ax.scatter('frac_same_subject_with_shared_strains', 'frac_diff_subject_with_shared_strains', c='num_samples', s='num_subjects_x_10', data=d1, alpha=0.4, label='__nolegend__')\n",
    "for n in [2, 4, 8, 16, 32]:\n",
    "    ax.scatter([], [], s=n * 10, c='k', alpha=0.4, label=n)\n",
    "ax.legend(title='Distinct Subjects')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.025, 0.67])\n",
    "cbar = fig.colorbar(cbar_artist, cax=cbar_ax)#, label=\"count strains\")\n",
    "cbar.solids.set_alpha(1.0)\n",
    "\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.set_aspect(1.0)\n",
    "ax.set_xticks([0, 0.5, 1.0])\n",
    "ax.set_yticks([0, 0.5, 1.0])\n",
    "\n",
    "ax.set_xlabel('Same Subject Strain Sharing')\n",
    "ax.set_ylabel('Different Subject Strain Sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz2",
   "language": "python",
   "name": "toolz2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
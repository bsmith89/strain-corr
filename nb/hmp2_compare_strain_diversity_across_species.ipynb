{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.path.realpath(os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from lib.pandas_util import idxwhere\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import sfacts as sf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.plot import construct_ordered_palette\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import lib.plot\n",
    "import scipy.stats\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'hmp2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = pd.read_table('meta/hmp2/mgen.tsv', index_col='library_id')\n",
    "prep = pd.read_table('meta/hmp2/preparation.tsv', index_col='preparation_id')\n",
    "stool = pd.read_table('meta/hmp2/stool.tsv', index_col='stool_id')\n",
    "subject = pd.read_table('meta/hmp2/subject.tsv', index_col='subject_id')\n",
    "\n",
    "meta = mgen.join(prep, on='preparation_id', rsuffix='_').join(stool, on='stool_id').join(subject, on='subject_id')\n",
    "assert meta.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy = pd.read_table('ref/gtpro/species_taxonomy_ext.tsv', names=['genome_id', 'species_id', 'taxonomy_string']).assign(species_id=lambda x: x.species_id.astype(str)).set_index('species_id')[['taxonomy_string']].assign(taxonomy_split=lambda x: x.taxonomy_string.str.split(';'))\n",
    "\n",
    "for level_name, level_number in [('p__', 1), ('c__', 2), ('o__', 3), ('f__', 4), ('g__', 5), ('s__', 6)]:\n",
    "    species_taxonomy = species_taxonomy.assign(**{level_name: species_taxonomy.taxonomy_split.apply(lambda x: x[level_number])}) \n",
    "species_taxonomy = species_taxonomy.drop(columns=['taxonomy_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_species_sample = {}\n",
    "num_species_position = {}\n",
    "species_list = []\n",
    "\n",
    "for path in glob(f'data/sp-*.{group}.a.r.proc.gtpro.filt-poly05-cvrg10.mgen.pdist.nc'):\n",
    "    species_id = path[len('data/sp-'):-len(f'.{group}.a.r.proc.gtpro.filt-poly05-cvrg10.mgen.pdist.nc')]\n",
    "    sizes = xr.open_dataset(f'data/sp-{species_id}.{group}.a.r.proc.gtpro.filt-poly05-cvrg10.mgen.nc').sizes\n",
    "    num_species_sample[species_id] = sizes['sample']\n",
    "    num_species_position[species_id] = sizes['position']\n",
    "    if (num_species_sample[species_id] > 100) and (num_species_position[species_id] > 100):\n",
    "        species_list.append(species_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(species_list), sorted(species_list)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_strain_label = {}\n",
    "species_strain_counts = {}\n",
    "\n",
    "phyla = species_taxonomy.loc[species_list].p__.unique()\n",
    "palette = construct_ordered_palette(phyla, cm='tab20')\n",
    "\n",
    "for species_id in tqdm(species_list):\n",
    "    pdmat = xr.load_dataarray(f'data/sp-{species_id}.{group}.a.r.proc.gtpro.filt-poly05-cvrg10.mgen.pdist.nc')\n",
    "    agg = pd.Series(AgglomerativeClustering(n_clusters=None, distance_threshold=0.02, affinity='precomputed', linkage='complete').fit(pdmat).labels_, index=pdmat.sampleA)\n",
    "    species_strain_label[species_id] = agg.astype(str)\n",
    "    species_strain_counts[species_id] = agg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_data = pd.DataFrame(\n",
    "    {s: (species_strain_counts[s].sum(), len(species_strain_counts[s])) for s in species_strain_counts},\n",
    "    index=['num_samples', 'num_strains']\n",
    ").T.assign(samples_per_strain=lambda x: x.num_samples / x.num_strains).join(species_taxonomy).sort_values('taxonomy_string')\n",
    "\n",
    "taxa = species_data.p__.unique()\n",
    "palette = construct_ordered_palette(taxa, cm='tab20')\n",
    "\n",
    "plt.scatter('num_samples', 'num_strains', data=species_data, c=species_data.p__.map(palette), label='__none__')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "for tax in species_data.p__.unique():\n",
    "    plt.scatter([], [], label=tax, color=palette[tax])\n",
    "plt.plot([0, 1e4], [0, 1e4], lw=1, linestyle='--', color='grey', zorder=0)\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rarifaction(value_counts):\n",
    "    x = pd.Series(\n",
    "        np.random.choice(\n",
    "            value_counts.index,\n",
    "            size=value_counts.sum(),\n",
    "            replace=True,\n",
    "            p=value_counts / value_counts.sum()\n",
    "        )\n",
    "    )\n",
    "    return (~pd.Series.duplicated(x)).cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for species_id in species_list:\n",
    "    ax.plot(rarifaction(species_strain_counts[species_id]), color=palette[species_taxonomy.loc[species_id].p__])\n",
    "\n",
    "for p__ in phyla:\n",
    "    ax.scatter([], [], label=p__, color=palette[p__])\n",
    "    \n",
    "ax.plot([0, 1e3], [0, 1e3], lw=1, linestyle='--', color='k')\n",
    "ax.set_aspect(1)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.plot.boxplot_with_points(x='p__', y='samples_per_strain', palette=palette, data=species_data[species_data.num_samples > 200])\n",
    "lib.plot.rotate_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "d = pd.DataFrame(species_strain_label).astype(float)\n",
    "d = d.loc[d.notna().sum(1) > 10, d.notna().sum() > 100]\n",
    "\n",
    "m = meta.loc[d.index]\n",
    "\n",
    "num_strains = d.notna().sum(1)\n",
    "\n",
    "def frac_shared_strains(x, y):\n",
    "    \"Fraction of all x strains shared by y where both have an assignment.\"\n",
    "    return (x == y).sum() / sum(~np.isnan(x) & ~np.isnan(y))\n",
    "\n",
    "def num_shared_strains(x, y):\n",
    "    \"Number of all x strains.\"\n",
    "    return (x == y).sum()\n",
    "\n",
    "# Values are in compressed_distance_matrix form with indexes species_strain_label.index\n",
    "shared_strains_num = pdist(d, metric=num_shared_strains)\n",
    "shared_strains_frac = pdist(d, metric=frac_shared_strains)\n",
    "\n",
    "diff_subject_mask = pdist(m[['subject_id']], metric=lambda x, y: x != y).astype(bool)\n",
    "diff_stool_mask = pdist(m[['stool_id']], metric=lambda x, y: x != y).astype(bool)\n",
    "diff_site_mask = pdist(m[['site']], metric=lambda x, y: x != y).astype(bool)\n",
    "diff_diagnosis_mask = pdist(m[['ibd_diagnosis']], metric=lambda x, y: x != y).astype(bool)\n",
    "diff_has_ibd_mask = pdist(m[['ibd_diagnosis']] == 'nonIBD', metric=lambda x, y: x != y).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 15))\n",
    "for (var_title, diff_masking, same_masking), ax_row in zip(\n",
    "    [\n",
    "        ('subj', diff_subject_mask, ~diff_subject_mask),\n",
    "        ('site', diff_site_mask & diff_subject_mask, ~diff_site_mask & diff_subject_mask),\n",
    "        ('stool', diff_stool_mask & ~diff_subject_mask, ~diff_stool_mask & ~diff_subject_mask),\n",
    "        ('diseased', diff_has_ibd_mask & diff_subject_mask, ~diff_has_ibd_mask & diff_subject_mask),\n",
    "        ('form', diff_diagnosis_mask & diff_subject_mask, ~diff_diagnosis_mask & diff_subject_mask),\n",
    "    ],\n",
    "    axs\n",
    "):\n",
    "    for (val_title, shared_strains, bins), ax in zip(\n",
    "        [\n",
    "            ('num', shared_strains_num, np.arange(50)),\n",
    "            ('frac', shared_strains_frac, np.linspace(0, 1, num=21))\n",
    "        ],\n",
    "        ax_row\n",
    "    ):\n",
    "        same_vals = shared_strains[same_masking]\n",
    "        diff_vals = shared_strains[diff_masking]\n",
    "        ax.hist(same_vals, bins=bins, density=True, alpha=0.5, label=f'same {var_title}')\n",
    "        ax.hist(diff_vals, bins=bins, density=True, alpha=0.5, label=f'diff {var_title}')\n",
    "        ax.legend()\n",
    "        ax.set_title((var_title, val_title))\n",
    "        ax.set_yscale('log')\n",
    "        mwu_pvalue = sp.stats.mannwhitneyu(same_vals, diff_vals, alternative='greater', nan_policy='omit').pvalue\n",
    "        ax.annotate(f'{mwu_pvalue:0.2e}', xy=(0.5, 0.5), xycoords='axes fraction')\n",
    "        print(var_title, val_title, np.round(np.mean(same_vals[~np.isnan(same_vals)]), 3), np.round(np.mean(diff_vals[~np.isnan(diff_vals)]), 3), mwu_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analysis_sample_list = d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_depth = pd.read_table('data/hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.fit-sfacts9-s75-g10000-seed0.collapse-10.strain_depth.tsv', index_col=['sample', 'strain']).squeeze().unstack(fill_value=0)\n",
    "strain_depth = strain_depth.loc[cluster_analysis_sample_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1e-1\n",
    "\n",
    "sfacts_jacc = pdist((strain_depth > thresh), metric='jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfacts_num = pdist((strain_depth > thresh), metric=lambda x, y: (x & y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 4, figsize=(15, 15))\n",
    "for (var_title, diff_masking, same_masking), ax_row in zip(\n",
    "    [\n",
    "        ('subj', diff_subject_mask, ~diff_subject_mask),\n",
    "        ('site', diff_site_mask & diff_subject_mask, ~diff_site_mask & diff_subject_mask),\n",
    "        ('stool', diff_stool_mask & ~diff_subject_mask, ~diff_stool_mask & ~diff_subject_mask),\n",
    "        ('diseased', diff_has_ibd_mask & diff_subject_mask, ~diff_has_ibd_mask & diff_subject_mask),\n",
    "        ('form', diff_diagnosis_mask & diff_subject_mask, ~diff_diagnosis_mask & diff_subject_mask),\n",
    "    ],\n",
    "    axs\n",
    "):\n",
    "    for (val_title, shared_strains, bins), ax in zip(\n",
    "        [\n",
    "            ('num', shared_strains_num, np.arange(50)),\n",
    "            ('frac', shared_strains_frac, np.linspace(0, 1, num=21)),\n",
    "            ('sf_jacc', 1 - sfacts_jacc, np.linspace(0, 1, num=21)),\n",
    "            ('sf_num', sfacts_num, np.arange(50)),\n",
    "        ],\n",
    "        ax_row\n",
    "    ):\n",
    "        same_vals = shared_strains[same_masking]\n",
    "        diff_vals = shared_strains[diff_masking]\n",
    "        ax.hist(same_vals, bins=bins, density=True, alpha=0.5, label=f'same {var_title}')\n",
    "        ax.hist(diff_vals, bins=bins, density=True, alpha=0.5, label=f'diff {var_title}')\n",
    "        ax.legend()\n",
    "        ax.set_title((var_title, val_title))\n",
    "        ax.set_yscale('log')\n",
    "        mwu_pvalue = sp.stats.mannwhitneyu(same_vals, diff_vals, alternative='greater', nan_policy='omit').pvalue\n",
    "        ax.annotate(f'{mwu_pvalue:0.2e}', xy=(0.5, 0.5), xycoords='axes fraction')\n",
    "        print(var_title, val_title, np.round(np.mean(same_vals[~np.isnan(same_vals)]), 3), np.round(np.mean(diff_vals[~np.isnan(diff_vals)]), 3), mwu_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfacts",
   "language": "python",
   "name": "sfacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir(_os.environ[\"PROJECT_ROOT\"])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import chain, product\n",
    "from tempfile import mkstemp\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sfacts as sf\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.plot\n",
    "import lib.thisproject.data\n",
    "from lib.pandas_util import align_indexes, aligned_index, idxwhere, invert_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkage_order(linkage, labels):\n",
    "    return labels[sp.cluster.hierarchy.to_tree(linkage).pre_order(lambda x: x.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_2tailed_pvalue_from_perm(obs, perms):\n",
    "    hypoth_left = perms > obs\n",
    "    hypoth_right = perms < obs\n",
    "    null_p_left = (hypoth_left.sum() + 1) / (len(hypoth_left) + 1)\n",
    "    null_p_right = (hypoth_right.sum() + 1) / (len(hypoth_right) + 1)\n",
    "    return np.minimum(null_p_left, null_p_right) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_barplot(data, x_var, order, palette=None, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.subplot()\n",
    "    if palette is None:\n",
    "        palette = lib.plot.construct_ordered_palette(order)\n",
    "\n",
    "    # Bar styles\n",
    "    bar_kwargs = dict(\n",
    "        width=1.0,\n",
    "        alpha=1.0,\n",
    "        edgecolor=\"k\",\n",
    "        lw=1,\n",
    "    )\n",
    "    bar_kwargs.update(kwargs)\n",
    "\n",
    "    # Plot each bar segment\n",
    "    _last_top = 0\n",
    "    for y_var in order:\n",
    "        ax.bar(\n",
    "            x=data[x_var],\n",
    "            height=data[y_var],\n",
    "            bottom=_last_top,\n",
    "            label=y_var,\n",
    "            color=palette[y_var],\n",
    "            **bar_kwargs,\n",
    "        )\n",
    "        _last_top += data[y_var]\n",
    "    ax.set_xticks(data[x_var].values)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def rename_timepoints_for_ts(old_tp_label):\n",
    "    if isinstance(old_tp_label, float):\n",
    "        if np.isnan(old_tp_label):\n",
    "            return \"\"\n",
    "        else:\n",
    "            assert False, \"No idea what's going on here.\"\n",
    "    if old_tp_label == \"E0\":\n",
    "        return \"pE\"\n",
    "    elif old_tp_label.startswith(\"E\"):\n",
    "        return old_tp_label.replace(\"E0\", \"EE\")\n",
    "    elif old_tp_label.startswith(\"Po0\"):\n",
    "        return old_tp_label.replace(\"Po0\", \"PE\")\n",
    "    elif old_tp_label.startswith(\"Po\"):\n",
    "        return old_tp_label.replace(\"Po\", \"PE\")\n",
    "\n",
    "\n",
    "plot_stacked_barplot(\n",
    "    pd.DataFrame(dict(t=[0, 1, 2], y1=[0.0, 0.5, 1.0], y2=[1.0, 0.5, 0.0])),\n",
    "    x_var=\"t\",\n",
    "    order=[\"y1\", \"y2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_type_palette = {\n",
    "    \"EEN:PostEEN\": \"tab:green\",\n",
    "    \"EEN\": \"tab:blue\",\n",
    "    \"PostEEN\": \"tab:orange\",\n",
    "}\n",
    "\n",
    "diet_palette = {\n",
    "    \"EEN\": \"lightgreen\",\n",
    "    \"PostEEN\": \"lightblue\",\n",
    "    \"InVitro\": \"plum\",\n",
    "    \"PreEEN\": \"lightpink\",\n",
    "}\n",
    "\n",
    "subject_order = [\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"H\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "]\n",
    "\n",
    "# NOTE: Requires a dummy value because I want exactly 20 items.\n",
    "subject_palette = lib.plot.construct_ordered_palette(\n",
    "    subject_order + [f\"dummy{i}\" for i in range(20 - len(subject_order))], cm=\"tab20\"\n",
    ")\n",
    "subject_palette[\"X\"] = \"black\"\n",
    "pair_type_order = [\"EEN\", \"EEN:PostEEN\", \"PostEEN\"]\n",
    "pair_type_marker_palette = {\"EEN\": \"s\", \"EEN:PostEEN\": \">\", \"PostEEN\": \"o\"}\n",
    "pair_type_linestyle_palette = {\"EEN\": \":\", \"EEN:PostEEN\": \"-.\", \"PostEEN\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all species with pangenome profiles\n",
    "\n",
    "species_list = pd.read_table(\"meta/species_group.tsv\", dtype=str)[\n",
    "    lambda x: x.species_group_id == \"een\"\n",
    "].species_id\n",
    "assert species_list.is_unique\n",
    "species_list = list(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (\n",
    "    pd.read_table(\"meta/een-mgen/sample.tsv\")\n",
    "    .assign(\n",
    "        label=lambda x: x[\n",
    "            [\"collection_date_relative_een_end\", \"diet_or_media\", \"sample_id\"]\n",
    "        ].apply(tuple, axis=1)\n",
    "    )\n",
    "    .set_index(\"sample_id\")\n",
    ")\n",
    "subject = pd.read_table(\"meta/een-mgen/subject.tsv\", index_col=\"subject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxonomy embedded in the counts table file.\n",
    "rotu_counts0 = pd.read_table(\n",
    "    \"data/group/een/a.proc.zotu_counts.tsv\", index_col=\"#OTU ID\"\n",
    ").rename_axis(index=\"zotu\", columns=\"sample_id\")\n",
    "\n",
    "rotu_taxonomy0 = rotu_counts0.taxonomy\n",
    "rotu_taxonomy = rotu_taxonomy0.str.split(\";\").apply(\n",
    "    lambda x: pd.Series(x, index=[\"d__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\", \"s__\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_taxonomy_inpath = \"ref/uhgg_genomes_all_v2.tsv\"\n",
    "\n",
    "_motu_taxonomy = (\n",
    "    pd.read_table(motu_taxonomy_inpath)[lambda x: x.Genome == x.Species_rep]\n",
    "    .assign(species_id=lambda x: \"1\" + x.MGnify_accession.str.split(\"-\").str[2])\n",
    "    .set_index(\"species_id\")\n",
    ")\n",
    "\n",
    "motu_lineage_string = _motu_taxonomy.Lineage\n",
    "\n",
    "\n",
    "def _parse_taxonomy_string(taxonomy_string):\n",
    "    values = taxonomy_string.split(\";\")\n",
    "    return pd.Series(values, index=[\"d__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\", \"s__\"])\n",
    "\n",
    "\n",
    "motu_taxonomy = _motu_taxonomy.Lineage.apply(\n",
    "    _parse_taxonomy_string\n",
    ")  # .assign(taxonomy_string=motu_lineage_string)\n",
    "motu_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_meta = pd.read_table(\n",
    "    \"ref/cog-20.meta.tsv\",\n",
    "    encoding=\"latin10\",\n",
    "    names=[\"cog\", \"categories\", \"description\", \"gene_name\", \"pathway\", \"_5\", \"color\"],\n",
    "    index_col=\"cog\",\n",
    ")\n",
    "cog_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_category_meta = pd.read_table(\n",
    "    \"ref/cog-20.categories.tsv\",\n",
    "    names=[\"category\", \"color\", \"description\"],\n",
    "    index_col=\"category\",\n",
    ")\n",
    "cog_category_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubiquitous, single-copy genes to be used for estimating total genome depth:\n",
    "\n",
    "schg_cog_list = [\n",
    "    \"COG0012\",\n",
    "    \"COG0016\",\n",
    "    \"COG0048\",\n",
    "    \"COG0049\",\n",
    "    \"COG0052\",\n",
    "    \"COG0080\",\n",
    "    \"COG0081\",\n",
    "    \"COG0085\",\n",
    "    \"COG0087\",\n",
    "    \"COG0088\",\n",
    "    \"COG0090\",\n",
    "    \"COG0091\",\n",
    "    \"COG0092\",\n",
    "    \"COG0093\",\n",
    "    \"COG0094\",\n",
    "    \"COG0096\",\n",
    "    \"COG0097\",\n",
    "    \"COG0098\",\n",
    "    \"COG0099\",\n",
    "    \"COG0100\",\n",
    "    \"COG0102\",\n",
    "    \"COG0103\",\n",
    "    \"COG0124\",\n",
    "    \"COG0184\",\n",
    "    \"COG0185\",\n",
    "    \"COG0186\",\n",
    "    \"COG0197\",\n",
    "    \"COG0200\",\n",
    "    \"COG0201\",\n",
    "    \"COG0256\",\n",
    "    \"COG0495\",\n",
    "    \"COG0522\",\n",
    "    \"COG0525\",\n",
    "    \"COG0533\",\n",
    "    \"COG0542\",  # This one is a depth outlier...\n",
    "]\n",
    "\n",
    "cog_meta.loc[schg_cog_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zOTUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotu_counts = pd.read_table(\n",
    "    \"data/group/een/a.proc.zotu_counts.tsv\", index_col=\"#OTU ID\"\n",
    ").rename_axis(index=\"zotu\", columns=\"sample_id\")\n",
    "rotu_counts = rotu_counts.drop(columns=[\"taxonomy\"]).T\n",
    "rotu_rabund = rotu_counts.divide(rotu_counts.sum(1), axis=0)\n",
    "\n",
    "sample_rotu_bc_cdmat = sp.spatial.distance.pdist(rotu_rabund, \"braycurtis\")\n",
    "sample_rotu_bc_pdist = pd.DataFrame(\n",
    "    squareform(sample_rotu_bc_cdmat), index=rotu_rabund.index, columns=rotu_rabund.index\n",
    ")\n",
    "sample_rotu_bc_linkage = sp.cluster.hierarchy.linkage(\n",
    "    sample_rotu_bc_cdmat, method=\"average\", optimal_ordering=True\n",
    ")\n",
    "\n",
    "rotu_rabund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_depth = (\n",
    "    pd.read_table(\n",
    "        \"data/group/een/r.proc.gene99_v20-v23-agg75.spgc_specgene-ref-filt-p95.all_species_depth.tsv\",\n",
    "        index_col=[\"sample\", \"species_id\"],\n",
    "    )\n",
    "    .depth.unstack(fill_value=0)\n",
    "    .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .rename({\"CF_15\": \"CF_11\", \"CF_11\": \"CF_15\"})\n",
    ")\n",
    "motu_rabund = motu_depth.divide(motu_depth.sum(1), axis=0)\n",
    "\n",
    "sample_motu_bc_cdmat = sp.spatial.distance.pdist(motu_rabund, \"braycurtis\")\n",
    "sample_motu_bc_pdist = pd.DataFrame(\n",
    "    squareform(sample_motu_bc_cdmat), index=motu_rabund.index, columns=motu_rabund.index\n",
    ")\n",
    "sample_motu_bc_linkage = sp.cluster.hierarchy.linkage(\n",
    "    sample_motu_bc_cdmat, method=\"average\", optimal_ordering=True\n",
    ")\n",
    "\n",
    "motu_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_rabund_thresh = 1e-4\n",
    "motu_prevalence_by_subject = (\n",
    "    motu_rabund.gt(motu_rabund_thresh)\n",
    "    .groupby(sample[lambda x: x.sample_type == \"human\"].subject_id)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_depth = []\n",
    "missing_files = []\n",
    "for species_id in motu_depth.columns:\n",
    "    path = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv\"\n",
    "    try:\n",
    "        d = (\n",
    "            pd.read_table(path, index_col=[\"sample\", \"strain\"])\n",
    "            .squeeze()\n",
    "            .unstack()\n",
    "            .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "            .rename({\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})  # Sample swap.\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        missing_files.append(path)\n",
    "        d = pd.DataFrame([])\n",
    "    _keep_strains = idxwhere(d.sum() > 0.05)\n",
    "    assert d.index.isin(motu_depth.index).all()\n",
    "    d = d.reindex(index=motu_depth.index, columns=_keep_strains, fill_value=0)\n",
    "    d = d.assign(__other=lambda x: 1 - x.sum(1)).rename(columns={\"__other\": -1})\n",
    "    d[d < 0] = 0\n",
    "    d = d.divide(d.sum(1), axis=0)\n",
    "    d = d.multiply(motu_depth[species_id], axis=0)\n",
    "    d = d.rename(columns=lambda s: f\"{species_id}_{s}\")\n",
    "    sotu_depth.append(d)\n",
    "sotu_depth = pd.concat(sotu_depth, axis=1)\n",
    "sotu_rabund = sotu_depth.divide(sotu_depth.sum(1), axis=0)\n",
    "\n",
    "sample_sotu_bc_cdmat = sp.spatial.distance.pdist(sotu_rabund, metric=\"braycurtis\")\n",
    "sample_sotu_bc_pdist = pd.DataFrame(\n",
    "    squareform(sample_sotu_bc_cdmat), index=sotu_rabund.index, columns=sotu_rabund.index\n",
    ")\n",
    "sample_sotu_bc_linkage = sp.cluster.hierarchy.linkage(\n",
    "    sample_sotu_bc_pdist, method=\"average\", optimal_ordering=True\n",
    ")\n",
    "\n",
    "sns.clustermap(\n",
    "    sample_sotu_bc_pdist,\n",
    "    col_linkage=sample_sotu_bc_linkage,\n",
    "    row_linkage=sample_sotu_bc_linkage,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table of gene depths for each species and aggregate by COG.\n",
    "# Can take up to 8 minutes to compile everything\n",
    "cog_depth = {}\n",
    "\n",
    "for species in tqdm(species_list):\n",
    "    gene_x_cog_inpath = (\n",
    "        f\"data/species/sp-{species}/midasdb_v20.emapper.gene75_x_cog.tsv\"\n",
    "    )\n",
    "    gene_depth_inpath = (\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gene99_v20-v23-agg75.depth2.nc\"\n",
    "    )\n",
    "    _gene_x_cog = (\n",
    "        pd.read_table(gene_x_cog_inpath)\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"centroid_75\")\n",
    "        .squeeze()\n",
    "    )\n",
    "\n",
    "    # Calculate the depth of each COG by summing all genes labeled as that COG.\n",
    "    _cog_depth = (\n",
    "        xr.load_dataarray(gene_depth_inpath)\n",
    "        .to_pandas()\n",
    "        .T.join(_gene_x_cog)\n",
    "        .groupby(\"cog\")\n",
    "        .sum()\n",
    "    )\n",
    "    cog_depth[species] = _cog_depth.stack()\n",
    "\n",
    "cog_depth = (\n",
    "    pd.DataFrame(cog_depth)\n",
    "    .stack()\n",
    "    .rename_axis([\"cog\", \"sample\", \"species\"])\n",
    "    .to_xarray()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Normalize sample names and swap the mislabeled samples.\n",
    "cog_depth[\"sample\"] = (\n",
    "    cog_depth.sample.to_series()\n",
    "    .map(lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .replace({\"CF_15\": \"CF_11\", \"CF_11\": \"CF_15\"})\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_test(d):\n",
    "    try:\n",
    "        res = sp.stats.wilcoxon(d[\"PostEEN\"], d[\"EEN\"])\n",
    "    except ValueError:\n",
    "        res = (np.nan, np.nan)\n",
    "    log2_ratio = np.log2(d[\"PostEEN\"] / d[\"EEN\"])\n",
    "    return pd.Series(\n",
    "        [log2_ratio.mean(), d[\"EEN\"].mean(), d[\"PostEEN\"].mean(), res[1]],\n",
    "        index=[\"log2_ratio\", \"mean_EEN\", \"mean_PostEEN\", \"pvalue\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_enrichment_results = (\n",
    "    motu_rabund.apply(lambda x: x + x.replace({0: np.inf}).min())\n",
    "    .join(sample[[\"subject_id\", \"diet_or_media\"]])\n",
    "    .groupby([\"subject_id\", \"diet_or_media\"])\n",
    "    .mean()\n",
    "    .stack()\n",
    "    .unstack(\"diet_or_media\")[[\"EEN\", \"PostEEN\"]]\n",
    "    .dropna()\n",
    "    # .assign(log2_ratio=lambda x: np.log2(x[\"EEN\"] / x[\"PostEEN\"]))\n",
    "    .rename_axis(index=[\"subject_id\", \"motu_id\"])\n",
    "    .groupby(level=\"motu_id\")\n",
    "    .apply(enrichment_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_enrichment_results_with_fdr = (\n",
    "    motu_enrichment_results.dropna(subset=[\"pvalue\"])[\n",
    "        lambda x: (x.mean_EEN > 1e-3) | (x.mean_PostEEN > 1e-3)\n",
    "    ]\n",
    "    .assign(\n",
    "        fdr=lambda x: fdrcorrection(x.pvalue)[1],\n",
    "        hit=lambda x: (True & (x.fdr < 0.1)),\n",
    "    )\n",
    "    .sort_values(\"fdr\")\n",
    ")\n",
    "motu_enrichment_results_with_fdr.sort_values(\"pvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\"log2_ratio\", \"pvalue\", c=\"hit\", data=motu_enrichment_results_with_fdr, s=5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_inverted(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_enrichment_results_with_fdr.loc[\"101493\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_mean_rabund = (\n",
    "    motu_enrichment_results.mean_EEN + motu_enrichment_results.mean_PostEEN\n",
    ") / 2\n",
    "plt.hist(motu_mean_rabund)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Limit Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_detection_limit = cog_depth.where(lambda x: x != 0, np.inf).min(\n",
    "    (\"sample\", \"species\")\n",
    ")\n",
    "undetected_cogs_list = idxwhere((cog_detection_limit == np.inf).to_series())\n",
    "\n",
    "cog_depth_or_detection_limit = cog_depth.where(\n",
    "    lambda x: x != 0, cog_detection_limit\n",
    ").drop_sel(cog=undetected_cogs_list)\n",
    "\n",
    "cog_depth_or_detection_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize COG depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_genome_depth = (\n",
    "    cog_depth_or_detection_limit.sel(cog=schg_cog_list)\n",
    "    .median(\"cog\")\n",
    "    .sum(\"species\")  # NOTE: Mean or Median? Does it matter?\n",
    ")\n",
    "normalized_cog_depth_by_sample = (\n",
    "    cog_depth_or_detection_limit.sum(\"species\") / total_genome_depth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cog_depth_by_subject_and_type = (\n",
    "    normalized_cog_depth_by_sample.to_pandas()\n",
    "    .T.join(sample[[\"subject_id\", \"diet_or_media\"]])[\n",
    "        lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "    ]\n",
    "    .groupby([\"subject_id\", \"diet_or_media\"])\n",
    "    .median()  # NOTE: Mean or Median?\n",
    "    .unstack(\"diet_or_media\")\n",
    "    .dropna()\n",
    "    .stack(\"diet_or_media\")\n",
    ")\n",
    "normalized_cog_depth_by_subject_and_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cog_test_results = {}\n",
    "for cog in tqdm(normalized_cog_depth_by_subject_and_type.columns):\n",
    "    d = normalized_cog_depth_by_subject_and_type[cog].unstack()\n",
    "    mean_een = d.EEN.mean()\n",
    "    mean_post = d.PostEEN.mean()\n",
    "    mean_log2_ratio = np.log2(d.PostEEN / d.EEN).mean()\n",
    "    median_log2_ratio = np.log2(d.PostEEN / d.EEN).median()\n",
    "    try:\n",
    "        result = sp.stats.wilcoxon(\n",
    "            d.PostEEN,\n",
    "            d.EEN,\n",
    "        )\n",
    "        pval = result.pvalue\n",
    "    except ValueError:\n",
    "        pval = np.nan\n",
    "    pairwise_cog_test_results[cog] = (\n",
    "        mean_een,\n",
    "        mean_post,\n",
    "        mean_log2_ratio,\n",
    "        median_log2_ratio,\n",
    "        pval,\n",
    "    )\n",
    "\n",
    "pairwise_cog_test_results = pd.DataFrame(\n",
    "    pairwise_cog_test_results,\n",
    "    index=(\"mean_een\", \"mean_post\", \"mean_log2_ratio\", \"median_log2_ratio\", \"pval\"),\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where I define filters on COGs:\n",
    "#    ~~They must have a mean depth during one of the two time-periods of > 0.01~~\n",
    "\n",
    "pairwise_cog_test_results_filt_with_fdr = (\n",
    "    pairwise_cog_test_results.dropna(subset=[\"pval\"])[\n",
    "        lambda x: (x.mean_een > 0.01) | (x.mean_post > 0.01)\n",
    "    ]\n",
    "    .assign(\n",
    "        fdr=lambda x: fdrcorrection(x.pval)[1],\n",
    "        hit=lambda x: (\n",
    "            True\n",
    "            & (x.fdr < 0.1)\n",
    "            # & (np.abs(x.mean_log2_ratio) > 0.2)\n",
    "        ),\n",
    "    )\n",
    "    .sort_values(\"fdr\")\n",
    ")\n",
    "pairwise_cog_test_results_filt_with_fdr.sort_values(\"pval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cog_test_results_filt_with_fdr[\n",
    "    lambda x: (x.median_log2_ratio < 0) & x.hit\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cog_test_results_filt_with_fdr[\n",
    "    lambda x: (x.median_log2_ratio > 0) & x.hit\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pairwise_cog_test_results_filt_with_fdr.sort_values(\"pval\").join(cog_meta)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 4))\n",
    "ax.scatter(\n",
    "    \"mean_log2_ratio\",\n",
    "    \"pval\",\n",
    "    data=d[d.hit & (d.mean_log2_ratio < 0)],\n",
    "    color=\"tab:blue\",\n",
    "    s=10,\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.scatter(\n",
    "    \"mean_log2_ratio\",\n",
    "    \"pval\",\n",
    "    data=d[d.hit & (d.mean_log2_ratio > 0)],\n",
    "    color=\"tab:orange\",\n",
    "    s=10,\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.scatter(\"mean_log2_ratio\", \"pval\", data=d[~d.hit], color=\"grey\", s=5)\n",
    "ax.invert_yaxis()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.axvline(0.0, color=\"black\", lw=1, linestyle=\"--\")\n",
    "# ax.axvline(-0.2, color=\"black\", lw=1, linestyle=\"--\")\n",
    "# ax.axhline(0.05, color=\"black\", lw=1, linestyle=\"--\")\n",
    "ax.set_xlabel(\"Mean Log2(Fold-change)\")\n",
    "ax.set_ylabel(\"P-value\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"fig/een_gene_abundance_test.tall.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cog_test_results_filt_with_fdr.loc[\n",
    "    [\"COG3845\", \"COG4603\", \"COG4813\", \"COG3867\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_classifier(sample_typeA, sample_typeB):\n",
    "    return \":\".join(sorted(set([sample_typeA, sample_typeB])))\n",
    "\n",
    "\n",
    "def construct_turnover_analysis_data(\n",
    "    dmat,\n",
    "    meta,\n",
    "    sample_type_var,\n",
    "    stratum_var=None,\n",
    "    time_var=None,\n",
    "):\n",
    "    var_list = []\n",
    "    for var in [sample_type_var, stratum_var, time_var]:\n",
    "        if var is not None:\n",
    "            var_list.append(var)\n",
    "    meta = meta.reindex(dmat.index)[var_list].dropna()\n",
    "    dmat = dmat.loc[meta.index, meta.index]\n",
    "    data = []\n",
    "    for (i, idxA), (j, idxB) in product(enumerate(meta.index), repeat=2):\n",
    "        pair_data = {\n",
    "            \"sampleA\": idxA,\n",
    "            \"sampleB\": idxB,\n",
    "            \"sample_typeA\": meta.loc[idxA, sample_type_var],\n",
    "            \"sample_typeB\": meta.loc[idxB, sample_type_var],\n",
    "            \"diss\": dmat.loc[idxA, idxB],\n",
    "        }\n",
    "        if stratum_var is not None:\n",
    "            pair_data.update(\n",
    "                {\n",
    "                    \"stratumA\": meta.loc[idxA, stratum_var],\n",
    "                    \"stratumB\": meta.loc[idxB, stratum_var],\n",
    "                }\n",
    "            )\n",
    "        if time_var is not None:\n",
    "            pair_data.update(\n",
    "                {\"timeA\": meta.loc[idxA, time_var], \"timeB\": meta.loc[idxB, time_var]}\n",
    "            )\n",
    "        data.append(pair_data)\n",
    "    data = pd.DataFrame(\n",
    "        data,\n",
    "    )\n",
    "    data = data.assign(\n",
    "        pair_type=lambda x: x.apply(\n",
    "            lambda y: pair_classifier(y.sample_typeA, y.sample_typeB), axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if time_var:\n",
    "        data = data.assign(time_delta=lambda x: np.abs(x.timeB - x.timeA))\n",
    "\n",
    "    data = data[lambda x: (x.stratumA == x.stratumB) & (x.sampleA < x.sampleB)]\n",
    "    if stratum_var:\n",
    "        data = data.assign(stratum=lambda x: x.stratumA)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Species (zOTUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "coef_name_list = [\"pair_type[EEN]\", \"pair_type[PostEEN]\", \"pair_type[EEN:PostEEN]\"]\n",
    "n_perm = 999\n",
    "\n",
    "turnover_data = construct_turnover_analysis_data(\n",
    "    sample_rotu_bc_pdist,\n",
    "    meta=sample[lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])],\n",
    "    sample_type_var=\"diet_or_media\",\n",
    "    stratum_var=\"subject_id\",\n",
    "    time_var=\"collection_date_relative_een_end\",\n",
    ")\n",
    "\n",
    "obs_fit = smf.ols(formula, data=turnover_data).fit()\n",
    "obs_fit.summary()\n",
    "\n",
    "global_rotu_obs_coefs = obs_fit.params.reindex(coef_name_list)\n",
    "global_rotu_obs_coefs[\"num_pairs\"] = obs_fit.nobs\n",
    "global_rotu_obs_coefs[\"num_subjects_with_pairs\"] = turnover_data.stratum.unique().shape[\n",
    "    0\n",
    "]\n",
    "_transition_pairs = turnover_data[lambda x: x.pair_type == \"EEN:PostEEN\"]\n",
    "global_rotu_obs_coefs[\"num_transition_pairs\"] = _transition_pairs.shape[0]\n",
    "global_rotu_obs_coefs[\n",
    "    \"num_subjects_with_transition_pairs\"\n",
    "] = _transition_pairs.stratum.unique().shape[0]\n",
    "\n",
    "np.random.seed(0)\n",
    "_null_coef_dists = []\n",
    "for _ in tqdm(range(n_perm)):\n",
    "    perm_fit = smf.ols(\n",
    "        formula,\n",
    "        data=turnover_data.assign(\n",
    "            pair_type=lambda x: x.groupby(\"stratum\").pair_type.sample(frac=1).values\n",
    "        ),\n",
    "    ).fit()\n",
    "    _null_coef_dists.append(perm_fit.params.reindex(coef_name_list))\n",
    "\n",
    "global_rotu_null_coefs = pd.DataFrame(_null_coef_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = turnover_data\n",
    "fit = obs_fit\n",
    "\n",
    "\n",
    "# pair_type_palette = {'Transition': 'tab:green', 'EEN': 'tab:blue', 'PostEEN': 'tab:orange'}\n",
    "# pair_type_marker_palette = {'EEN': 's', 'Transition': '>', 'PostEEN': 'o'}\n",
    "# pair_type_linestyle_palette = {'EEN': ':', 'Transition': '--', 'PostEEN': '-'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "# ax.set_title(\"Within-subject Pairwise Turnover\")\n",
    "for pair_type in [\"EEN\", \"PostEEN\", \"EEN:PostEEN\"]:\n",
    "    d3 = d1[lambda x: (x.pair_type == pair_type)]\n",
    "    ax.scatter(\n",
    "        \"time_delta\",\n",
    "        \"diss\",\n",
    "        label=\"__nolegend__\",\n",
    "        data=d3,\n",
    "        color=pair_type_palette[pair_type],\n",
    "        marker=pair_type_marker_palette[pair_type],\n",
    "        edgecolor=\"white\",\n",
    "        lw=0.5,\n",
    "        alpha=0.75,\n",
    "        s=40,\n",
    "    )\n",
    "\n",
    "_arbitrary_subject = d1.stratum.unique()[1]\n",
    "predict_data = pd.DataFrame(\n",
    "    product(\n",
    "        [_arbitrary_subject],\n",
    "        [\"EEN\", \"PostEEN\", \"EEN:PostEEN\"],\n",
    "        np.logspace(1.0, 2.6),\n",
    "    ),\n",
    "    columns=[\"stratum\", \"pair_type\", \"time_delta\"],\n",
    ")\n",
    "predict_data = predict_data.assign(\n",
    "    prediction=fit.predict(predict_data),\n",
    "    predict_mean_subject=lambda x: x.prediction\n",
    "    - fit.params[f\"C(stratum, Sum)[S.{_arbitrary_subject}]\"],\n",
    ")\n",
    "for pair_type in pair_type_order:\n",
    "    d4 = predict_data[lambda x: x.pair_type == pair_type]\n",
    "    left, right = d1[lambda x: x.pair_type == pair_type].time_delta.quantile(\n",
    "        [0.05, 0.95]\n",
    "    )\n",
    "    ax.plot(\n",
    "        \"time_delta\",\n",
    "        \"predict_mean_subject\",\n",
    "        label=\"__nolegend__\",\n",
    "        data=d4[lambda x: (x.time_delta > left) & (x.time_delta < right)],\n",
    "        color=\"black\",\n",
    "        linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        lw=2,\n",
    "    )\n",
    "ax.set_ylabel(\"Turnover\")\n",
    "ax.set_xlabel(\"Days between Samples\")\n",
    "ax.set_xscale(\"symlog\", linthresh=1e-1)\n",
    "\n",
    "fig.savefig(\"fig/een_turnover_analysis_zotu_level.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 1.5))\n",
    "for pair_type in pair_type_order:\n",
    "    ax.scatter(\n",
    "        [],\n",
    "        [],\n",
    "        label=pair_type,\n",
    "        color=pair_type_palette[pair_type],\n",
    "        marker=pair_type_marker_palette[pair_type],\n",
    "        edgecolor=\"grey\",\n",
    "        lw=0.5,\n",
    "        s=50,\n",
    "    )\n",
    "for pair_type in pair_type_order:\n",
    "    ax.plot(\n",
    "        [],\n",
    "        [],\n",
    "        label=pair_type,\n",
    "        color=\"k\",\n",
    "        linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        lw=2,\n",
    "    )\n",
    "ax.legend(ncols=2, handlelength=3, markerscale=1.1)\n",
    "lib.plot.hide_axes_and_spines(ax=ax)\n",
    "\n",
    "fig.savefig(\"fig/een_turnover_analysis_legend.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_obs = global_rotu_obs_coefs\n",
    "_null = global_rotu_null_coefs\n",
    "\n",
    "for coef, color in zip(coef_name_list, [\"tab:blue\", \"tab:orange\", \"tab:green\"]):\n",
    "    sns.kdeplot(_null[coef], color=color)\n",
    "    plt.axvline(_obs[coef], color=color, label=coef)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = dict(\n",
    "    transition_vs_een=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[EEN]\"],\n",
    "    transition_vs_pos=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    een_vs_post=lambda x: x[\"pair_type[EEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    transition_vs_mean=lambda x: x[\"pair_type[EEN:PostEEN]\"]\n",
    "    - 0.5 * (x[\"pair_type[EEN]\"] + x[\"pair_type[PostEEN]\"]),\n",
    ")\n",
    "\n",
    "_obs = global_rotu_obs_coefs\n",
    "_null = global_rotu_null_coefs\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, sharex=True)\n",
    "for comp, ax in zip(comparisons, axs):\n",
    "    x, y = _null.apply(comparisons[comp], axis=1), comparisons[comp](_obs)\n",
    "    ax.set_title(comp)\n",
    "    ax.hist(x)\n",
    "    ax.axvline(y)\n",
    "    print(calculate_2tailed_pvalue_from_perm(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_2tailed_pvalue_from_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test for the difference between the transition and each of the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Species (Metagenomics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "coef_name_list = [\"pair_type[EEN]\", \"pair_type[PostEEN]\", \"pair_type[EEN:PostEEN]\"]\n",
    "n_perm = 999\n",
    "\n",
    "turnover_data = construct_turnover_analysis_data(\n",
    "    sample_motu_bc_pdist,\n",
    "    meta=sample[lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])],\n",
    "    sample_type_var=\"diet_or_media\",\n",
    "    stratum_var=\"subject_id\",\n",
    "    time_var=\"collection_date_relative_een_end\",\n",
    ")\n",
    "\n",
    "obs_fit = smf.ols(formula, data=turnover_data).fit()\n",
    "obs_fit.summary()\n",
    "\n",
    "global_motu_obs_coefs = obs_fit.params.reindex(coef_name_list)\n",
    "global_motu_obs_coefs[\"num_pairs\"] = obs_fit.nobs\n",
    "global_motu_obs_coefs[\"num_subjects_with_pairs\"] = turnover_data.stratum.unique().shape[\n",
    "    0\n",
    "]\n",
    "_transition_pairs = turnover_data[lambda x: x.pair_type == \"EEN:PostEEN\"]\n",
    "global_motu_obs_coefs[\"num_transition_pairs\"] = _transition_pairs.shape[0]\n",
    "global_motu_obs_coefs[\n",
    "    \"num_subjects_with_transition_pairs\"\n",
    "] = _transition_pairs.stratum.unique().shape[0]\n",
    "\n",
    "np.random.seed(0)\n",
    "_null_coef_dists = []\n",
    "for _ in tqdm(range(n_perm)):\n",
    "    perm_fit = smf.ols(\n",
    "        formula,\n",
    "        data=turnover_data.assign(\n",
    "            pair_type=lambda x: x.groupby(\"stratum\").pair_type.sample(frac=1).values\n",
    "        ),\n",
    "    ).fit()\n",
    "    _null_coef_dists.append(perm_fit.params.reindex(coef_name_list))\n",
    "\n",
    "global_motu_null_coefs = pd.DataFrame(_null_coef_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_obs = global_motu_obs_coefs\n",
    "_null = global_motu_null_coefs\n",
    "\n",
    "for coef, color in zip(coef_name_list, [\"tab:blue\", \"tab:orange\", \"tab:green\"]):\n",
    "    sns.kdeplot(_null[coef], color=color)\n",
    "    plt.axvline(_obs[coef], color=color, label=coef)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = dict(\n",
    "    transition_vs_een=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[EEN]\"],\n",
    "    transition_vs_pos=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    een_vs_post=lambda x: x[\"pair_type[EEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    transition_vs_mean=lambda x: x[\"pair_type[EEN:PostEEN]\"]\n",
    "    - 0.5 * (x[\"pair_type[EEN]\"] + x[\"pair_type[PostEEN]\"]),\n",
    ")\n",
    "\n",
    "_obs = global_motu_obs_coefs\n",
    "_null = global_motu_null_coefs\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, sharex=True)\n",
    "for comp, ax in zip(comparisons, axs):\n",
    "    x, y = _null.apply(comparisons[comp], axis=1), comparisons[comp](_obs)\n",
    "    ax.set_title(comp)\n",
    "    ax.hist(x)\n",
    "    ax.axvline(y)\n",
    "    print(calculate_2tailed_pvalue_from_perm(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test for the difference between the transition and each of the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "coef_name_list = [\"pair_type[EEN]\", \"pair_type[PostEEN]\", \"pair_type[EEN:PostEEN]\"]\n",
    "n_perm = 999\n",
    "\n",
    "turnover_data = construct_turnover_analysis_data(\n",
    "    sample_sotu_bc_pdist,\n",
    "    meta=sample[lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])],\n",
    "    sample_type_var=\"diet_or_media\",\n",
    "    stratum_var=\"subject_id\",\n",
    "    time_var=\"collection_date_relative_een_end\",\n",
    ")\n",
    "\n",
    "obs_fit = smf.ols(formula, data=turnover_data).fit()\n",
    "obs_fit.summary()\n",
    "\n",
    "global_sotu_obs_coefs = obs_fit.params.reindex(coef_name_list)\n",
    "global_sotu_obs_coefs[\"num_pairs\"] = obs_fit.nobs\n",
    "global_sotu_obs_coefs[\"num_subjects_with_pairs\"] = turnover_data.stratum.unique().shape[\n",
    "    0\n",
    "]\n",
    "_transition_pairs = turnover_data[lambda x: x.pair_type == \"EEN:PostEEN\"]\n",
    "global_sotu_obs_coefs[\"num_transition_pairs\"] = _transition_pairs.shape[0]\n",
    "global_sotu_obs_coefs[\n",
    "    \"num_subjects_with_transition_pairs\"\n",
    "] = _transition_pairs.stratum.unique().shape[0]\n",
    "\n",
    "np.random.seed(0)\n",
    "_null_coef_dists = []\n",
    "for _ in tqdm(range(n_perm)):\n",
    "    perm_fit = smf.ols(\n",
    "        formula,\n",
    "        data=turnover_data.assign(\n",
    "            pair_type=lambda x: x.groupby(\"stratum\").pair_type.sample(frac=1).values\n",
    "        ),\n",
    "    ).fit()\n",
    "    _null_coef_dists.append(perm_fit.params.reindex(coef_name_list))\n",
    "\n",
    "global_sotu_null_coefs = pd.DataFrame(_null_coef_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = turnover_data\n",
    "fit = obs_fit\n",
    "\n",
    "\n",
    "# pair_type_palette = {'Transition': 'tab:green', 'EEN': 'tab:blue', 'PostEEN': 'tab:orange'}\n",
    "# pair_type_marker_palette = {'EEN': 's', 'Transition': '>', 'PostEEN': 'o'}\n",
    "# pair_type_linestyle_palette = {'EEN': ':', 'Transition': '--', 'PostEEN': '-'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "# ax.set_title(\"Within-subject Pairwise Turnover\")\n",
    "for pair_type in pair_type_order:\n",
    "    d3 = d1[lambda x: (x.pair_type == pair_type)]\n",
    "    ax.scatter(\n",
    "        \"time_delta\",\n",
    "        \"diss\",\n",
    "        label=\"__nolegend__\",\n",
    "        data=d3,\n",
    "        color=pair_type_palette[pair_type],\n",
    "        marker=pair_type_marker_palette[pair_type],\n",
    "        edgecolor=\"white\",\n",
    "        lw=0.5,\n",
    "        alpha=0.75,\n",
    "        s=40,\n",
    "    )\n",
    "\n",
    "_arbitrary_subject = d1.stratum.unique()[1]\n",
    "predict_data = pd.DataFrame(\n",
    "    product(\n",
    "        [_arbitrary_subject],\n",
    "        pair_type_order,\n",
    "        np.logspace(1.0, 2.6),\n",
    "    ),\n",
    "    columns=[\"stratum\", \"pair_type\", \"time_delta\"],\n",
    ")\n",
    "predict_data = predict_data.assign(\n",
    "    prediction=fit.predict(predict_data),\n",
    "    predict_mean_subject=lambda x: x.prediction\n",
    "    - fit.params[f\"C(stratum, Sum)[S.{_arbitrary_subject}]\"],\n",
    ")\n",
    "for pair_type in pair_type_order:\n",
    "    d4 = predict_data[lambda x: x.pair_type == pair_type]\n",
    "    left, right = d1[lambda x: x.pair_type == pair_type].time_delta.quantile(\n",
    "        [0.05, 0.95]\n",
    "    )\n",
    "    ax.plot(\n",
    "        \"time_delta\",\n",
    "        \"predict_mean_subject\",\n",
    "        label=\"__nolegend__\",\n",
    "        data=d4[lambda x: (x.time_delta > left) & (x.time_delta < right)],\n",
    "        color=\"black\",\n",
    "        linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        lw=2,\n",
    "    )\n",
    "ax.set_ylabel(\"Turnover\")\n",
    "ax.set_xlabel(\"Days between Samples\")\n",
    "ax.set_xscale(\"symlog\", linthresh=1e-1)\n",
    "\n",
    "fig.savefig(\"fig/een_turnover_analysis_strain_level.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 1.5))\n",
    "for pair_type in pair_type_order:\n",
    "    ax.scatter(\n",
    "        [],\n",
    "        [],\n",
    "        label=pair_type,\n",
    "        color=pair_type_palette[pair_type],\n",
    "        marker=pair_type_marker_palette[pair_type],\n",
    "        edgecolor=\"grey\",\n",
    "        lw=0.5,\n",
    "        s=50,\n",
    "    )\n",
    "for pair_type in pair_type_order:\n",
    "    ax.plot(\n",
    "        [],\n",
    "        [],\n",
    "        label=pair_type,\n",
    "        color=\"k\",\n",
    "        linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        lw=2,\n",
    "    )\n",
    "ax.legend(ncols=2, handlelength=3, markerscale=1.1)\n",
    "lib.plot.hide_axes_and_spines(ax=ax)\n",
    "\n",
    "fig.savefig(\"fig/een_turnover_analysis_legend.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_obs = global_sotu_obs_coefs\n",
    "_null = global_sotu_null_coefs\n",
    "\n",
    "for coef, color in zip(coef_name_list, [\"tab:blue\", \"tab:orange\", \"tab:green\"]):\n",
    "    sns.kdeplot(_null[coef], color=color)\n",
    "    plt.axvline(_obs[coef], color=color, label=coef)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = dict(\n",
    "    transition_vs_een=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[EEN]\"],\n",
    "    transition_vs_pos=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    een_vs_post=lambda x: x[\"pair_type[EEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    transition_vs_mean=lambda x: x[\"pair_type[EEN:PostEEN]\"]\n",
    "    - 0.5 * (x[\"pair_type[EEN]\"] + x[\"pair_type[PostEEN]\"]),\n",
    ")\n",
    "\n",
    "_obs = global_sotu_obs_coefs\n",
    "_null = global_sotu_null_coefs\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, sharex=True)\n",
    "for comp, ax in zip(comparisons, axs):\n",
    "    x, y = _null.apply(comparisons[comp], axis=1), comparisons[comp](_obs)\n",
    "    ax.set_title(comp)\n",
    "    ax.hist(x)\n",
    "    ax.axvline(y)\n",
    "    print(calculate_2tailed_pvalue_from_perm(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_turnover_analysis_details = {}\n",
    "for species_id in tqdm(motu_rabund.columns):\n",
    "    inpath = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    if not os.path.exists(inpath):\n",
    "        print(species_id, \"file missing\")\n",
    "        continue\n",
    "\n",
    "    sf_fit = (\n",
    "        sf.data.World.load(inpath)\n",
    "        .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "        .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "        # .drop_low_abundance_strains(0.01)\n",
    "        # .rename_coords(strain=str)\n",
    "    )\n",
    "\n",
    "    comm = sf_fit.community.to_pandas()\n",
    "    comm_bc_pdist = pd.DataFrame(\n",
    "        squareform(pdist(comm, metric=\"braycurtis\")),\n",
    "        index=comm.index,\n",
    "        columns=comm.index,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        turnover_data = construct_turnover_analysis_data(\n",
    "            comm_bc_pdist,\n",
    "            meta=sample[lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])],\n",
    "            sample_type_var=\"diet_or_media\",\n",
    "            stratum_var=\"subject_id\",\n",
    "            time_var=\"collection_date_relative_een_end\",\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(species_id, \"data doesn't work\")\n",
    "        continue\n",
    "    species_turnover_analysis_details[species_id] = pd.Series(\n",
    "        dict(\n",
    "            overall_mean_diss=turnover_data.groupby(\"stratum\").diss.mean().mean(),\n",
    "            num_pairs=turnover_data.shape[0],\n",
    "            num_subjects_with_pairs=turnover_data.stratum.unique().shape[0],\n",
    "            num_transition_pairs=turnover_data[\n",
    "                lambda x: x.pair_type == \"EEN:PostEEN\"\n",
    "            ].shape[0],\n",
    "            num_subjects_with_transition_pairs=turnover_data[\n",
    "                lambda x: x.pair_type == \"EEN:PostEEN\"\n",
    "            ]\n",
    "            .stratum.unique()\n",
    "            .shape[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "species_turnover_analysis_details = pd.DataFrame(\n",
    "    species_turnover_analysis_details.values(),\n",
    "    index=species_turnover_analysis_details.keys(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "coef_name_list = [\"pair_type[EEN]\", \"pair_type[PostEEN]\", \"pair_type[EEN:PostEEN]\"]\n",
    "n_perm = 999  # FIXME: Replace this with 999. Take about 40 minutes.\n",
    "\n",
    "obs_coefs = {}\n",
    "null_coef_dists = []\n",
    "for species_id in tqdm(motu_rabund.columns):\n",
    "    inpath = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    if not os.path.exists(inpath):\n",
    "        print(species_id, \"file missing\")\n",
    "        continue\n",
    "\n",
    "    sf_fit = (\n",
    "        sf.data.World.load(inpath)\n",
    "        .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "        .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "        # .drop_low_abundance_strains(0.01)\n",
    "        # .rename_coords(strain=str)\n",
    "    )\n",
    "\n",
    "    comm = sf_fit.community.to_pandas()\n",
    "    comm_bc_pdist = pd.DataFrame(\n",
    "        squareform(pdist(comm, metric=\"braycurtis\")),\n",
    "        index=comm.index,\n",
    "        columns=comm.index,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        turnover_data = construct_turnover_analysis_data(\n",
    "            comm_bc_pdist,\n",
    "            meta=sample[lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])],\n",
    "            sample_type_var=\"diet_or_media\",\n",
    "            stratum_var=\"subject_id\",\n",
    "            time_var=\"collection_date_relative_een_end\",\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(species_id, \"data doesn't work\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        obs_fit = smf.ols(formula, data=turnover_data).fit()\n",
    "    except ValueError:\n",
    "        print(species_id, \"fit failed\")\n",
    "        continue\n",
    "    obs_coefs[species_id] = obs_fit.params.reindex(coef_name_list)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    _null_coef_dists = []\n",
    "    for _ in range(n_perm):\n",
    "        perm_fit = smf.ols(\n",
    "            formula,\n",
    "            data=turnover_data.assign(\n",
    "                pair_type=lambda x: x.groupby(\"stratum\").pair_type.sample(frac=1).values\n",
    "            ),\n",
    "        ).fit()\n",
    "        _null_coef_dists.append(perm_fit.params.reindex(coef_name_list))\n",
    "    null_coef_dists.append(\n",
    "        pd.DataFrame(_null_coef_dists, columns=coef_name_list).assign(\n",
    "            species_id=species_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "per_species_obs_coefs = pd.DataFrame(obs_coefs).T\n",
    "per_species_null_coefs = pd.concat(null_coef_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = dict(\n",
    "    transition_vs_een=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[EEN]\"],\n",
    "    transition_vs_pos=lambda x: x[\"pair_type[EEN:PostEEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    een_vs_post=lambda x: x[\"pair_type[EEN]\"] - x[\"pair_type[PostEEN]\"],\n",
    "    transition_vs_mean=lambda x: x[\"pair_type[EEN:PostEEN]\"]\n",
    "    - 0.5 * (x[\"pair_type[EEN]\"] + x[\"pair_type[PostEEN]\"]),\n",
    ")\n",
    "\n",
    "transition_stats_obs = per_species_obs_coefs.dropna().assign(**comparisons)\n",
    "transition_stats_null = per_species_null_coefs.assign(**comparisons)\n",
    "_stats = transition_stats_null.join(transition_stats_obs, on='species_id', lsuffix='_obs', rsuffix='_null', how='inner')\n",
    "\n",
    "species_transition_test_pvalue = _stats.dropna().groupby('species_id').apply(lambda x: calculate_2tailed_pvalue_from_perm(x.transition_vs_mean_obs, x.transition_vs_mean_null))\n",
    "# for species in per_species_obs_coefs.dropna().index:\n",
    "#     print(calculate_2tailed_pvalue_from_perm(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(transition_stats_obs.transition_vs_mean, species_transition_test_pvalue)\n",
    "ax.set_yscale('log')\n",
    "ax.yaxis.set_inverted(True)\n",
    "ax.set_xlim(-2.5, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zOTU / Metagenomics Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSSVD\n",
    "\n",
    "\n",
    "def plssvd_cross_mapping(x, y, scaled=False, transpose=False):\n",
    "    if transpose:\n",
    "        x, y = y, x\n",
    "    pls = PLSSVD(n_components=min(*x.shape, *y.shape), scale=scaled).fit(x, y)\n",
    "    cc = pd.DataFrame(\n",
    "        pls.x_weights_ @ pls.y_weights_.T, index=x.columns, columns=y.columns\n",
    "    )\n",
    "    if transpose:\n",
    "        cc = cc.T\n",
    "    return cc, pls\n",
    "\n",
    "\n",
    "def reciprocal_hits(x, y, score_func):\n",
    "    x, y = align_indexes(x, y)\n",
    "\n",
    "    coefs, aux = score_func(x, y)\n",
    "\n",
    "    cols = coefs.columns\n",
    "    idxs = coefs.index\n",
    "\n",
    "    x_weight = np.sqrt((x.mean().loc[idxs]))\n",
    "    y_weight = np.sqrt((y.mean().loc[cols]))\n",
    "    weighted_coef = coefs.multiply(x_weight, axis=0).multiply(y_weight, axis=1)\n",
    "\n",
    "    cols_rank = weighted_coef.rank(1, ascending=False)\n",
    "    idxs_rank = weighted_coef.rank(0, ascending=False)\n",
    "\n",
    "    result = (\n",
    "        (cols_rank * idxs_rank)\n",
    "        .stack()\n",
    "        .to_frame(\"rank_product\")\n",
    "        .assign(coef=coefs.stack(), weighted_coef=weighted_coef.stack())\n",
    "    )\n",
    "\n",
    "    return result, coefs, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = motu_rabund.copy(), rotu_rabund.copy()\n",
    "print(len(x), len(y))\n",
    "\n",
    "reciprocal_hits_results, cc, aux = reciprocal_hits(\n",
    "    x,\n",
    "    y,\n",
    "    score_func=lambda x, y: plssvd_cross_mapping(x, y, scaled=False),\n",
    ")\n",
    "reciprocal_hits_results = (\n",
    "    reciprocal_hits_results.join(motu_taxonomy[[\"f__\", \"g__\", \"s__\"]], on=\"species_id\")\n",
    "    .join(rotu_taxonomy[[\"f__\", \"g__\"]], lsuffix=\"mgen\", rsuffix=\"zotu\")\n",
    "    .sort_values(\"zotu\")\n",
    ")\n",
    "\n",
    "\n",
    "reciprocal_hits_results[lambda x: x.rank_product <= 2].sort_values(\n",
    "    \"zotu\"\n",
    ").rank_product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_hits_results[lambda x: x.rank_product <= 2].assign(\n",
    "    g_mgen_norm=lambda x: x.g__mgen.str[3:].str.split(\"_\").str[0],\n",
    "    g_zotu_norm=lambda x: x.g__zotu.str.split(\"_\").str[0],\n",
    "    g_match=lambda x: x.g_mgen_norm == x.g_zotu_norm,\n",
    "    f_mgen_norm=lambda x: x.f__mgen.str[3:].str.split(\"_\").str[0],\n",
    "    f_zotu_norm=lambda x: x.f__zotu.str.split(\"_\").str[0],\n",
    "    f_match=lambda x: x.f_mgen_norm == x.f_zotu_norm,\n",
    "    matches=lambda x: (x.f_match | x.g_match),\n",
    ").matches.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_hits_results.xs(\"Zotu5\", level=\"zotu\").sort_values(\"rank_product\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_hits_filtered = reciprocal_hits_results[\n",
    "    lambda x: x.rank_product <= 2\n",
    "].assign(\n",
    "    g_mgen_norm=lambda x: x.g__mgen.str[3:].str.split(\"_\").str[0],\n",
    "    g_zotu_norm=lambda x: x.g__zotu.str.split(\"_\").str[0],\n",
    "    g_match=lambda x: x.g_mgen_norm == x.g_zotu_norm,\n",
    "    f_mgen_norm=lambda x: x.f__mgen.str[3:].str.split(\"_\").str[0],\n",
    "    f_zotu_norm=lambda x: x.f__zotu.str.split(\"_\").str[0],\n",
    "    f_match=lambda x: x.f_mgen_norm == x.f_zotu_norm,\n",
    ")[\n",
    "    lambda x: (x.f_match | x.g_match)\n",
    "]\n",
    "reciprocal_hits_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Table S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = reciprocal_hits_filtered.join(motu_taxonomy.s__.rename('uhgg_taxonomy')).assign(\n",
    "    coefficient=lambda x: x.coef.round(3),\n",
    "    weighted_coefficient=lambda x: x.weighted_coef.round(3),\n",
    "    rank_product=lambda x: x.rank_product.astype(int),\n",
    "    uhgg_url=lambda x: \"https://www.ebi.ac.uk/metagenomics/genomes/MGYG0000\" + x.index.to_frame().species_id.str[1:],\n",
    "    ezbc_id='',\n",
    "    network_association='',\n",
    ")[['coefficient', 'weighted_coefficient', 'rank_product', 'uhgg_taxonomy', 'uhgg_url', 'ezbc_id', 'network_association']]\n",
    "\n",
    "d.to_csv('fig/een_supplementary_table_s3.tsv', sep='\\t')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zOTUs or species, and what fraction of relative abundance do these account for?\n",
    "d.index.to_frame().zotu.unique().shape, d.index.to_frame().species_id.unique().shape, rotu_rabund[d.index.to_frame().zotu.values].sum(1).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.5, 4))\n",
    "\n",
    "bins = np.linspace(-0.2, 1.0, num=41)\n",
    "plt.hist(\n",
    "    reciprocal_hits_results.coef,\n",
    "    density=True,\n",
    "    bins=bins,\n",
    "    histtype=\"step\",\n",
    "    color=\"k\",\n",
    "    lw=1,\n",
    "    linestyle=\"--\",\n",
    "    label=\"All\",\n",
    "    zorder=2,\n",
    ")\n",
    "plt.hist(\n",
    "    reciprocal_hits_filtered.coef,\n",
    "    density=True,\n",
    "    bins=bins,\n",
    "    color=\"tab:blue\",\n",
    "    label=\"Matches\",\n",
    "    zorder=1,\n",
    ")\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"zOTU-to-Species\\nMatching Coefficient\")\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.savefig(\"fig/een_species_matching_correlation_density.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zOTU5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(\n",
    "    dict(\n",
    "        rotu=rotu_rabund[[\"Zotu5\"]].sum(1),\n",
    "        motu_A=motu_rabund[[\"101386\"]].sum(1),\n",
    "        motu_B=motu_rabund[[\"101493\"]].sum(1),\n",
    "        motu_both=motu_rabund[[\"101493\", \"101386\"]].sum(1),\n",
    "    )\n",
    ").dropna()\n",
    "print(sp.stats.pearsonr(d[\"motu_A\"], d[\"rotu\"]))\n",
    "print(sp.stats.pearsonr(d[\"motu_B\"], d[\"rotu\"]))\n",
    "print(sp.stats.pearsonr(d[\"motu_both\"], d[\"rotu\"]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.scatter(\n",
    "    \"rotu\",\n",
    "    \"motu_A\",\n",
    "    data=d,\n",
    "    label=\"$\\mathit{E. clostridioforme}$\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "plt.scatter(\n",
    "    \"rotu\",\n",
    "    \"motu_B\",\n",
    "    data=d,\n",
    "    label=\"$\\mathit{E. bolteae}$\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"lightcoral\",\n",
    ")\n",
    "plt.scatter(\n",
    "    \"rotu\",\n",
    "    \"motu_both\",\n",
    "    data=d,\n",
    "    label=\"Combined\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot([0, 0.5], [0, 0.5])\n",
    "plt.xlabel(\"zOTU5 relative abundance\")\n",
    "plt.ylabel(\"Species relative abundance\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "# plt.ylim(1e-8, 5e1)\n",
    "# ax.set_aspect(1)\n",
    "plt.legend(loc=\"lower right\", fontsize=\"small\", markerscale=2)\n",
    "\n",
    "plt.savefig(\"fig/een_zotu5_species_matching.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sp-101346 (B. uniformis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(\n",
    "    dict(\n",
    "        rotu_A=rotu_rabund[[\"Zotu48\"]].sum(1),\n",
    "        rotu_B=rotu_rabund[[\"Zotu6\"]].sum(1),\n",
    "        # rotu_C=rotu_rabund[[\"Zotu84\"]].sum(1),\n",
    "        motu=motu_rabund[[\"101346\"]].sum(1),\n",
    "        rotu_both=rotu_rabund[[\"Zotu6\", \"Zotu48\"]].sum(1),\n",
    "    )\n",
    ").dropna()\n",
    "print(sp.stats.pearsonr(d[\"rotu_A\"], d[\"motu\"]))\n",
    "print(sp.stats.pearsonr(d[\"rotu_B\"], d[\"motu\"]))\n",
    "# print(sp.stats.pearsonr(d[\"rotu_C\"], d[\"motu\"]))\n",
    "print(sp.stats.pearsonr(d[\"rotu_both\"], d[\"motu\"]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.scatter(\n",
    "    \"motu\",\n",
    "    \"rotu_A\",\n",
    "    data=d,\n",
    "    label=\"$\\mathit{zOTU48}$\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "plt.scatter(\n",
    "    \"motu\",\n",
    "    \"rotu_B\",\n",
    "    data=d,\n",
    "    label=\"$\\mathit{zOTU6}$\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"lightcoral\",\n",
    ")\n",
    "# plt.scatter(\n",
    "#     \"motu\",\n",
    "#     \"rotu_C\",\n",
    "#     data=d,\n",
    "#     label=\"$\\mathit{zOTU84}$\",\n",
    "#     s=20,\n",
    "#     alpha=0.7,\n",
    "#     edgecolor=\"grey\",\n",
    "#     color=\"lightgreen\",\n",
    "# )\n",
    "plt.scatter(\n",
    "    \"motu\",\n",
    "    \"rotu_both\",\n",
    "    data=d,\n",
    "    label=\"Combined\",\n",
    "    s=20,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"grey\",\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot([0, 0.5], [0, 0.5])\n",
    "plt.xlabel(\"B. uniformis\")\n",
    "plt.ylabel(\"zOTU relative abundance\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "# plt.ylim(1e-8, 5e1)\n",
    "# ax.set_aspect(1)\n",
    "plt.legend(loc=\"upper left\", fontsize=\"small\", markerscale=2)\n",
    "\n",
    "plt.savefig(\"fig/een_101346_zotu_matching.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Species Strain Time-Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 101493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"101493\"\n",
    "\n",
    "\n",
    "print(motu_taxonomy.loc[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_fit = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    .drop_low_abundance_strains(0.2)\n",
    "    .rename_coords(strain=str)\n",
    ")\n",
    "print(strain_fit.sizes)\n",
    "\n",
    "# Genotype similarity ordered palette:\n",
    "strain_linkage = strain_fit.genotype.linkage(optimal_ordering=True)\n",
    "strain_order = list(\n",
    "    linkage_order(\n",
    "        strain_linkage,\n",
    "        strain_fit.strain.values,\n",
    "    )\n",
    ")\n",
    "strain_order.remove(\"-1\")  # Drop \"other\" strain.\n",
    "strain_order.append(\"-1\")  # Add to end of list\n",
    "strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    ")\n",
    "\n",
    "sf.evaluation.metagenotype_error2(strain_fit, discretized=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sample_linkage = strain_fit.unifrac_linkage(optimal_ordering=True)\n",
    "position_ss = strain_fit.random_sample(\n",
    "    position=min(strain_fit.sizes[\"position\"], 1000)\n",
    ").position\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    strain_fit.sel(position=position_ss), col_linkage_func=lambda w: sample_linkage\n",
    ")\n",
    "sf.plot.plot_community(strain_fit, col_linkage_func=lambda w: sample_linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_colors_strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,  # Linkage order, I believe\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    "    desaturate_levels=[1.0, 0.7, 0.4],\n",
    ")\n",
    "\n",
    "\n",
    "sample.timepoint.map(rename_timepoints_for_ts)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,\n",
    "    10,\n",
    "    figsize=(10 * 2.7, 2 * 1.5),\n",
    "    squeeze=False,\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(hspace=1.8, wspace=0),\n",
    ")\n",
    "\n",
    "\n",
    "for subject, ax in zip(subject_order, axs.flatten()):\n",
    "    subject_comm_sample_list = list(\n",
    "        set(idxwhere(sample.subject_id == subject)) & set(strain_fit.sample.values)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        subject_comm = (\n",
    "            strain_fit.sel(sample=subject_comm_sample_list)\n",
    "            .drop_low_abundance_strains(0.2, agg_strain_coord=\"-1\")\n",
    "            .community.to_pandas()\n",
    "        )\n",
    "    except ValueError:\n",
    "        subject_comm = pd.DataFrame([], columns=[\"-1\"])\n",
    "\n",
    "    sample_list = sample.sort_values(\"collection_date_relative_een_end\")[\n",
    "        lambda x: (x.subject_id == subject)\n",
    "        & (x.sample_type == \"human\")\n",
    "        & (x.index.isin(subject_comm.index))\n",
    "    ].index\n",
    "\n",
    "    if len(sample_list) == 0:\n",
    "        lib.plot.hide_axes_and_spines(ax=ax)\n",
    "        continue\n",
    "\n",
    "    d = (\n",
    "        sample.reindex(sample_list)\n",
    "        # .dropna(subset=[\"collection_date_relative_een_end\"])\n",
    "        # .sort_values(\"collection_date_relative_een_end\")\n",
    "        .assign(\n",
    "            t=lambda x: range(len(x)),\n",
    "        )\n",
    "    ).join(subject_comm)\n",
    "    # d.loc[d.index[:num_offset_samples], 't'] -= 0.7  # Offset width\n",
    "\n",
    "    plot_stacked_barplot(\n",
    "        data=d,\n",
    "        x_var=\"t\",\n",
    "        order=[s for s in strain_order if s in subject_comm.columns],\n",
    "        palette=more_colors_strain_palette,\n",
    "        ax=ax,\n",
    "        width=0.8,\n",
    "        lw=0,\n",
    "    )\n",
    "\n",
    "    ax.set_title(subject)\n",
    "    ax.set_xticklabels(\n",
    "        d.timepoint.map(rename_timepoints_for_ts),\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_aspect(3, anchor=\"NW\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    lib.plot.rotate_xticklabels(rotation=90, ax=ax, ha=\"center\")\n",
    "    ax.set_yticks(np.linspace(0, 1.0, num=3))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, symbol=\"%\"))\n",
    "    ax.set_xlim(d.t.min() - 0.5, d.t.max() + 0.5)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    # ax.legend(bbox_to_anchor=(1, 1), ncols=2)\n",
    "\n",
    "fig.savefig(f\"fig/een.strain_timeseries.{species}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 101386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"101386\"\n",
    "\n",
    "\n",
    "print(motu_taxonomy.loc[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_fit = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    .drop_low_abundance_strains(0.2)\n",
    "    .rename_coords(strain=str)\n",
    ")\n",
    "print(strain_fit.sizes)\n",
    "\n",
    "# Genotype similarity ordered palette:\n",
    "strain_linkage = strain_fit.genotype.linkage(optimal_ordering=True)\n",
    "strain_order = list(\n",
    "    linkage_order(\n",
    "        strain_linkage,\n",
    "        strain_fit.strain.values,\n",
    "    )\n",
    ")\n",
    "strain_order.remove(\"-1\")  # Drop \"other\" strain.\n",
    "strain_order.append(\"-1\")  # Add to end of list\n",
    "strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    ")\n",
    "\n",
    "sf.evaluation.metagenotype_error2(strain_fit, discretized=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sample_linkage = strain_fit.unifrac_linkage(optimal_ordering=True)\n",
    "position_ss = strain_fit.random_sample(\n",
    "    position=min(strain_fit.sizes[\"position\"], 1000)\n",
    ").position\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    strain_fit.sel(position=position_ss), col_linkage_func=lambda w: sample_linkage\n",
    ")\n",
    "sf.plot.plot_community(strain_fit, col_linkage_func=lambda w: sample_linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_colors_strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,  # Linkage order, I believe\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    "    desaturate_levels=[1.0, 0.7, 0.4],\n",
    ")\n",
    "\n",
    "\n",
    "sample.timepoint.map(rename_timepoints_for_ts)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,\n",
    "    10,\n",
    "    figsize=(10 * 2.7, 2 * 1.5),\n",
    "    squeeze=False,\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(hspace=1.8, wspace=0),\n",
    ")\n",
    "\n",
    "\n",
    "for subject, ax in zip(subject_order, axs.flatten()):\n",
    "    subject_comm_sample_list = list(\n",
    "        set(idxwhere(sample.subject_id == subject)) & set(strain_fit.sample.values)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        subject_comm = (\n",
    "            strain_fit.sel(sample=subject_comm_sample_list)\n",
    "            .drop_low_abundance_strains(0.2, agg_strain_coord=\"-1\")\n",
    "            .community.to_pandas()\n",
    "        )\n",
    "    except ValueError:\n",
    "        subject_comm = pd.DataFrame([], columns=[\"-1\"])\n",
    "\n",
    "    sample_list = sample.sort_values(\"collection_date_relative_een_end\")[\n",
    "        lambda x: (x.subject_id == subject)\n",
    "        & (x.sample_type == \"human\")\n",
    "        & (x.index.isin(subject_comm.index))\n",
    "    ].index\n",
    "\n",
    "    if len(sample_list) == 0:\n",
    "        lib.plot.hide_axes_and_spines(ax=ax)\n",
    "        continue\n",
    "\n",
    "    d = (\n",
    "        sample.reindex(sample_list)\n",
    "        # .dropna(subset=[\"collection_date_relative_een_end\"])\n",
    "        # .sort_values(\"collection_date_relative_een_end\")\n",
    "        .assign(\n",
    "            t=lambda x: range(len(x)),\n",
    "        )\n",
    "    ).join(subject_comm)\n",
    "    # d.loc[d.index[:num_offset_samples], 't'] -= 0.7  # Offset width\n",
    "\n",
    "    plot_stacked_barplot(\n",
    "        data=d,\n",
    "        x_var=\"t\",\n",
    "        order=[s for s in strain_order if s in subject_comm.columns],\n",
    "        palette=more_colors_strain_palette,\n",
    "        ax=ax,\n",
    "        width=0.8,\n",
    "        lw=0,\n",
    "    )\n",
    "\n",
    "    ax.set_title(subject)\n",
    "    ax.set_xticklabels(\n",
    "        d.timepoint.map(rename_timepoints_for_ts),\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_aspect(3, anchor=\"NW\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    lib.plot.rotate_xticklabels(rotation=90, ax=ax, ha=\"center\")\n",
    "    ax.set_yticks(np.linspace(0, 1.0, num=3))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, symbol=\"%\"))\n",
    "    ax.set_xlim(d.t.min() - 0.5, d.t.max() + 0.5)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    # ax.legend(bbox_to_anchor=(1, 1), ncols=2)\n",
    "\n",
    "fig.savefig(f\"fig/een.strain_timeseries.{species}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 102506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"102506\"\n",
    "\n",
    "\n",
    "print(motu_taxonomy.loc[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_fit = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    .drop_low_abundance_strains(0.2)\n",
    "    .rename_coords(strain=str)\n",
    ")\n",
    "print(strain_fit.sizes)\n",
    "\n",
    "# Genotype similarity ordered palette:\n",
    "strain_linkage = strain_fit.genotype.linkage(optimal_ordering=True)\n",
    "strain_order = list(\n",
    "    linkage_order(\n",
    "        strain_linkage,\n",
    "        strain_fit.strain.values,\n",
    "    )\n",
    ")\n",
    "strain_order.remove(\"-1\")  # Drop \"other\" strain.\n",
    "strain_order.append(\"-1\")  # Add to end of list\n",
    "strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    ")\n",
    "\n",
    "sf.evaluation.metagenotype_error2(strain_fit, discretized=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sample_linkage = strain_fit.unifrac_linkage(optimal_ordering=True)\n",
    "position_ss = strain_fit.random_sample(\n",
    "    position=min(strain_fit.sizes[\"position\"], 1000)\n",
    ").position\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    strain_fit.sel(position=position_ss), col_linkage_func=lambda w: sample_linkage\n",
    ")\n",
    "sf.plot.plot_community(strain_fit, col_linkage_func=lambda w: sample_linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_colors_strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,  # Linkage order, I believe\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    "    desaturate_levels=[1.0, 0.7, 0.4],\n",
    ")\n",
    "\n",
    "\n",
    "sample.timepoint.map(rename_timepoints_for_ts)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,\n",
    "    10,\n",
    "    figsize=(10 * 2.7, 2 * 1.5),\n",
    "    squeeze=False,\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(hspace=1.8, wspace=0),\n",
    ")\n",
    "\n",
    "\n",
    "for subject, ax in zip(subject_order, axs.flatten()):\n",
    "    subject_comm_sample_list = list(\n",
    "        set(idxwhere(sample.subject_id == subject)) & set(strain_fit.sample.values)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        subject_comm = (\n",
    "            strain_fit.sel(sample=subject_comm_sample_list)\n",
    "            .drop_low_abundance_strains(0.2, agg_strain_coord=\"-1\")\n",
    "            .community.to_pandas()\n",
    "        )\n",
    "    except ValueError:\n",
    "        subject_comm = pd.DataFrame([], columns=[\"-1\"])\n",
    "\n",
    "    sample_list = sample.sort_values(\"collection_date_relative_een_end\")[\n",
    "        lambda x: (x.subject_id == subject)\n",
    "        & (x.sample_type == \"human\")\n",
    "        & (x.index.isin(subject_comm.index))\n",
    "    ].index\n",
    "\n",
    "    if len(sample_list) == 0:\n",
    "        lib.plot.hide_axes_and_spines(ax=ax)\n",
    "        continue\n",
    "\n",
    "    d = (\n",
    "        sample.reindex(sample_list)\n",
    "        # .dropna(subset=[\"collection_date_relative_een_end\"])\n",
    "        # .sort_values(\"collection_date_relative_een_end\")\n",
    "        .assign(\n",
    "            t=lambda x: range(len(x)),\n",
    "        )\n",
    "    ).join(subject_comm)\n",
    "    # d.loc[d.index[:num_offset_samples], 't'] -= 0.7  # Offset width\n",
    "\n",
    "    plot_stacked_barplot(\n",
    "        data=d,\n",
    "        x_var=\"t\",\n",
    "        order=[s for s in strain_order if s in subject_comm.columns],\n",
    "        palette=more_colors_strain_palette,\n",
    "        ax=ax,\n",
    "        width=0.8,\n",
    "        lw=0,\n",
    "    )\n",
    "\n",
    "    ax.set_title(subject)\n",
    "    ax.set_xticklabels(\n",
    "        d.timepoint.map(rename_timepoints_for_ts),\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_aspect(3, anchor=\"NW\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    lib.plot.rotate_xticklabels(rotation=90, ax=ax, ha=\"center\")\n",
    "    ax.set_yticks(np.linspace(0, 1.0, num=3))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, symbol=\"%\"))\n",
    "    ax.set_xlim(d.t.min() - 0.5, d.t.max() + 0.5)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    # ax.legend(bbox_to_anchor=(1, 1), ncols=2)\n",
    "\n",
    "fig.savefig(f\"fig/een.strain_timeseries.{species}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 101346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"101346\"\n",
    "\n",
    "\n",
    "print(motu_taxonomy.loc[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_fit = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    .drop_low_abundance_strains(0.2)\n",
    "    .rename_coords(strain=str)\n",
    ")\n",
    "print(strain_fit.sizes)\n",
    "\n",
    "# Genotype similarity ordered palette:\n",
    "strain_linkage = strain_fit.genotype.linkage(optimal_ordering=True)\n",
    "strain_order = list(\n",
    "    linkage_order(\n",
    "        strain_linkage,\n",
    "        strain_fit.strain.values,\n",
    "    )\n",
    ")\n",
    "strain_order.remove(\"-1\")  # Drop \"other\" strain.\n",
    "strain_order.append(\"-1\")  # Add to end of list\n",
    "strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    ")\n",
    "\n",
    "sf.evaluation.metagenotype_error2(strain_fit, discretized=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "sample_linkage = strain_fit.unifrac_linkage(optimal_ordering=True)\n",
    "position_ss = strain_fit.random_sample(\n",
    "    position=min(strain_fit.sizes[\"position\"], 1000)\n",
    ").position\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    strain_fit.sel(position=position_ss), col_linkage_func=lambda w: sample_linkage\n",
    ")\n",
    "sf.plot.plot_community(strain_fit, col_linkage_func=lambda w: sample_linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_colors_strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,  # Linkage order, I believe\n",
    "    cm=\"rainbow\",\n",
    "    extend={\"-1\": \"silver\"},\n",
    "    desaturate_levels=[1.0, 0.7, 0.4],\n",
    ")\n",
    "\n",
    "\n",
    "sample.timepoint.map(rename_timepoints_for_ts)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    2,\n",
    "    10,\n",
    "    figsize=(10 * 2.7, 2 * 1.5),\n",
    "    squeeze=False,\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(hspace=1.8, wspace=0),\n",
    ")\n",
    "\n",
    "\n",
    "for subject, ax in zip(subject_order, axs.flatten()):\n",
    "    subject_comm_sample_list = list(\n",
    "        set(idxwhere(sample.subject_id == subject)) & set(strain_fit.sample.values)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        subject_comm = (\n",
    "            strain_fit.sel(sample=subject_comm_sample_list)\n",
    "            .drop_low_abundance_strains(0.2, agg_strain_coord=\"-1\")\n",
    "            .community.to_pandas()\n",
    "        )\n",
    "    except ValueError:\n",
    "        subject_comm = pd.DataFrame([], columns=[\"-1\"])\n",
    "\n",
    "    sample_list = sample.sort_values(\"collection_date_relative_een_end\")[\n",
    "        lambda x: (x.subject_id == subject)\n",
    "        & (x.sample_type == \"human\")\n",
    "        & (x.index.isin(subject_comm.index))\n",
    "    ].index\n",
    "\n",
    "    if len(sample_list) == 0:\n",
    "        lib.plot.hide_axes_and_spines(ax=ax)\n",
    "        continue\n",
    "\n",
    "    d = (\n",
    "        sample.reindex(sample_list)\n",
    "        # .dropna(subset=[\"collection_date_relative_een_end\"])\n",
    "        # .sort_values(\"collection_date_relative_een_end\")\n",
    "        .assign(\n",
    "            t=lambda x: range(len(x)),\n",
    "        )\n",
    "    ).join(subject_comm)\n",
    "    # d.loc[d.index[:num_offset_samples], 't'] -= 0.7  # Offset width\n",
    "\n",
    "    plot_stacked_barplot(\n",
    "        data=d,\n",
    "        x_var=\"t\",\n",
    "        order=[s for s in strain_order if s in subject_comm.columns],\n",
    "        palette=more_colors_strain_palette,\n",
    "        ax=ax,\n",
    "        width=0.8,\n",
    "        lw=0,\n",
    "    )\n",
    "\n",
    "    ax.set_title(subject)\n",
    "    ax.set_xticklabels(\n",
    "        d.timepoint.map(rename_timepoints_for_ts),\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_aspect(3, anchor=\"NW\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    lib.plot.rotate_xticklabels(rotation=90, ax=ax, ha=\"center\")\n",
    "    ax.set_yticks(np.linspace(0, 1.0, num=3))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, symbol=\"%\"))\n",
    "    ax.set_xlim(d.t.min() - 0.5, d.t.max() + 0.5)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    # ax.legend(bbox_to_anchor=(1, 1), ncols=2)\n",
    "\n",
    "fig.savefig(f\"fig/een.strain_timeseries.{species}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Summary and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    motu_enrichment_results.join(per_species_obs_coefs)\n",
    "    .join(species_turnover_analysis_details)\n",
    "    .assign(\n",
    "        uhgg_taxonomy=motu_lineage_string,\n",
    "        zotu_match=reciprocal_hits_filtered.reset_index().groupby('species_id').zotu.apply(', '.join),\n",
    "        subject_prevalence=(motu_prevalence_by_subject > 0).mean(),\n",
    "        mean_rabund=lambda x: (x.mean_EEN + x.mean_PostEEN) / 2,\n",
    "        indicator_score=lambda x: np.abs(x.log2_ratio)\n",
    "        * x.num_pairs\n",
    "        * x.mean_rabund\n",
    "        * x.overall_mean_diss,\n",
    "    )\n",
    "    .rename(\n",
    "        columns=dict(\n",
    "            log2_ratio=\"species_log2_fold_change\",\n",
    "            mean_rabund=\"species_overall_mean_relative_abundance\",\n",
    "            num_pairs=\"num_intrasubject_sample_pairs\",\n",
    "            overall_mean_diss=\"mean_pairwise_braycurtis_dissimilarity\",\n",
    "            zotu_match=\"zotu_match\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# # Save statistics\n",
    "# (\n",
    "#     d0.sort_values(\"indicator_score\", ascending=False)[\n",
    "#         lambda x: x.indicator_score > 0.1\n",
    "#     ][\n",
    "#         [\n",
    "#             \"indicator_score\",\n",
    "#             \"species_log2_fold_change\",\n",
    "#             \"species_overall_mean_relative_abundance\",\n",
    "#             \"mean_pairwise_braycurtis_dissimilarity\",\n",
    "#             \"num_intrasubject_sample_pairs\",\n",
    "#             \"uhgg_taxonomy\",\n",
    "#             \"zotu_match\",\n",
    "#         ]\n",
    "#     ]\n",
    "#     .round(3)\n",
    "#     .to_csv(\"fig/een_turnover_stats.tsv\", sep=\"\\t\")\n",
    "# )\n",
    "\n",
    "d1 = d0[\n",
    "    lambda x: (x.num_intrasubject_sample_pairs > 20)\n",
    "    & (~x.species_overall_mean_relative_abundance.isna())\n",
    "].assign(zorder=0)\n",
    "\n",
    "\n",
    "focal_species_style_map = {\n",
    "    \"101493\": (\"E. bolteae\", (-10, 10)),\n",
    "    \"101386\": (\"E. clostridioforme\", (-20, -30)),\n",
    "    \"102506\": (\"E. coli\", (-10, 10)),\n",
    "    \"101346\": (\"B. uniformis\", (-40, 10)),\n",
    "}\n",
    "\n",
    "d1.loc[focal_species_style_map.keys(), \"zorder\"] = 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    \"species_log2_fold_change\",\n",
    "    \"mean_pairwise_braycurtis_dissimilarity\",\n",
    "    data=d1[d1.zorder == 0],\n",
    "    c=\"indicator_score\",\n",
    "    zorder=0,\n",
    "    norm=mpl.colors.SymLogNorm(linthresh=0.1, linscale=0.5),\n",
    "    s=50,\n",
    "    edgecolor=\"grey\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    \"species_log2_fold_change\",\n",
    "    \"mean_pairwise_braycurtis_dissimilarity\",\n",
    "    data=d1[d1.zorder == 1],\n",
    "    c=\"indicator_score\",\n",
    "    zorder=1,\n",
    "    # norm=mpl.colors.SymLogNorm(linthresh=0.1, linscale=0.5),\n",
    "    s=70,\n",
    "    edgecolor=\"grey\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "# plt.ylim(-0.5, 1.5)\n",
    "cbar = plt.colorbar(label=\"Score\", alpha=1.0)\n",
    "cbar.solids.set(alpha=1)\n",
    "\n",
    "for _species, (_name, (textx, texty)) in focal_species_style_map.items():\n",
    "    # plt.scatter(\n",
    "    #     \"species_log2_fold_change\",\n",
    "    #     \"mean_pairwise_braycurtis_dissimilarity\",\n",
    "    #     data=d1.loc[[_species]],\n",
    "    #     edgecolor=_color,\n",
    "    #     facecolor=\"none\",\n",
    "    #     s=200,\n",
    "    # )\n",
    "    plt.annotate(\n",
    "        _name,\n",
    "        xy=d1.loc[\n",
    "            _species,\n",
    "            [\"species_log2_fold_change\", \"mean_pairwise_braycurtis_dissimilarity\"],\n",
    "        ].values,\n",
    "        xytext=(textx, texty),\n",
    "        textcoords=\"offset points\",\n",
    "        # rotation=rotation,\n",
    "        fontstyle='italic',\n",
    "        arrowprops=dict(arrowstyle=\"->\", color='darkred', linewidth=1.2),\n",
    "        ha='right',\n",
    "        \n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Mean Log2(Fold-change)\")\n",
    "plt.ylabel(\"Mean Turnover\")\n",
    "# plt.yscale('symlog', linthresh=1e-2)\n",
    "# plt.xlim(-13, 6)\n",
    "plt.xticks([-12, -9, -6, -3, 0, 3, 6, 9, 12])\n",
    "plt.savefig(\"fig/een_turnover_stats.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "print(\n",
    "    sp.stats.spearmanr(\n",
    "        d1.species_log2_fold_change, d1.mean_pairwise_braycurtis_dissimilarity\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_transition_test_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = (\n",
    "    motu_enrichment_results.join(per_species_obs_coefs)\n",
    "    .join(species_turnover_analysis_details)\n",
    "    .assign(\n",
    "        zotu_match=reciprocal_hits_filtered.reset_index().groupby('species_id').zotu.apply(', '.join),\n",
    "        subject_prevalence=(motu_prevalence_by_subject > 0).mean(),\n",
    "        mean_rabund=lambda x: (x.mean_EEN + x.mean_PostEEN) / 2,\n",
    "        indicator_score=lambda x: np.abs(x.log2_ratio)\n",
    "        * x.mean_rabund\n",
    "        * x.num_pairs\n",
    "        * x.overall_mean_diss,\n",
    "        transition_turnover_effect=transition_stats_obs.transition_vs_mean,\n",
    "        transition_turnover_pvalue=species_transition_test_pvalue,\n",
    "    )\n",
    "    .rename(\n",
    "        columns=dict(\n",
    "            log2_ratio=\"species_log2_fold_change\",\n",
    "            pvalue=\"species_pvalue\",\n",
    "            mean_rabund=\"species_overall_mean_relative_abundance\",\n",
    "            num_pairs=\"num_intrasubject_sample_pairs\",\n",
    "            overall_mean_diss=\"mean_pairwise_braycurtis_dissimilarity\",\n",
    "            zotu_match=\"zotu_match\",\n",
    "\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "d1 = (\n",
    "    d0.dropna(subset=['indicator_score']).sort_values(\"indicator_score\", ascending=False)\n",
    "    .assign(\n",
    "        indicator_score=lambda x: x.indicator_score.round(3),\n",
    "        species_log2_fold_change=lambda x: x.species_log2_fold_change.round(1),\n",
    "        species_pvalue=lambda x: x.species_pvalue.round(4),\n",
    "        species_overall_mean_relative_abundance=lambda x: x.species_overall_mean_relative_abundance.round(4),\n",
    "        num_intrasubject_sample_pairs=lambda x: x.num_intrasubject_sample_pairs.astype(int),\n",
    "        mean_pairwise_braycurtis_dissimilarity=lambda x: x.mean_pairwise_braycurtis_dissimilarity.round(2),\n",
    "        transition_turnover_effect=lambda x: x.transition_turnover_effect.round(2),\n",
    "        transition_turnover_pvalue=lambda x: x.transition_turnover_pvalue.round(4),\n",
    "        # zotu_match=lambda x: x.zotu_match.fillna(\"\"),\n",
    "        uhgg_taxonomy=motu_taxonomy.s__,\n",
    "        uhgg_url=lambda x: \"https://www.ebi.ac.uk/metagenomics/genomes/MGYG0000\" + x.index.to_series().str[1:],\n",
    "        ezbc_id=\"\",\n",
    "        network_association=\"\",\n",
    "    )\n",
    "    [\n",
    "        [\n",
    "            \"indicator_score\",\n",
    "            \"species_log2_fold_change\",\n",
    "            \"species_pvalue\",\n",
    "            \"species_overall_mean_relative_abundance\",\n",
    "            \"num_intrasubject_sample_pairs\",\n",
    "            \"mean_pairwise_braycurtis_dissimilarity\",\n",
    "            \"transition_turnover_effect\",\n",
    "            \"transition_turnover_pvalue\",\n",
    "            \"zotu_match\",\n",
    "            \"uhgg_taxonomy\",\n",
    "            \"uhgg_url\",\n",
    "            \"ezbc_id\",\n",
    "            \"network_association\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "d1[lambda x: x.indicator_score > 0.1].to_csv(\"fig/een_supplementary_table_s4.tsv\", sep=\"\\t\")\n",
    "d1[lambda x: x.indicator_score > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[lambda x: x.indicator_score > 0.1].zotu_match.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.loc[['101493', '101386', '102506', '101346']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[lambda x: (x.indicator_score > 0.1) & (x.transition_turnover_pvalue < 0.05) & (x.transition_turnover_effect > 0)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz5",
   "language": "python",
   "name": "toolz5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
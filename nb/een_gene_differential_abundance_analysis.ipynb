{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir(_os.environ[\"PROJECT_ROOT\"])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import chain, product\n",
    "from tempfile import mkstemp\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sfacts as sf\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.dissimilarity\n",
    "import lib.plot\n",
    "import lib.thisproject.data\n",
    "from lib.pandas_util import align_indexes, aligned_index, idxwhere, invert_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_2tailed_pvalue_from_perm(obs, perms):\n",
    "    hypoth_left = perms > obs\n",
    "    hypoth_right = perms < obs\n",
    "    null_p_left = (hypoth_left.sum() + 1) / (len(hypoth_left) + 1)\n",
    "    null_p_right = (hypoth_right.sum() + 1) / (len(hypoth_right) + 1)\n",
    "    return np.minimum(null_p_left, null_p_right) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkage_order(linkage, labels):\n",
    "    return labels[sp.cluster.hierarchy.to_tree(linkage).pre_order(lambda x: x.id)]\n",
    "\n",
    "\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def iterate_primes_up_to(n, return_index=False):\n",
    "    n = int(np.ceil(n))\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        if is_prime(i):\n",
    "            if return_index:\n",
    "                yield (idx, i)\n",
    "            else:\n",
    "                yield i\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def maximally_shuffled_order(sorted_order):\n",
    "    n = len(sorted_order)\n",
    "    primes_list = list(iterate_primes_up_to(np.sqrt(n)))\n",
    "    table = pd.DataFrame(np.arange(n), index=sorted_order, columns=[\"original_order\"])\n",
    "    for prime in primes_list:\n",
    "        table[prime] = table.original_order % prime\n",
    "    table.sort_values(primes_list).original_order.values\n",
    "    table = table.assign(new_order=table.sort_values(primes_list).original_order.values)\n",
    "    z = table.sort_values(\"new_order\").original_order.values\n",
    "    table[\"delta\"] = [np.nan] + list(z[1:] - z[:-1])\n",
    "    return table.sort_values(\"new_order\").index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_meta = pd.read_table(\n",
    "    \"ref/cog-20.meta.tsv\",\n",
    "    encoding=\"latin10\",\n",
    "    names=[\"cog\", \"categories\", \"description\", \"gene_name\", \"pathway\", \"_5\", \"color\"],\n",
    "    index_col=\"cog\",\n",
    ")\n",
    "cog_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_category_meta = pd.read_table(\n",
    "    \"ref/cog-20.categories.tsv\",\n",
    "    names=[\"category\", \"color\", \"description\"],\n",
    "    index_col=\"category\",\n",
    ")\n",
    "cog_category_meta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOTE: If I decide that it's the filenames that are wrong, then I need to swap labels in the metagenomic results (including sfacts worlds and\n",
    "# species relative abundances).\n",
    "\n",
    "SAMPLE_SWAP_CORRECTION = {\n",
    "    # CF_667 through CF_672 should actually be labeled CF_531 - CF_537\n",
    "    'CF_667': 'CF_531',\n",
    "    'CF_668': 'CF_532',\n",
    "    'CF_669': 'CF_533',\n",
    "    'CF_670': 'CF_534',\n",
    "    'CF_671': 'CF_535',\n",
    "    'CF_672': 'CF_536',\n",
    "\n",
    "    # CF_11 <-> CF_15\n",
    "    'CF_11': 'CF_15',\n",
    "    'CF_15': 'CF_11',\n",
    "\n",
    "    # Some/half of the newly shared samples\n",
    "    CF_379\n",
    "    CF_380\n",
    "    CF_381\n",
    "    CF_384\n",
    "    CF_385\n",
    "    CF_386\n",
    "    CF_426\n",
    "    CF_427\n",
    "    CF_428\n",
    "    CF_429\n",
    "    CF_430\n",
    "    CF_431\n",
    "    CF_395\n",
    "    CF_397\n",
    "    CF_402\n",
    "    CF_406\n",
    "    CF_409\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_type_palette = {\n",
    "    \"EEN\": \"teal\",\n",
    "    \"PostEEN\": \"mediumblue\",\n",
    "    \"Transition\": \"blueviolet\",\n",
    "}\n",
    "\n",
    "diet_palette = {\n",
    "    \"EEN\": \"lightgreen\",\n",
    "    \"PostEEN\": \"lightblue\",\n",
    "    \"InVitro\": \"plum\",\n",
    "    \"PreEEN\": \"lightpink\",\n",
    "}\n",
    "\n",
    "subject_order = [\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"H\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "]\n",
    "\n",
    "# NOTE: Requires a dummy value because I want exactly 20 items.\n",
    "subject_palette = lib.plot.construct_ordered_palette(\n",
    "    subject_order + [f\"dummy{i}\" for i in range(20 - len(subject_order))], cm=\"tab20\"\n",
    ")\n",
    "subject_palette[\"X\"] = \"black\"\n",
    "pair_type_order = [\"EEN\", \"Transition\", \"PostEEN\"]\n",
    "pair_type_marker_palette = {\"EEN\": \"s\", \"Transition\": \">\", \"PostEEN\": \"o\"}\n",
    "pair_type_linestyle_palette = {\"EEN\": \":\", \"Transition\": \"-.\", \"PostEEN\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_experiment_sample(x):\n",
    "    if x.sample_type == \"human\":\n",
    "        label = f\"{x.subject_id} [{x.sample_id}] {x.collection_date_relative_een_end} {x.diet_or_media}\"\n",
    "    elif x.sample_type in [\"Fermenter_inoculum\"]:\n",
    "        label = (\n",
    "            f\"{x.subject_id} [{x.sample_id}] {x.source_samples} inoc {x.diet_or_media}\"\n",
    "        )\n",
    "    elif x.sample_type in [\"Fermenter\"]:\n",
    "        label = (\n",
    "            f\"{x.subject_id} [{x.sample_id}] {x.source_samples} frmnt {x.diet_or_media}\"\n",
    "        )\n",
    "    elif x.sample_type in [\"mouse\"]:\n",
    "        if x.status_mouse_inflamed == \"Inflamed\":\n",
    "            label = f\"{x.subject_id} [{x.sample_id}] {x.source_samples} \ud83d\udc2d {x.mouse_genotype} {x.diet_or_media} inflam\"\n",
    "        elif x.status_mouse_inflamed == \"not_Inflamed\":\n",
    "            label = f\"{x.subject_id} [{x.sample_id}] {x.source_samples} \ud83d\udc2d {x.mouse_genotype} {x.diet_or_media} not_inf\"\n",
    "        else:\n",
    "            raise ValueError(f\"sample type {x.status_mouse_inflamed} not understood\")\n",
    "    else:\n",
    "        raise ValueError(f\"sample type {x.sample_type} not understood\")\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (\n",
    "    pd.read_table(\"meta/een-mgen/sample.tsv\")\n",
    "    .assign(\n",
    "        label=lambda x: x[\n",
    "            [\n",
    "                \"subject_id\",\n",
    "                \"collection_date_relative_een_end\",\n",
    "                \"diet_or_media\",\n",
    "                \"sample_id\",\n",
    "            ]\n",
    "        ].apply(tuple, axis=1),\n",
    "        fuller_label=lambda d: d.apply(_label_experiment_sample, axis=1),\n",
    "    )\n",
    "    .set_index(\"sample_id\")\n",
    ")\n",
    "subject = pd.read_table(\"meta/een-mgen/subject.tsv\", index_col=\"subject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubiquitous, single-copy genes to be used for estimating total genome depth:\n",
    "\n",
    "schg_cog_list = [\n",
    "    \"COG0012\",\n",
    "    \"COG0016\",\n",
    "    \"COG0048\",\n",
    "    \"COG0049\",\n",
    "    \"COG0052\",\n",
    "    \"COG0080\",\n",
    "    \"COG0081\",\n",
    "    \"COG0085\",\n",
    "    \"COG0087\",\n",
    "    \"COG0088\",\n",
    "    \"COG0090\",\n",
    "    \"COG0091\",\n",
    "    \"COG0092\",\n",
    "    \"COG0093\",\n",
    "    \"COG0094\",\n",
    "    \"COG0096\",\n",
    "    \"COG0097\",\n",
    "    \"COG0098\",\n",
    "    \"COG0099\",\n",
    "    \"COG0100\",\n",
    "    \"COG0102\",\n",
    "    \"COG0103\",\n",
    "    \"COG0124\",\n",
    "    \"COG0184\",\n",
    "    \"COG0185\",\n",
    "    \"COG0186\",\n",
    "    \"COG0197\",\n",
    "    \"COG0200\",\n",
    "    \"COG0201\",\n",
    "    \"COG0256\",\n",
    "    \"COG0495\",\n",
    "    \"COG0522\",\n",
    "    \"COG0525\",\n",
    "    \"COG0533\",\n",
    "    \"COG0542\",  # This one is a depth outlier...\n",
    "]\n",
    "\n",
    "cog_meta.loc[schg_cog_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all species with pangenome profiles\n",
    "\n",
    "species_list = pd.read_table(\"meta/species_group.tsv\")[\n",
    "    lambda x: x.species_group_id == \"een\"\n",
    "].species_id\n",
    "assert species_list.is_unique\n",
    "species_list = list(species_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table of gene depths for each species and aggregate by COG.\n",
    "# Can take up to 8 minutes to compile everything\n",
    "cog_depth = {}\n",
    "\n",
    "for species in tqdm(species_list):\n",
    "    gene_x_cog_inpath = (\n",
    "        f\"data/species/sp-{species}/pangenome.centroids.emapper.gene_x_cog.tsv\"\n",
    "    )\n",
    "    # f\"data/species/sp-{species}/midasdb_v15.emapper.gene75_x_cog.tsv\"  # This is new as of 2023-12-06 and used the \"voting\" procedure. Also, it's based on MIDASDB v1.5... so that might be problematic.\n",
    "    gene_depth_inpath = (\n",
    "        f\"data/group/een/species/sp-{species}/r.proc.gene99_new-v22-agg75.depth2.nc\"\n",
    "    )\n",
    "    _gene_x_cog = (\n",
    "        pd.read_table(gene_x_cog_inpath)\n",
    "        .drop_duplicates()\n",
    "        .set_index(\"gene_id\")\n",
    "        .squeeze()\n",
    "    )\n",
    "\n",
    "    # Calculate the depth of each COG by summing all genes labeled as that COG.\n",
    "    _cog_depth = (\n",
    "        xr.load_dataarray(gene_depth_inpath)\n",
    "        .to_pandas()\n",
    "        .T.join(_gene_x_cog)\n",
    "        .groupby(\"cog\")\n",
    "        .sum()\n",
    "    )\n",
    "    cog_depth[species] = _cog_depth.stack()\n",
    "\n",
    "cog_depth = (\n",
    "    pd.DataFrame(cog_depth)\n",
    "    .stack()\n",
    "    .rename_axis([\"cog\", \"sample\", \"species\"])\n",
    "    .to_xarray()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Normalize sample names and swap the mislabeled samples.\n",
    "cog_depth[\"sample\"] = (\n",
    "    cog_depth.sample.to_series()\n",
    "    .map(lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .replace({\"CF_15\": \"CF_11\", \"CF_11\": \"CF_15\"})\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SCHGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schg_cog_by_sample_depth = cog_depth.sum(\"species\").sel(cog=schg_cog_list).to_pandas()\n",
    "\n",
    "sns.clustermap(\n",
    "    schg_cog_by_sample_depth,\n",
    "    metric=\"cosine\",\n",
    "    yticklabels=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_schg_cog_correlation = 1 - lib.dissimilarity.dmatrix(\n",
    "    schg_cog_by_sample_depth, metric=\"correlation\"\n",
    ")\n",
    "sns.clustermap(\n",
    "    pairwise_schg_cog_correlation, norm=mpl.colors.PowerNorm(1, vmin=0, vmax=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = cog_depth.sel(cog=schg_cog_list).mean(\"cog\")\n",
    "species_relabund = species_depth / species_depth.sum(\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Species Depth Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_list = [\"100003\", \"102506\", \"100022\"]\n",
    "_sample_list = [\"CF_94\", \"CF_93\"]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(_species_list),\n",
    "    len(_sample_list),\n",
    "    figsize=(5 * len(_sample_list), 3 * len(_species_list)),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "axs = np.asanyarray(axs).reshape((len(_species_list), len(_sample_list)))\n",
    "\n",
    "bins = np.logspace(-3, 4, num=100)\n",
    "\n",
    "for (_species, _sample), ax in zip(product(_species_list, _sample_list), axs.flatten()):\n",
    "    ax.hist(cog_depth.sel(sample=_sample, species=_species).to_pandas(), bins=bins)\n",
    "    ax.axvline(species_depth.loc[_sample, _species], color=\"black\")\n",
    "    ax.set_title((_species, _sample))\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "# plt.xlim(0, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Limit Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_detection_limit = cog_depth.where(lambda x: x != 0, np.inf).min(\n",
    "    (\"sample\", \"species\")\n",
    ")\n",
    "undetected_cogs_list = idxwhere((cog_detection_limit == np.inf).to_series())\n",
    "\n",
    "cog_depth_or_detection_limit = cog_depth.where(\n",
    "    lambda x: x != 0, cog_detection_limit\n",
    ").drop_sel(cog=undetected_cogs_list)\n",
    "cog_depth_or_detection_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize COG depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_genome_depth = (\n",
    "    cog_depth_or_detection_limit.sel(cog=schg_cog_list)\n",
    "    .median(\"cog\")\n",
    "    .sum(\"species\")  # NOTE: Mean or Median? Does it matter?\n",
    ")\n",
    "normalized_cog_depth_by_sample = (\n",
    "    cog_depth_or_detection_limit.sum(\"species\") / total_genome_depth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cog_depth_by_subject_and_type = (\n",
    "    normalized_cog_depth_by_sample.to_pandas()\n",
    "    .T.join(sample[[\"subject_id\", \"diet_or_media\"]])[\n",
    "        lambda x: x.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "    ]\n",
    "    .groupby([\"subject_id\", \"diet_or_media\"])\n",
    "    .median()  # NOTE: Mean or Median?\n",
    "    .unstack(\"diet_or_media\")\n",
    "    .dropna()\n",
    "    .stack(\"diet_or_media\")\n",
    ")\n",
    "normalized_cog_depth_by_subject_and_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_test_results = {}\n",
    "for cog in tqdm(normalized_cog_depth_by_subject_and_type.columns):\n",
    "    d = normalized_cog_depth_by_subject_and_type[cog].unstack()\n",
    "    mean_een = d.EEN.mean()\n",
    "    mean_post = d.PostEEN.mean()\n",
    "    mean_log2_ratio = np.log2(d.PostEEN / d.EEN).mean()\n",
    "    median_log2_ratio = np.log2(d.PostEEN / d.EEN).median()\n",
    "    try:\n",
    "        result = sp.stats.wilcoxon(\n",
    "            d.EEN,\n",
    "            d.PostEEN,\n",
    "        )\n",
    "        pval = result.pvalue\n",
    "    except ValueError:\n",
    "        pval = np.nan\n",
    "    pairwise_test_results[cog] = (\n",
    "        mean_een,\n",
    "        mean_post,\n",
    "        mean_log2_ratio,\n",
    "        median_log2_ratio,\n",
    "        pval,\n",
    "    )\n",
    "\n",
    "pairwise_test_results = pd.DataFrame(\n",
    "    pairwise_test_results,\n",
    "    index=(\"mean_een\", \"mean_post\", \"mean_log2_ratio\", \"median_log2_ratio\", \"pval\"),\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where I define filters on COGs:\n",
    "#    They must have a mean depth during one of the two time-periods of > 0.01\n",
    "\n",
    "pairwise_test_results_filt_with_fdr = (\n",
    "    pairwise_test_results\n",
    "    # [lambda x: (x.mean_een > 0.01) | (x.mean_post > 0.01)]\n",
    "    .assign(\n",
    "        fdr=lambda x: fdrcorrection(x.pval)[1],\n",
    "        hit=lambda x: (\n",
    "            True\n",
    "            & (x.fdr < 0.1)\n",
    "            # & (np.abs(x.mean_log2_ratio) > 0.2)\n",
    "        ),\n",
    "    ).sort_values(\"fdr\")\n",
    ")\n",
    "pairwise_test_results_filt_with_fdr[lambda x: x.hit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_test_results_filt_with_fdr[lambda x: x.hit].join(cog_meta).sort_values(\n",
    "    \"median_log2_ratio\", ascending=False\n",
    ").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pairwise_test_results_filt_with_fdr.sort_values(\"pval\").join(cog_meta)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\"mean_log2_ratio\", \"pval\", data=d[d.hit], color=\"r\", s=5)\n",
    "ax.scatter(\"mean_log2_ratio\", \"pval\", data=d[~d.hit], color=\"grey\", s=5)\n",
    "ax.invert_yaxis()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.axvline(0.2, color=\"black\", lw=1, linestyle=\"--\")\n",
    "ax.axvline(-0.2, color=\"black\", lw=1, linestyle=\"--\")\n",
    "ax.axhline(0.05, color=\"black\", lw=1, linestyle=\"--\")\n",
    "ax.set_xlabel(\"Mean Log2(OR)\")\n",
    "ax.set_ylabel(\"P-value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time-series for one, top COG.\n",
    "cog = \"COG5599\"\n",
    "\n",
    "d = (\n",
    "    sample.assign(cog=normalized_cog_depth_by_sample.sel(cog=cog).to_series())\n",
    "    .sort_values(\"collection_date_relative_een_end\")\n",
    "    .dropna(subset=[\"cog\"])\n",
    ")\n",
    "\n",
    "for subject in subject_order:\n",
    "    plt.plot(\n",
    "        \"collection_date_relative_een_end\",\n",
    "        \"cog\",\n",
    "        data=d[lambda w: w.subject_id == subject],\n",
    "    )\n",
    "plt.xscale(\"symlog\")\n",
    "plt.xlabel(\"Days before/after EEN End\")\n",
    "plt.ylabel(\"Normalized COG abundance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pairwise_test_results_filt_with_fdr.fdr < 0.1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG-categories Enriched in Gene Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_x_cog_category_matrix = (\n",
    "    cog_meta.categories.map(tuple)\n",
    "    .explode()\n",
    "    .rename(\"category\")\n",
    "    .reset_index()\n",
    "    .assign(in_category=True)\n",
    "    .set_index([\"cog\", \"category\"])\n",
    "    .in_category.unstack(fill_value=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_enrichment(x, y, data):\n",
    "    contingency = (\n",
    "        data[[x, y]]\n",
    "        .value_counts()\n",
    "        .reindex(\n",
    "            [(True, True), (True, False), (False, True), (False, False)], fill_value=0\n",
    "        )\n",
    "        .unstack()\n",
    "    )\n",
    "    contingency_pc = contingency + 1\n",
    "    log2_odds_ratio_pc = np.log2(\n",
    "        (contingency_pc.loc[True, True] / contingency_pc.loc[True, False])\n",
    "        / (contingency_pc.loc[False, True] / contingency_pc.loc[False, False])\n",
    "    )\n",
    "    num_hit = contingency_pc.loc[True, True] - 1\n",
    "    return (\n",
    "        num_hit,\n",
    "        log2_odds_ratio_pc,\n",
    "        *sp.stats.fisher_exact(contingency, alternative=\"greater\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pairwise_test_results_filt_with_fdr.assign(\n",
    "    increased=lambda x: x.hit & (x.median_log2_ratio > 0),\n",
    "    decreased=lambda x: x.hit & (x.median_log2_ratio < 0),\n",
    ").join(cog_x_cog_category_matrix)\n",
    "\n",
    "results = []\n",
    "for cog_category in cog_x_cog_category_matrix.columns:\n",
    "    for direction in [\"increased\", \"decreased\"]:\n",
    "        results.append(\n",
    "            (cog_category, direction, *test_enrichment(direction, cog_category, data=d))\n",
    "        )\n",
    "results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"cog_category\",\n",
    "        \"direction\",\n",
    "        \"num_hit\",\n",
    "        \"log2_odds_ratio_pc\",\n",
    "        \"fisher_stat\",\n",
    "        \"pvalue\",\n",
    "    ],\n",
    ")\n",
    "results.sort_values(\"pvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz2",
   "language": "python",
   "name": "toolz2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
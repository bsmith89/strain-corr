{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir(_os.environ[\"PROJECT_ROOT\"])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import chain, product\n",
    "from tempfile import mkstemp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "import sfacts as sf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.plot\n",
    "from lib.dissimilarity import load_dmat_as_pickle\n",
    "from lib.pandas_util import align_indexes, aligned_index, idxwhere, invert_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.thisproject.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = (\n",
    "    pd.read_table(\"meta/species_group.tsv\")[\n",
    "        lambda x: x.species_group_id == \"hmp2\"\n",
    "    ]\n",
    "    .species_id.astype(str)\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_taxonomy_string(taxonomy_string):\n",
    "    values = taxonomy_string.split(\";\")\n",
    "    return pd.Series(values, index=[\"d__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\", \"s__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy_inpath = \"ref/uhgg_genomes_all_v2.tsv\"\n",
    "\n",
    "species_taxonomy = (\n",
    "    pd.read_table(species_taxonomy_inpath)[lambda x: x.Genome == x.Species_rep]\n",
    "    .assign(species_id=lambda x: \"1\" + x.MGnify_accession.str.split(\"-\").str[2])\n",
    "    .set_index(\"species_id\")\n",
    "    .Lineage.apply(parse_taxonomy_string)\n",
    ")\n",
    "species_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylum_palette = lib.plot.construct_ordered_palette(\n",
    "    sorted(species_taxonomy.p__.unique()),\n",
    "    cm=\"tab10\",\n",
    ")\n",
    "\n",
    "# assert len(set(phylum_palette.values())) == len((phylum_palette.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = pd.read_table('meta/hmp2/mgen.tsv', index_col='library_id')\n",
    "preparation = pd.read_table('meta/hmp2/preparation.tsv', index_col='preparation_id')\n",
    "stool = pd.read_table('meta/hmp2/stool.tsv', index_col='stool_id')\n",
    "visit = pd.read_table('meta/hmp2/visit.tsv', index_col='visit_id')\n",
    "subject = pd.read_table('meta/hmp2/subject.tsv', index_col='subject_id')\n",
    "\n",
    "meta_all = (\n",
    "    mgen\n",
    "    .join(preparation.drop(columns='library_type'), on='preparation_id')\n",
    "    .join(stool, on='stool_id')\n",
    "    .join(visit, on='visit_id', rsuffix='_')\n",
    "    .join(subject, on='subject_id')\n",
    "    .assign(new_name=lambda x: (\n",
    "        x[['subject_id', 'week_number']]\n",
    "        .assign(library_id=x.index)\n",
    "        .assign(week_number=lambda x: x.week_number.fillna(999).astype(int))\n",
    "        .apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    ))\n",
    "    # .reset_index()\n",
    "    # .set_index('new_name')\n",
    ")\n",
    "\n",
    "library_id_to_new_name = meta_all.new_name\n",
    "\n",
    "assert not any(meta_all.subject_id.isna())\n",
    "\n",
    "# TODO: Rename samples based on subject and visit number\n",
    "# TODO: Drop duplicate stools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = []\n",
    "_missing_species = []\n",
    "\n",
    "for species in tqdm(species_list):\n",
    "    inpath = f\"data/group/hmp2/species/sp-{species}/r.proc.gtpro.sfacts-fit.gene99_v15-v22-agg75.spgc-fit.species_depth.tsv\"\n",
    "    if not os.path.exists(inpath):\n",
    "        _missing_species.append(species)\n",
    "        continue\n",
    "    data = pd.read_table(inpath, names=['sample', 'depth']).assign(species=species)\n",
    "    species_depth.append(data)\n",
    "species_depth = pd.concat(species_depth).set_index(['sample', 'species']).depth.unstack(fill_value=0)\n",
    "\n",
    "print(\n",
    "    len(_missing_species),\n",
    "    \"out of\",\n",
    "    len(species_list),\n",
    "    \"species are missing.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_thresh = 0.2\n",
    "\n",
    "species_found = species_depth > depth_thresh\n",
    "species_prevalence = species_found.groupby(meta_all.subject_id).any().mean().sort_values(ascending=False)\n",
    "\n",
    "species_rabund_when_found = species_depth.divide(species_depth.sum(1), axis=0).where(species_found, np.nan)\n",
    "species_mean_rabund_when_found = species_rabund_when_found.groupby(meta_all.subject_id).mean().mean().sort_values(ascending=False)\n",
    "species_median_rabund_when_found = species_rabund_when_found.groupby(meta_all.subject_id).median().median().sort_values(ascending=False)\n",
    "\n",
    "species_prevalence.to_frame('prevalence').assign(mean_rabund=species_mean_rabund_when_found, median_rabund=species_median_rabund_when_found).join(species_taxonomy).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_genome(x):\n",
    "    if (x.genome_type == \"Isolate\") & x.passes_filter:\n",
    "        return \"isolate\"\n",
    "    elif (x.genome_type == \"Isolate\") & ~x.passes_filter:\n",
    "        return \"isolate_fails_qc\"\n",
    "    elif (x.genome_type == \"MAG\") & x.passes_filter:\n",
    "        return \"mag\"\n",
    "    elif (x.genome_type == \"MAG\") & ~x.passes_filter:\n",
    "        return \"mag_fails_qc\"\n",
    "    elif (x.genome_type == \"SPGC\") & x.passes_filter:\n",
    "        return \"spgc\"\n",
    "    elif (x.genome_type == \"SPGC\") & x.passes_geno_positions & x.passes_in_sample_list:\n",
    "        return \"sfacts_only\"\n",
    "    elif (x.genome_type == \"SPGC\") & ~(\n",
    "        x.passes_geno_positions & x.passes_in_sample_list\n",
    "    ):\n",
    "        return \"sfacts_fails_qc\"\n",
    "    else:\n",
    "        raise ValueError(\"Genome did not match classification criteria:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_stats = []\n",
    "missing_species = []\n",
    "\n",
    "for species in tqdm(species_list):\n",
    "    inpath = f\"data/group/hmp2/species/sp-{species}/r.proc.gtpro.sfacts-fit.gene99_v15-v22-agg75.spgc-fit.strain_meta_spgc_and_ref.tsv\"\n",
    "    if not os.path.exists(inpath):\n",
    "        missing_species.append(species)\n",
    "        continue\n",
    "    data = pd.read_table(inpath).assign(species=species, inpath=inpath)\n",
    "    filt_stats.append(data)\n",
    "filt_stats = pd.concat(filt_stats).assign(\n",
    "    genome_class=lambda x: x.apply(classify_genome, axis=1)\n",
    ")\n",
    "\n",
    "print(\n",
    "    len(missing_species),\n",
    "    \"out of\",\n",
    "    len(species_list),\n",
    "    \"species are missing stats.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Collect strain fractions:\n",
    "\n",
    "strain_depth = []\n",
    "missing_species = []\n",
    "for species in species_list:\n",
    "    inpath = f\"data/group/hmp2/species/sp-{species}/r.proc.gtpro.sfacts-fit.comm.tsv\"\n",
    "    if not os.path.exists(inpath):\n",
    "        missing_species.append(species)\n",
    "        d = pd.DataFrame([])\n",
    "    else:\n",
    "        d = (\n",
    "            pd.read_table(inpath, index_col=[\"sample\", \"strain\"])\n",
    "            .squeeze()\n",
    "            .unstack()\n",
    "        )\n",
    "\n",
    "    if species in species_depth.columns:\n",
    "        _species_depth = species_depth[species]\n",
    "    else:\n",
    "        _species_depth = 0\n",
    "    \n",
    "    _keep_strains = idxwhere(d.sum() > 0.05)\n",
    "    assert d.index.isin(species_depth.index).all()\n",
    "    d = d.reindex(index=species_depth.index, columns=_keep_strains, fill_value=0)\n",
    "    d = d.assign(__other=lambda x: 1 - x.sum(1)).rename(columns={\"__other\": -1})\n",
    "    d[d < 0] = 0\n",
    "    d = d.divide(d.sum(1), axis=0)\n",
    "    d = d.multiply(_species_depth, axis=0)\n",
    "    d = d.rename(columns=lambda s: f\"{species}_{s}\")\n",
    "    strain_depth.append(d)\n",
    "\n",
    "strain_depth = pd.concat(strain_depth, axis=1)\n",
    "strain_rabund = strain_depth.divide(strain_depth.sum(1), axis=0)\n",
    "strain_rabund['-1'] = 1 - strain_rabund.sum(1)\n",
    "\n",
    "print(\n",
    "    len(missing_species),\n",
    "    \"out of\",\n",
    "    len(species_list),\n",
    "    \"species are missing stats.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared strains between \n",
    "other_strain_list = idxwhere(strain_depth.columns.to_series().str.endswith(\"-1\"))\n",
    "strain_present = strain_depth > 0.1\n",
    "low_strain_samples = idxwhere(strain_present.sum(1) <= 10)\n",
    "m, x = align_indexes(meta_all, strain_present.drop(columns=other_strain_list, index=low_strain_samples))\n",
    "\n",
    "shared_strains = pdist(x, metric=lambda x, y: (x & y).sum())\n",
    "diff_subj = pdist(m[['subject_id']], lambda x, y: (x != y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, shared_strains.max())\n",
    "\n",
    "for _diff_subj, c in zip([0, 1], ['tab:blue', 'tab:orange']):\n",
    "    plt.hist(shared_strains[diff_subj == _diff_subj], alpha=0.5, color=c, bins=bins, density=True)\n",
    "    plt.hist(shared_strains[diff_subj == _diff_subj], histtype='step', color=c, bins=bins, density=True)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_by_subject = (strain_depth.groupby(meta_all.subject_id).max() > 0.1).drop(columns=other_strain_list)\n",
    "plt.hist(strain_by_subject.sum(1), bins=np.linspace(0, 700, num=51))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(strain_by_subject.sum(0), bins=np.arange(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.stats\n",
    "\n",
    "lib.stats.mannwhitneyu('x', 'y', data=pd.DataFrame(dict(x=diff_subj.astype(bool), y=shared_strains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.mannwhitneyu(shared_strains[diff_subj.astype(bool)], shared_strains[~diff_subj.astype(bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared strains between \n",
    "other_strain_list = idxwhere(strain_depth.columns.to_series().str.endswith(\"-1\"))\n",
    "x = (strain_depth.groupby(meta_all.subject_id).max() > 0.1).drop(columns=other_strain_list)\n",
    "\n",
    "shared_strains_between_subjects = pdist(x, metric=lambda x, y: (x & y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 150)\n",
    "\n",
    "plt.hist(shared_strains_between_subjects, bins=bins)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(shared_strains_between_subjects).quantile([0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz3",
   "language": "python",
   "name": "toolz3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
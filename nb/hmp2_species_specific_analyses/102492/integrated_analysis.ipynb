{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from lib.pandas_util import idxwhere, align_indexes, invert_mapping\n",
    "import matplotlib as mpl\n",
    "import lib.plot\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from tempfile import mkstemp\n",
    "import time\n",
    "import subprocess\n",
    "from itertools import chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.thisproject.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.dpi'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default file path forming for interactive use.\n",
    "\n",
    "group = 'xjin_hmp2'\n",
    "species = '101346'\n",
    "stemA = 'r.proc'\n",
    "stemB = 'filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts43-s85-seed0'\n",
    "stemC = 'sfacts42-seed0'\n",
    "spgc_params = 'e100'\n",
    "centroid = 95\n",
    "\n",
    "path = dict(\n",
    "    flag=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.refit-{stemC}.midas_gene{centroid}.spgc-{spgc_params}.strain_files.flag\",\n",
    "    fit=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.world.nc\",\n",
    "    refit=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.refit-{stemC}.world.nc\",\n",
    "    strain_correlation=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.midas_gene{centroid}.spgc-{spgc_params}.strain_correlation.tsv\",\n",
    "    strain_depth_ratio=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.midas_gene{centroid}.spgc-{spgc_params}.strain_depth_ratio.tsv\",\n",
    "    strain_fraction=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.comm.tsv\",\n",
    "    species_gene_mean_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.midas_gene{centroid}.spgc-{spgc_params}.species_depth.tsv\",\n",
    "    species_gtpro_depth=f\"data/group/{group}/{stemA}.gtpro.species_depth.tsv\",\n",
    "    species_correlation=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.midas_gene{centroid}.spgc-{spgc_params}.species_correlation.tsv\",\n",
    "    strain_thresholds=f\"data/group/{group}/species/sp-{species}/{stemA}.gtpro.{stemB}.midas_gene{centroid}.spgc-{spgc_params}.strain_gene_threshold.tsv\",\n",
    "    gene_annotations=f\"ref/midasdb_uhgg_gene_annotations/sp-{species}.gene{centroid}_annotations.tsv\",\n",
    "    raw_gene_depth=f\"data/group/{group}/species/sp-{species}/{stemA}.midas_gene{centroid}.depth.nc\",\n",
    "    reference_copy_number=f\"ref/midasdb_uhgg_pangenomes/{species}/midas_gene{centroid}.reference_copy_number.nc\",\n",
    "    cluster_info=f\"ref/midasdb_uhgg/pangenomes/{species}/cluster_info.txt\",\n",
    "    species_taxonomy=\"ref/gtpro/species_taxonomy_ext.tsv\",\n",
    "    midasdb_genomes=\"ref/uhgg_genomes_all_4644.tsv\",\n",
    "    gtpro_reference_genotype=f\"data/species/sp-{species}/gtpro_ref.mgtp.nc\",\n",
    ")\n",
    "\n",
    "path_exists = {}\n",
    "for p in path:\n",
    "    path_exists[path[p]] = os.path.exists(path[p])\n",
    "\n",
    "assert all(path_exists.values()), '\\n'.join([\"Missing files:\"] + [p for p in path_exists if not path_exists[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy = lib.thisproject.data.load_species_taxonomy(path[\"species_taxonomy\"])\n",
    "species_taxonomy.loc[species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_gtpro_depth = lib.thisproject.data.load_species_depth(path[\"species_gtpro_depth\"])\n",
    "all_species_gtpro_rabund = all_species_gtpro_depth.divide(all_species_gtpro_depth.sum(1), axis=0) \n",
    "\n",
    "plt.hist(all_species_gtpro_rabund[species], bins=[0] + list(np.logspace(-7, 1, num=101)))\n",
    "plt.xscale('symlog', linthresh=1e-7)\n",
    "plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_species_gtpro_depth[species], bins=np.logspace(-4, 4, num=51))\n",
    "plt.xscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_species_core_depth = lib.thisproject.data.load_single_species_depth(path[\"species_gene_mean_depth\"])\n",
    "\n",
    "d = pd.DataFrame(dict(\n",
    "    gtpro=all_species_gtpro_depth[species],\n",
    "    gene=focal_species_core_depth,\n",
    "))\n",
    "\n",
    "plt.scatter('gtpro', 'gene', data=d, alpha=0.1)\n",
    "plt.yscale('symlog', linthresh=1e-4)\n",
    "plt.xscale('symlog', linthresh=1e-4)\n",
    "plt.plot([1e-4, 1e2], [1e-4, 1e2])\n",
    "plt.xlabel('GT-Pro depth')\n",
    "plt.ylabel('Core gene depth')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_species_core_depth = lib.thisproject.data.load_single_species_depth(path[\"species_gene_mean_depth\"])\n",
    "\n",
    "d = pd.DataFrame(dict(\n",
    "    gtpro=all_species_gtpro_depth[species],\n",
    "    gene=focal_species_core_depth,\n",
    "))\n",
    "\n",
    "plt.scatter('gtpro', 'gene', data=d, alpha=0.1)\n",
    "# plt.yscale('symlog', linthresh=1e-4)\n",
    "# plt.xscale('symlog', linthresh=1e-4)\n",
    "plt.plot([1e-4, 1e2], [1e-4, 1e2])\n",
    "plt.xlabel('GT-Pro depth')\n",
    "plt.ylabel('Core gene depth')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_depth = xr.load_dataarray(path[\"raw_gene_depth\"])\n",
    "\n",
    "plt.hist(np.log10(gene_depth.isel(sample=0) + 1e-5), bins=50)\n",
    "plt.yscale('log')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_corr = pd.read_table(path[\"species_correlation\"], names=['sample', 'correlation'], index_col='sample').squeeze()\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(1 - species_corr, bins=np.logspace(-3, 0, num=101))\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.invert_xaxis()\n",
    "\n",
    "\n",
    "species_threshold = species_corr.sort_values(ascending=False).head(700).min()\n",
    "species_marker_gene = idxwhere(species_corr > species_threshold)\n",
    "print(species_threshold)\n",
    "ax.axvline(1 - species_threshold, lw=1, linestyle='--', color='k')\n",
    "None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mgen = pd.read_table('meta/hmp2/mgen.tsv', index_col='library_id')\n",
    "preparation = pd.read_table('meta/hmp2/preparation.tsv', index_col='preparation_id')\n",
    "stool = pd.read_table('meta/hmp2/stool.tsv', index_col='stool_id')\n",
    "subject = pd.read_table('meta/hmp2/subject.tsv', index_col='subject_id')\n",
    "\n",
    "sample_meta = mgen.join(preparation, on='preparation_id', rsuffix='_').join(stool, on='stool_id').join(subject, on='subject_id').loc[all_species_gtpro_depth.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth = pd.read_table(path[\"species_gene_mean_depth\"], names=['sample', 'depth'], index_col='sample').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sf.World.load(\n",
    "    path[\"fit\"]\n",
    ").drop_low_abundance_strains(0.05)\n",
    "\n",
    "refit = sf.World.load(\n",
    "    path[\"refit\"]\n",
    ")\n",
    "\n",
    "print(fit.sizes)\n",
    "\n",
    "np.random.seed(0)\n",
    "position_ss = fit.random_sample(position=min(fit.sizes['position'], 1000)).position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    fit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    ")\n",
    "sf.plot.plot_depth(\n",
    "    fit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    ")\n",
    "sf.plot.plot_dominance(\n",
    "    fit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    ")\n",
    "sf.plot.plot_community(\n",
    "    fit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    "    row_linkage_func=lambda w: w.genotype.linkage(\"strain\"),\n",
    ")\n",
    "sf.plot.plot_genotype(\n",
    "    fit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: w.genotype.linkage(\"strain\"),\n",
    ")\n",
    "sf.plot.plot_genotype(\n",
    "    refit.sel(position=position_ss),\n",
    "    # scaley=0.2, scalex=0.3,\n",
    "    col_linkage_func=lambda w: fit.sel(position=position_ss).metagenotype.linkage(\"position\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geno = sf.Genotype(\n",
    "    sf.data.Metagenotype.load(path[\"gtpro_reference_genotype\"])\n",
    "    .to_estimated_genotype()\n",
    "    .to_series()\n",
    "    .unstack()\n",
    "    .rename(lambda s: 'UHGG' + s[len('GUT_GENOME'):])\n",
    "    .stack()\n",
    "    .to_xarray()\n",
    "    .sel(position=fit.position)\n",
    ")\n",
    "print(ref_geno.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_strain = (\n",
    "    (fit.community.data > 0.95)\n",
    "    .to_series()\n",
    "    .unstack()\n",
    "    .apply(idxwhere, axis=1)\n",
    "    [lambda x: x.apply(bool)]\n",
    "    .str[0]\n",
    "    .rename('strain')\n",
    ")\n",
    "    \n",
    "strain_to_sample_list = (\n",
    "    sample_to_strain\n",
    "    .rename('strain_id')\n",
    "    .reset_index()\n",
    "    .groupby('strain_id')\n",
    "    .apply(lambda x: x['sample'].to_list())\n",
    ")\n",
    "strain_to_sample_list.apply(len).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_thresholds = (\n",
    "    pd.read_table(path[\"strain_thresholds\"], index_col='strain')\n",
    "    .rename(columns=dict(\n",
    "        correlation_strict='corr_threshold_strict',\n",
    "        correlation_moderate='corr_threshold_moderate',\n",
    "        correlation_lenient='corr_threshold_lenient',\n",
    "        depth_high='depth_thresh_high',\n",
    "        depth_low='depth_thresh_low',\n",
    "    ))\n",
    ")\n",
    "\n",
    "_strain_meta = (\n",
    "    strain_thresholds\n",
    "    .join(fit.genotype.entropy().to_series().rename('genotype_entropy'))\n",
    "    .join(refit.genotype.entropy().to_series().rename('genotype_refit_entropy'))\n",
    "    .join(fit.metagenotype.entropy().to_series().rename('metagenotype_entropy').groupby(sample_to_strain).mean().rename(int))\n",
    "    .join(strain_to_sample_list.apply(len).rename('num_samples'))\n",
    "    .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).std().rename('depth_stdev').rename(int))\n",
    "    .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).max().rename('depth_max').rename(int))\n",
    "    .join(species_depth.apply(lambda x: x**(1)).groupby(sample_to_strain).sum().rename('depth_sum').rename(int))\n",
    "    .assign(power_index=lambda x: (x.depth_stdev * np.sqrt(x.num_samples)).fillna(0))\n",
    ")\n",
    "strain_meta = _strain_meta\n",
    "\n",
    "\n",
    "power_index_thresh = 5\n",
    "genotype_entropy_thresh = 0.2\n",
    "genotype_refit_entropy_thresh = 1.0\n",
    "\n",
    "high_power_strain_list = idxwhere(\n",
    "    (strain_meta.power_index > power_index_thresh)\n",
    "    & (strain_meta.genotype_entropy < genotype_entropy_thresh)\n",
    "    & (strain_meta.genotype_refit_entropy < genotype_refit_entropy_thresh)\n",
    ")\n",
    "print(len(high_power_strain_list))\n",
    "highest_power_strain_list = strain_meta.sort_values('power_index', ascending=False).head(3).index\n",
    "\n",
    "plt.scatter(strain_meta.power_index, strain_meta.corr_threshold_moderate, c=strain_meta.genotype_refit_entropy, alpha=0.5)\n",
    "plt.axvline(power_index_thresh, lw=1, linestyle='--', color='k')\n",
    "plt.colorbar()\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('metagenotype_entropy', 'genotype_entropy', data=strain_meta, c='genotype_refit_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_meta.assign(high_power=lambda x: x.index.isin(high_power_strain_list)).sort_values('power_index', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_meta.loc[high_power_strain_list].sort_values('corr_threshold_moderate').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_power_strain_palette = lib.plot.construct_ordered_palette(high_power_strain_list, mpl.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_corr = pd.read_table(path[\"strain_correlation\"], index_col=['gene_id', 'strain']).squeeze().unstack('strain', fill_value=0)\n",
    "strain_depth = pd.read_table(\n",
    "    path[\"strain_depth_ratio\"],\n",
    "    index_col=['gene_id', 'strain']\n",
    ").squeeze().unstack()\n",
    "strain_corr, strain_depth = align_indexes(strain_corr, strain_depth)\n",
    "strain_corr = strain_corr[strain_meta.index]\n",
    "strain_depth = strain_depth[strain_meta.index]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "strain = 20\n",
    "_strain_corr = strain_corr[strain]\n",
    "_strain_depth = strain_depth[strain]\n",
    "# _strain_corr = _strain_corr[(_strain_depth < strain_meta.depth_thresh_high[strain]) & (_strain_depth > strain_meta.depth_thresh_low[strain])]\n",
    "_species_corr = species_corr.loc[_strain_corr.index]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(1 - _species_corr, 1 - _strain_corr, s=1, c=_strain_depth)\n",
    "ax.plot([0, 1], [0, 1])\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_strain_list = high_power_strain_list\n",
    "\n",
    "fig, axs = lib.plot.subplots_grid(ncols=3, naxes=len(_strain_list), ax_width=5, ax_height=4, sharex=True)\n",
    "\n",
    "for strain, ax in zip(_strain_list, axs.flatten()):\n",
    "    d = pd.DataFrame(dict(\n",
    "        corr=1 - strain_corr[strain],\n",
    "        depth=strain_depth[strain],\n",
    "        marker=species_corr > species_threshold,\n",
    "        species_corr=1 - species_corr,\n",
    "    ))\n",
    "    ax.scatter('corr', 'depth', data=d, s=1, alpha=0.1, c='species_corr', cmap='winter_r', norm=mpl.colors.LogNorm())\n",
    "    # ax.scatter('corr', 'depth', data=d[d.marker], s=1, alpha=0.05, c='tab:orange')\n",
    "    ax.axvline(1 - strain_meta['corr_threshold_moderate'][strain], color='k', linestyle='--', lw=0.5)\n",
    "    ax.axhline(strain_meta['depth_thresh_low'][strain], color='k', linestyle='--', lw=0.5)\n",
    "    ax.set_xscale('symlog', linthresh=1e-3)\n",
    "    ax.set_xlim(left=-1e-4, right=1)\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(strain)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_corr_hit = strain_corr > strain_meta.corr_threshold_strict\n",
    "lenient_corr_hit = strain_corr > strain_meta.corr_threshold_lenient\n",
    "moderate_corr_hit = strain_corr > strain_meta.corr_threshold_moderate\n",
    "low_corr =  strain_corr < strain_meta.corr_threshold_lenient\n",
    "\n",
    "low_depth = (strain_depth < strain_meta.depth_thresh_low)\n",
    "depth_hit = ~low_depth\n",
    "high_depth = (strain_depth > strain_meta.depth_thresh_high)\n",
    "high_confidence_hit = depth_hit & strict_corr_hit\n",
    "moderate_hit = depth_hit & moderate_corr_hit\n",
    "maybe_hit = depth_hit & lenient_corr_hit\n",
    "low_depth_hit = low_depth & strict_corr_hit\n",
    "high_depth_hit = high_depth & strict_corr_hit\n",
    "ambiguous_hit = depth_hit ^ strict_corr_hit\n",
    "high_confidence_not_hit = low_depth & low_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_copy_number = xr.load_dataarray(path[\"reference_copy_number\"])\n",
    "reference_hit = pd.DataFrame(\n",
    "    reference_copy_number.T > 0,\n",
    "    columns=reference_copy_number.genome_id,\n",
    "    index=reference_copy_number.gene_id,\n",
    ")\n",
    "\n",
    "print(reference_copy_number.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    tally_moderate_hits=moderate_hit.sum(),\n",
    "    sum_gene_ratio=strain_depth[moderate_hit].sum(),\n",
    ")).assign(ratio=lambda x: x.sum_gene_ratio / x.tally_moderate_hits)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "bins = np.linspace(0, 10000, num=21)\n",
    "# sns.kdeplot(reference_hit.sum())\n",
    "# sns.kdeplot(d.tally_moderate_hits)\n",
    "# sns.kdeplot(d.tally_moderate_hits.loc[high_power_strain_list])\n",
    "\n",
    "\n",
    "plt.hist(reference_hit.sum(), bins=bins, density=True, alpha=0.5)\n",
    "# plt.hist(d.tally_moderate_hits, bins=bins, density=True, alpha=0.5)\n",
    "plt.hist(d.tally_moderate_hits.loc[high_power_strain_list], bins=bins, density=True, alpha=0.5)\n",
    "\n",
    "d.loc[high_power_strain_list].sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    tally_maybe_hits=maybe_hit.sum(),\n",
    "    sum_gene_ratio=strain_depth[maybe_hit].sum(),\n",
    ")).assign(ratio=lambda x: x.sum_gene_ratio / x.tally_maybe_hits)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "bins = np.linspace(0, 10000, num=21)\n",
    "# sns.kdeplot(reference_hit.sum())\n",
    "# sns.kdeplot(d.tally_moderate_hits)\n",
    "# sns.kdeplot(d.tally_moderate_hits.loc[high_power_strain_list])\n",
    "\n",
    "\n",
    "plt.hist(reference_hit.sum(), bins=bins, density=True, alpha=0.5)\n",
    "# plt.hist(d.tally_moderate_hits, bins=bins, density=True, alpha=0.5)\n",
    "plt.hist(d.tally_maybe_hits.loc[high_power_strain_list], bins=bins, density=True, alpha=0.5)\n",
    "\n",
    "d.loc[high_power_strain_list].sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(dict(\n",
    "    tally_moderate_hits=moderate_hit.sum(),\n",
    "    sum_gene_ratio=strain_depth[moderate_hit].sum(),\n",
    ")).assign(ratio=lambda x: x.sum_gene_ratio / x.tally_moderate_hits)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "bins = np.linspace(0, 10000, num=21)\n",
    "# sns.kdeplot(reference_hit.sum())\n",
    "# sns.kdeplot(d.tally_moderate_hits)\n",
    "# sns.kdeplot(d.tally_moderate_hits.loc[high_power_strain_list])\n",
    "\n",
    "\n",
    "plt.hist(reference_copy_number.sum(\"gene_id\"), bins=bins, density=True, alpha=0.5)\n",
    "# plt.hist(d.sum_gene_ratio, bins=bins, density=True, alpha=0.5)\n",
    "plt.hist(d.sum_gene_ratio.loc[high_power_strain_list], bins=bins, density=True, alpha=0.5)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_high_power_strains = idxwhere(fit.community.data.sel(strain=high_power_strain_list).sum(\"strain\").to_series() > 0.5)\n",
    "samples_without_high_power_strains = idxwhere(fit.community.data.sel(strain=high_power_strain_list).sum(\"strain\").to_series() < 0.5)\n",
    "len(samples_with_high_power_strains), len(samples_without_high_power_strains)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.plot.plot_genotype(\n",
    "    fit,\n",
    "    # col_linkage_func=lambda w: fit.metagenotype.linkage(\"position\"),\n",
    "    # row_linkage_func=lambda w: fit.genotype.linkage(\"strain\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = fit.sel(strain=high_power_strain_list, position=position_ss)\n",
    "w1 = refit.sel(strain=high_power_strain_list, position=position_ss)\n",
    "\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    w0,\n",
    "    row_linkage_func=lambda w: w0.metagenotype.linkage(\"position\"),\n",
    "    col_linkage_func=lambda w: w0.community.linkage(\"sample\"),\n",
    "    scaley=0.0095,\n",
    "    scalex=0.004,\n",
    "    transpose=True,\n",
    "    xticklabels=0,\n",
    ")\n",
    "\n",
    "sf.plot.plot_genotype(\n",
    "    w0,\n",
    "    col_linkage_func=lambda w: w0.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: w1.genotype.linkage(\"strain\"),\n",
    ")\n",
    "\n",
    "sf.plot.plot_genotype(\n",
    "    w1,\n",
    "    col_linkage_func=lambda w: w0.metagenotype.linkage(\"position\"),\n",
    "    row_linkage_func=lambda w: w1.genotype.linkage(\"strain\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w = fit.sel(sample=strain_to_sample_list[131] + strain_to_sample_list[149])\n",
    "sf.plot_metagenotype(w.drop_low_abundance_strains(0.05), scaley=0.01, row_linkage_func=lambda w: w.metagenotype.linkage())\n",
    "sf.plot_genotype(w.drop_low_abundance_strains(0.05), scaley=0.01, transpose=True, col_linkage_func=lambda w: w.metagenotype.linkage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_metagenotype(\n",
    "    fit.sel(sample=samples_with_high_power_strains, position=position_ss).drop_low_abundance_strains(0.05),\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    "    row_linkage_func=lambda w: w.metagenotype.linkage(\"position\"),\n",
    "    col_colors=fit.sel(sample=samples_with_high_power_strains, position=position_ss).sample.to_series().map(sample_to_strain).map(high_power_strain_palette),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot.plot_community(\n",
    "    fit.sel(sample=samples_with_high_power_strains, position=position_ss).drop_low_abundance_strains(0.05),\n",
    "    col_linkage_func=lambda w: w.community.linkage(),\n",
    "    row_linkage_func=lambda w: w.genotype.linkage(\"strain\"),\n",
    "    col_colors=fit.sel(sample=samples_with_high_power_strains, position=position_ss).sample.to_series().map(sample_to_strain).map(high_power_strain_palette),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster = pd.read_table(\n",
    "    path[\"cluster_info\"]\n",
    ").set_index('centroid_99', drop=False).rename_axis(index='gene_id')\n",
    "gene_annotation = pd.read_table(\n",
    "    path[\"gene_annotations\"],\n",
    "    names=['locus_tag', 'ftype', 'length_bp', 'gene', 'EC_number', 'COG', 'product'],\n",
    "    index_col='locus_tag',\n",
    ").rename(columns=str.lower)\n",
    "\n",
    "gene_meta = gene_cluster.loc[gene_cluster[f'centroid_{centroid}'].unique()].join(gene_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cog_meta = pd.read_table(\n",
    "    'ref/cog-20.meta.tsv',\n",
    "    names=['cog', 'categories', 'description', 'gene', 'pathway', '_1', '_2'],\n",
    "    index_col=['cog']\n",
    ")\n",
    "cog_meta = _cog_meta.drop(columns=['categories', '_1', '_2'])\n",
    "cog_x_category = _cog_meta.categories.apply(tuple).apply(pd.Series).unstack().to_frame(name='category').reset_index()[['cog', 'category']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_category = pd.read_table('ref/cog-20.categories.tsv', names=['category', 'description'], index_col='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = idxwhere(moderate_hit[strain_list].sum(1) > 0)\n",
    "\n",
    "x = strain_depth.loc[gene_list, strain_list]\n",
    "\n",
    "# _gene_linkage = sp.cluster.hierarchy.linkage(x, metric='cosine')\n",
    "\n",
    "if len(gene_list) < 2e4:\n",
    "    sns.clustermap(\n",
    "        x,\n",
    "        metric='cosine',\n",
    "        norm=mpl.colors.SymLogNorm(linthresh=1e-4, vmin=0.1, vmax=10),\n",
    "        yticklabels=0,\n",
    "        xticklabels=0,\n",
    "        # row_linkage=_gene_linkage,\n",
    "        col_linkage=fit.genotype.discretized().sel(strain=strain_list).linkage(\"strain\"),\n",
    "    )\n",
    "else:\n",
    "    print(\"Too many genes for clustermap:\", len(gene_list))\n",
    "\n",
    "print(len(gene_list), len(gene_list) - gene_annotation.loc[gene_list]['product'].value_counts()['hypothetical protein'])\n",
    "print()\n",
    "print(\n",
    "    gene_annotation\n",
    "    .loc[gene_list]\n",
    "    .cog.to_frame()\n",
    "    .join(cog_meta, on='cog')\n",
    "    .pathway\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(\n",
    "    gene_meta\n",
    "    .loc[gene_list]\n",
    "    ['product']\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(pd.merge(\n",
    "    gene_annotation.loc[gene_list].cog.dropna().to_frame(),\n",
    "    cog_x_category,\n",
    "    on='cog',\n",
    ").category.value_counts().to_frame().join(cog_category).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = idxwhere(moderate_hit[strain_list].mean(1) > 0.8)\n",
    "\n",
    "x = strain_depth.loc[gene_list, strain_list]\n",
    "\n",
    "_gene_linkage = sp.cluster.hierarchy.linkage(x, metric='cosine')\n",
    "\n",
    "if len(gene_list) < 2e4:\n",
    "    try:\n",
    "        sns.clustermap(\n",
    "            x,\n",
    "            metric='cosine',\n",
    "            norm=mpl.colors.SymLogNorm(linthresh=1e-4, vmin=0.1, vmax=10),\n",
    "            yticklabels=0,\n",
    "            xticklabels=0,\n",
    "            row_linkage=_gene_linkage,\n",
    "            col_linkage=fit.genotype.discretized().sel(strain=strain_list).linkage(\"strain\"),\n",
    "        )\n",
    "    except RecursionError as err:\n",
    "        print(\"Problem with row_linkage?\", err)\n",
    "else:\n",
    "    print(\"Too many genes for clustermap:\", len(gene_list))\n",
    "\n",
    "print(len(gene_list), len(gene_list) - gene_annotation.loc[gene_list]['product'].value_counts()['hypothetical protein'])\n",
    "print()\n",
    "print(\n",
    "    gene_annotation\n",
    "    .loc[gene_list]\n",
    "    .cog.to_frame()\n",
    "    .join(cog_meta, on='cog')\n",
    "    .pathway\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(\n",
    "    gene_meta\n",
    "    .loc[gene_list]\n",
    "    ['product']\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(pd.merge(\n",
    "    gene_annotation.loc[gene_list].cog.dropna().to_frame(),\n",
    "    cog_x_category,\n",
    "    on='cog',\n",
    ").category.value_counts().to_frame().join(cog_category).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = idxwhere((moderate_hit[strain_list].mean(1) > 0.05) & (high_confidence_not_hit[strain_list].mean(1) > 0.2))\n",
    "\n",
    "x = strain_depth.loc[gene_list, strain_list]\n",
    "\n",
    "_gene_linkage = sp.cluster.hierarchy.linkage(x, metric='euclidean')\n",
    "\n",
    "if len(gene_list) < 2e4:\n",
    "    try:\n",
    "        sns.clustermap(\n",
    "            x,\n",
    "            metric='cosine',\n",
    "            norm=mpl.colors.SymLogNorm(linthresh=1e-4, vmin=0.1, vmax=10),\n",
    "            yticklabels=0,\n",
    "            xticklabels=0,\n",
    "            row_linkage=_gene_linkage,  # FIXME: Why does this fail sometimes?\n",
    "            col_linkage=fit.genotype.discretized().sel(strain=strain_list).linkage(\"strain\"),\n",
    "        )\n",
    "    except RecursionError as err:\n",
    "        print(\"Problem with row_linkage?\", err)\n",
    "else:\n",
    "    print(\"Too many genes for clustermap:\", len(gene_list))\n",
    "\n",
    "print(len(gene_list), len(gene_list) - gene_annotation.loc[gene_list]['product'].value_counts()['hypothetical protein'])\n",
    "print()\n",
    "print(\n",
    "    gene_annotation\n",
    "    .loc[gene_list]\n",
    "    .cog.to_frame()\n",
    "    .join(cog_meta, on='cog')\n",
    "    .pathway\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(\n",
    "    gene_meta\n",
    "    .loc[gene_list]\n",
    "    ['product']\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    ")\n",
    "print()\n",
    "print(pd.merge(\n",
    "    gene_annotation.loc[gene_list].cog.dropna().to_frame(),\n",
    "    cog_x_category,\n",
    "    on='cog',\n",
    ").category.value_counts().to_frame().join(cog_category).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = idxwhere((moderate_hit[strain_list].mean(1) > 0.05) & (high_confidence_not_hit[strain_list].mean(1) > 0.2))\n",
    "\n",
    "x = (\n",
    "    moderate_hit.loc[gene_list, strain_list].astype(float) * 3\n",
    "    + (1 - high_confidence_not_hit.loc[gene_list, strain_list].astype(float)) * 2\n",
    ")\n",
    "\n",
    "if len(gene_list) < 2e4:\n",
    "    try:\n",
    "        sns.clustermap(\n",
    "            x,\n",
    "            metric='cosine',\n",
    "            # norm=mpl.colors.SymLogNorm(linthresh=1e-4, vmin=0.1, vmax=10),\n",
    "            yticklabels=0,\n",
    "            xticklabels=0,\n",
    "            row_linkage=_gene_linkage,  # FIXME: Why does this fail sometimes?\n",
    "            col_linkage=fit.genotype.discretized().sel(strain=strain_list).linkage(\"strain\"),\n",
    "            cmap='gray',\n",
    "        )\n",
    "    except RecursionError as err:\n",
    "        print(\"Problem with row_linkage?\", err)\n",
    "else:\n",
    "    print(\"Too many genes for clustermap:\", len(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reference_hit.mean(1)\n",
    "y = moderate_hit[high_power_strain_list].mean(1)\n",
    "\n",
    "_all_genes = list(set(x.index) | set(y.index))\n",
    "\n",
    "x = x.reindex(_all_genes, fill_value=False)\n",
    "y = y.reindex(_all_genes, fill_value=False)\n",
    "\n",
    "plt.scatter(x, y, alpha=0.2, s=1)\n",
    "sp.stats.pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subset with ref_geno look similar to the full set of genomes.\n",
    "\n",
    "x = reference_hit[ref_geno.strain].mean(1)\n",
    "y = reference_hit.mean(1)\n",
    "\n",
    "plt.scatter(x, y, alpha=0.2, s=1)\n",
    "sp.stats.pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reference_hit[ref_geno.strain].mean(1)\n",
    "y = moderate_hit[high_power_strain_list].mean(1)\n",
    "\n",
    "_all_genes = list(set(x.index) | set(y.index))\n",
    "\n",
    "x = x.reindex(_all_genes, fill_value=False)\n",
    "y = y.reindex(_all_genes, fill_value=False)\n",
    "\n",
    "plt.scatter(x, y, alpha=0.2, s=1)\n",
    "sp.stats.pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broad strokes characterization of gene sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylogenetic conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = moderate_hit.index\n",
    "\n",
    "m = gene_meta.join(cog_meta, on='cog', rsuffix='_cog')\n",
    "x = moderate_hit.loc[gene_list, strain_list]\n",
    "\n",
    "fdist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(x.T, metric='jaccard')), index=x.columns, columns=x.columns)\n",
    "gdist = fit.genotype.discretized().sel(strain=strain_list).pdist()\n",
    "\n",
    "d = pd.DataFrame(dict(\n",
    "    genotype_distance=sp.spatial.distance.squareform(gdist),\n",
    "    gene_content_distance=sp.spatial.distance.squareform(fdist)\n",
    "))\n",
    "plt.scatter('genotype_distance', 'gene_content_distance', data=d, s=5)\n",
    "sp.stats.spearmanr(d.genotype_distance, d.gene_content_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "gene_list = idxwhere((moderate_hit[strain_list].mean(1) > 0.05) & (high_confidence_not_hit[strain_list].mean(1) > 0.2))\n",
    "\n",
    "m = gene_meta.join(cog_meta, on='cog', rsuffix='_cog')\n",
    "x = moderate_hit.loc[gene_list, strain_list]\n",
    "\n",
    "fdist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(x.T, metric='jaccard')), index=x.columns, columns=x.columns)\n",
    "gdist = fit.genotype.discretized().sel(strain=strain_list).pdist()\n",
    "\n",
    "d = pd.DataFrame(dict(\n",
    "    genotype_distance=sp.spatial.distance.squareform(gdist),\n",
    "    gene_content_distance=sp.spatial.distance.squareform(fdist)\n",
    "))\n",
    "plt.scatter('genotype_distance', 'gene_content_distance', data=d, s=5)\n",
    "sp.stats.spearmanr(d.genotype_distance, d.gene_content_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_cog_category_reps = pd.merge(\n",
    "    gene_meta.loc[idxwhere(moderate_hit[strain_list].any(1))].cog.value_counts().reset_index().rename(columns=dict(index='cog', cog='tally')),\n",
    "    cog_x_category,\n",
    "    on='cog'\n",
    ").groupby('category').tally.sum().sort_values(ascending=False)\n",
    "tally_cog_category_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 3, figsize=(15, 19), sharex=True, sharey=True)\n",
    "\n",
    "for this_cog_category, ax in zip(tally_cog_category_reps.index, axs.flatten()):\n",
    "    ax.set_title(this_cog_category)\n",
    "    strain_list = high_power_strain_list\n",
    "    cog_list = cog_x_category[cog_x_category.category == this_cog_category].cog.unique()\n",
    "    gene_list = gene_meta.cog.isin(cog_list)\n",
    "\n",
    "    x = moderate_hit.loc[gene_list, strain_list]\n",
    "    fdist = pd.DataFrame(sp.spatial.distance.squareform(sp.spatial.distance.pdist(x.T, metric='jaccard')), index=x.columns, columns=x.columns)\n",
    "\n",
    "    gdist = fit.genotype.discretized().sel(strain=strain_list).pdist()\n",
    "\n",
    "    d = pd.DataFrame(dict(\n",
    "        genotype_distance=sp.spatial.distance.squareform(gdist),\n",
    "        gene_content_distance=sp.spatial.distance.squareform(fdist)\n",
    "    ))\n",
    "    ax.scatter('genotype_distance', 'gene_content_distance', data=d, s=5)\n",
    "    ax.annotate(np.round(sp.stats.spearmanr(d.genotype_distance, d.gene_content_distance)[0], 2), xy=(0.8, 0.9), xycoords='axes fraction')\n",
    "    ax.annotate(int(x.mean(1).sum()), xy=(0.8, 0.7), xycoords='axes fraction')\n",
    "    ax.annotate(cog_category.loc[this_cog_category].description, xy=(0.0, 0.8), xycoords='axes fraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment Analysis in Reference Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reference_hit\n",
    "y = moderate_hit\n",
    "\n",
    "_all_genes = list(set(x.index) | set(y.index))\n",
    "\n",
    "x = x.reindex(_all_genes, fill_value=False)\n",
    "y = y.reindex(_all_genes, fill_value=False)\n",
    "\n",
    "jac_cdist_inf_moderate = pd.DataFrame(sp.spatial.distance.cdist(x.T, y.T, metric='jaccard'), index=x.columns, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_confidence_diff = pd.DataFrame(x[jac_cdist_inf_moderate.idxmin()].values * 2 - y[jac_cdist_inf_moderate.columns].values * 3, index=x.index, columns=y.columns).replace({-3: 'only_inf', -1: 'shared_genes', 0: 'both_lacking', 2: 'only_ref'})\n",
    "moderate_confidence_diff.apply(lambda x: x.value_counts())[high_power_strain_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reference_hit\n",
    "y = high_confidence_hit\n",
    "\n",
    "_all_genes = list(set(x.index) | set(y.index))\n",
    "\n",
    "x = x.reindex(_all_genes, fill_value=False)\n",
    "y = y.reindex(_all_genes, fill_value=False)\n",
    "\n",
    "jac_cdist_inf_confident = pd.DataFrame(sp.spatial.distance.cdist(x.T, y.T, metric='jaccard'), index=x.columns, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confidence_diff = pd.DataFrame(x[jac_cdist_inf_confident.idxmin()].values * 2 - y[jac_cdist_inf_confident.columns].values * 3, index=x.index, columns=y.columns).replace({-3: 'only_inf', -1: 'shared_genes', 0: 'both_lacking', 2: 'only_ref'})\n",
    "high_confidence_diff.apply(lambda x: x.value_counts())[high_power_strain_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_geno_pdist = ref_geno.pdist()\n",
    "ref_hits_pdist = pd.DataFrame(\n",
    "    sp.spatial.distance.squareform(sp.spatial.distance.pdist(reference_hit[ref_geno.strain].T, metric='jaccard')),\n",
    "    index=ref_geno_pdist.index,\n",
    "    columns=ref_geno_pdist.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sp.spatial.distance.squareform(ref_geno_pdist)\n",
    "y = sp.spatial.distance.squareform(ref_hits_pdist)\n",
    "plt.scatter(x, y, alpha=0.1, s=1)\n",
    "# plt.xscale('symlog', linthresh=1e-3, linscale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_cdist_to_ref = pd.DataFrame(sf.math.genotype_cdist(fit.genotype.discretized().values, ref_geno.values), index=fit.strain, columns=ref_geno.strain)\n",
    "geno_cdist_to_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_cdist_to_ref = pd.DataFrame(sp.spatial.distance.cdist(moderate_hit.reindex(reference_hit.index, fill_value=False).T, reference_hit[ref_geno.strain].T, metric='jaccard'), index=moderate_hit.columns, columns=ref_geno.strain)\n",
    "hits_cdist_to_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_only_hits_cdist_to_ref = pd.DataFrame(sp.spatial.distance.cdist(depth_hit.reindex(reference_hit.index, fill_value=False).T, reference_hit[ref_geno.strain].T, metric='jaccard'), index=moderate_hit.columns, columns=ref_geno.strain)\n",
    "depth_only_hits_cdist_to_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_geno_cdist, _hits_cdist, _depth_hits_cdist = align_indexes(geno_cdist_to_ref, hits_cdist_to_ref, depth_only_hits_cdist_to_ref)\n",
    "\n",
    "best_match_inf_geno = _geno_cdist.idxmin(1)\n",
    "best_match_inf_geno_diss = {}\n",
    "best_match_inf_hits_diss = {}\n",
    "best_match_depth_inf_hits_diss = {}\n",
    "for s in _geno_cdist.index:\n",
    "    best_match_inf_geno_diss[s] = _geno_cdist.loc[s, best_match_inf_geno[s]]\n",
    "    best_match_inf_hits_diss[s] = _hits_cdist.loc[s, best_match_inf_geno[s]]\n",
    "    best_match_depth_inf_hits_diss[s] = _depth_hits_cdist.loc[s, best_match_inf_geno[s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_geno_cdist, _hits_cdist = (ref_geno_pdist + np.eye(ref_geno_pdist.shape[0])), (ref_hits_pdist + np.eye(ref_hits_pdist.shape[0]))\n",
    "\n",
    "best_match_ref_geno = _geno_cdist.idxmin(1)\n",
    "# By adding 1 to the diagonal, we should make the best match NOT itself.\n",
    "assert not (best_match_ref_geno.index.to_series() == best_match_ref_geno).any()\n",
    "\n",
    "best_match_ref_geno_diss = {}\n",
    "best_match_ref_hits_diss = {}\n",
    "for s in _geno_cdist.index:\n",
    "    best_match_ref_geno_diss[s] = _geno_cdist.loc[s, best_match_ref_geno[s]]\n",
    "    best_match_ref_hits_diss[s] = _hits_cdist.loc[s, best_match_ref_geno[s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inf_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_inf_geno_diss,\n",
    "    hits=best_match_inf_hits_diss,\n",
    "    depth_hits=best_match_depth_inf_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "))\n",
    "\n",
    "d_ref_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_ref_geno_diss,\n",
    "    hits=best_match_ref_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "))\n",
    "\n",
    "d_all_by_all = pd.DataFrame(dict(\n",
    "    geno=sp.spatial.distance.squareform(ref_geno_pdist),\n",
    "    hits=sp.spatial.distance.squareform(ref_hits_pdist),\n",
    "))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "xbins = np.logspace(-3, 0, num=101)\n",
    "ybins = np.linspace(0, 1.0, num=101)\n",
    "plt.hist2d('geno', 'hits', data=d_all_by_all, bins=(xbins, ybins), norm=mpl.colors.SymLogNorm(linthresh=1), cmap=mpl.cm.Greys)\n",
    "plt.colorbar()\n",
    "plt.xscale('symlog', linthresh=1e-3, linscale=0.2)\n",
    "# plt.scatter('geno', 'hits', data=d_ref_to_ref, s=20)\n",
    "# plt.scatter('geno', 'hits', data=d_inf_to_ref.loc[high_power_strain_list], s=20)\n",
    "\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inf_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_inf_geno_diss,\n",
    "    hits=best_match_inf_hits_diss,\n",
    "    depth_hits=best_match_depth_inf_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "    genotype_entropy=strain_meta.genotype_entropy,\n",
    "    genotype_refit_entropy=strain_meta.genotype_refit_entropy,\n",
    "))\n",
    "\n",
    "d_ref_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_ref_geno_diss,\n",
    "    hits=best_match_ref_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "))\n",
    "\n",
    "d_all_by_all = pd.DataFrame(dict(\n",
    "    geno=sp.spatial.distance.squareform(ref_geno_pdist),\n",
    "    hits=sp.spatial.distance.squareform(ref_hits_pdist),\n",
    "))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "xbins = np.logspace(-3, 0, num=101)\n",
    "ybins = np.linspace(0, 1.0, num=101)\n",
    "plt.hist2d('geno', 'hits', data=d_all_by_all, bins=(xbins, ybins), norm=mpl.colors.SymLogNorm(linthresh=1), cmap=mpl.cm.Greys)\n",
    "plt.colorbar()\n",
    "plt.xscale('symlog', linthresh=1e-3, linscale=0.2)\n",
    "plt.scatter('geno', 'hits', data=d_ref_to_ref, s=20, color='tab:blue')\n",
    "# plt.scatter('geno', 'depth_hits', data=d_inf_to_ref.loc[high_power_strain_list], s=40, color='tab:purple')\n",
    "plt.scatter('geno', 'hits', data=d_inf_to_ref.loc[high_power_strain_list], s=40, c='genotype_refit_entropy', cmap=mpl.cm.YlOrRd_r)\n",
    "\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inf_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_inf_geno_diss,\n",
    "    hits=best_match_inf_hits_diss,\n",
    "    depth_hits=best_match_depth_inf_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "    genotype_entropy=strain_meta.genotype_entropy,\n",
    "    genotype_refit_entropy=strain_meta.genotype_refit_entropy,\n",
    "))\n",
    "\n",
    "d_ref_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_ref_geno_diss,\n",
    "    hits=best_match_ref_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "))\n",
    "\n",
    "d_all_by_all = pd.DataFrame(dict(\n",
    "    geno=sp.spatial.distance.squareform(ref_geno_pdist),\n",
    "    hits=sp.spatial.distance.squareform(ref_hits_pdist),\n",
    "))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "xbins = np.linspace(0, 1.0, num=101)\n",
    "ybins = np.linspace(0, 1.0, num=101)\n",
    "plt.hist2d('geno', 'hits', data=d_all_by_all, bins=(xbins, ybins), norm=mpl.colors.SymLogNorm(linthresh=1), cmap=mpl.cm.Greys)\n",
    "plt.colorbar()\n",
    "plt.scatter('geno', 'hits', data=d_ref_to_ref, s=20, color='tab:blue')\n",
    "# plt.scatter('geno', 'depth_hits', data=d_inf_to_ref.loc[high_power_strain_list], s=40, color='tab:purple')\n",
    "plt.scatter('geno', 'hits', data=d_inf_to_ref.loc[high_power_strain_list], s=40, c='genotype_refit_entropy', cmap=mpl.cm.YlOrRd_r)\n",
    "\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inf_to_ref = pd.DataFrame(dict(\n",
    "    geno=best_match_inf_geno_diss,\n",
    "    hits=best_match_inf_hits_diss,\n",
    "    depth_hits=best_match_depth_inf_hits_diss,\n",
    "    power_index=strain_meta.power_index,\n",
    "    genotype_entropy=strain_meta.genotype_entropy,\n",
    "    genotype_refit_entropy=strain_meta.genotype_refit_entropy,\n",
    "))\n",
    "\n",
    "plt.scatter('hits', 'depth_hits', data=d_inf_to_ref, c='genotype_refit_entropy', cmap=mpl.cm.YlOrRd_r)\n",
    "plt.colorbar()\n",
    "plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sf.Genotype.concat(dict(\n",
    "    ref=ref_geno.sel(strain=best_match_inf_geno.unique()),\n",
    "    fit=refit.genotype.sel(strain=high_power_strain_list),\n",
    "), dim='strain')\n",
    "sf.plot_genotype(g.sel(position=position_ss), row_linkage_func=lambda w: w.genotype.discretized().linkage(\"strain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_similarity_scores(pdist_matrix, binary_matrix, pdist_transformation=np.sqrt):\n",
    "    x = binary_matrix.astype(float) * 2 - 1  # Shift and scale the binary matrix so it spans -1 to +1.\n",
    "    reciprocal_transformed_pdist = np.nan_to_num(1 / pdist_transformation(pdist_matrix), posinf=0, neginf=0)\n",
    "    return np.sum(\n",
    "        (\n",
    "            np.einsum('ab,bc->acb', x.T, x)\n",
    "            * np.expand_dims(reciprocal_transformed_pdist, -1)\n",
    "        ),\n",
    "        (0, 1),\n",
    "    )\n",
    "\n",
    "def null_pairwise_similarity_scores(pdist_matrix, n_permutations=10_000, pdist_transformation=np.sqrt):\n",
    "    nstrains = pdist_matrix.shape[0]    \n",
    "    # Construct a matrix, where gene i (1-indexed) has i strains with that binary\n",
    "    # feature (a lower triangular matrix works for this)\n",
    "    unpermuted_x = np.tri(nstrains + 1, M=nstrains, k=-1)\n",
    "    \n",
    "    # Use permutations of this matrix to constuct the nulls, parameterized\n",
    "    # by the number of strains.\n",
    "    null_scores = []\n",
    "    for i in range(n_permutations):\n",
    "        x = unpermuted_x[:, np.random.choice(np.arange(nstrains), size=nstrains, replace=False)]\n",
    "        null_scores.append(pairwise_similarity_scores(pdist_matrix, x, pdist_transformation=pdist_transformation))\n",
    "    return pd.DataFrame(null_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(null_pairwise_similarity_scores(gdist, n_permutations=100).mean())\n",
    "plt.plot(null_pairwise_similarity_scores(gdist, n_permutations=100, pdist_transformation=lambda x: x).mean())\n",
    "plt.plot(null_pairwise_similarity_scores(gdist, n_permutations=100, pdist_transformation=lambda x: x**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_list = high_power_strain_list\n",
    "nstrains = len(strain_list)\n",
    "gdist = refit.genotype.sel(strain=strain_list).pdist().values\n",
    "n_permutations = 1_000\n",
    "# Slow if n_permutations is much higher than 10_000\n",
    "permutation_scores = null_pairwise_similarity_scores(gdist, n_permutations=n_permutations, pdist_transformation=np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "for i in permutation_scores.columns:\n",
    "    if i / nstrains <= 0.5:\n",
    "        ax = axs[0]\n",
    "    else:\n",
    "        ax = axs[1]\n",
    "    sns.kdeplot(permutation_scores[i], c=mpl.cm.coolwarm(i / nstrains), ax=ax)\n",
    "    \n",
    "# for i in permutation_scores.columns:\n",
    "#     plt.plot([], [], color=mpl.cm.coolwarm(i / nstrains), label=i)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = idxwhere((moderate_hit[strain_list].sum(1) > 0) & (moderate_hit[strain_list].sum(1) < (nstrains)))\n",
    "hits = moderate_hit.loc[gene_list, strain_list]\n",
    "scores = pd.Series(pairwise_similarity_scores(gdist, hits, pdist_transformation=np.sqrt), index=hits.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations_to_pvalues(empirical_scores, key, permutation_scores, decimals=100, test='two-sided'):\n",
    "    n_permutations = permutation_scores.shape[0]\n",
    "    \n",
    "    # NOTE: I may need to round to some number of decimals for numerical reasons.\n",
    "    empirical_scores = np.round(empirical_scores, decimals=decimals)\n",
    "    permutation_scores = np.round(permutation_scores, decimals=decimals)\n",
    "\n",
    "    pvalues = []\n",
    "    for k, score_empir in zip(key, empirical_scores):\n",
    "        scores_perm = permutation_scores[k]\n",
    "        # Got some tips on how to calculate p-values from <https://stats.stackexchange.com/a/25929>\n",
    "        if test == 'two-sided':\n",
    "            p = ((np.abs(scores_perm) >= abs(score_empir)).sum() + 1) / (n_permutations + 1)\n",
    "        elif test == 'lower':\n",
    "            p = ((np.abs(scores_perm) <= min(score_empir, -score_empir)).sum() + 1) / (n_permutations + 1)\n",
    "        elif test == 'higher':\n",
    "            p = ((np.abs(scores_perm) >= max(score_empir, -score_empir)).sum() + 1) / (n_permutations + 1)\n",
    "        else:\n",
    "            raise ValueError(f\"`test` parameter must be one of ['two-sided', 'left', 'right'], not '{test}'.\")\n",
    "        pvalues.append(p)\n",
    "    return pd.Series(pvalues, empirical_scores.index)\n",
    "    \n",
    "pvalues = permutations_to_pvalues(scores, hits.sum(1), permutation_scores, decimals=4, test='two-sided')\n",
    "\n",
    "# pvalues_old = []\n",
    "# decimals = 4\n",
    "# for n, s in tqdm(list(zip(hits.sum(1), scores))):\n",
    "#     # NOTE: I need to round to some number of decimals for numerical reasons.\n",
    "#     scores_perm = np.round(permutation_scores[n], decimals=decimals)\n",
    "#     scores_empir = np.round(s, decimals=decimals)\n",
    "#     # Got some tips on how to calculate p-values from <https://stats.stackexchange.com/a/25929>\n",
    "#     # Choose one:\n",
    "#     # p_left = ((permutation_scores[n] <= min(s, -s)).sum() + 1) / (n_permutations + 1)\n",
    "#     # p_right = ((permutation_scores[n] >= max(s, -s)).sum() + 1) / (n_permutations + 1)\n",
    "#     p_ts = ((np.abs(scores_perm) >= abs(scores_empir)).sum() + 1) / (n_permutations + 1)\n",
    "#     pvalues_old.append(p_ts)\n",
    "# pvalues_old = pd.Series(pvalues_old, scores.index)\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pvalues.sort_values().values)\n",
    "plt.yscale('logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_scores = hits.sum(1).map(permutation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_scores = scores - expected_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pvalues, bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    adjusted_scores,\n",
    "    -np.log10(pvalues),\n",
    "    s=5,\n",
    "    c=hits.sum(1),\n",
    "    cmap=mpl.cm.viridis,\n",
    "    # alpha=0.1\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.axvline(0, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gene_list = idxwhere((pvalues < 1e-2))\n",
    "print(len(_gene_list))\n",
    "x = hits.loc[_gene_list]\n",
    "s = adjusted_scores.loc[_gene_list]\n",
    "vrange = max(s.max(), -s.min())\n",
    "c = (s + vrange) / (vrange * 2)\n",
    "\n",
    "sns.clustermap(x, col_linkage=refit.genotype.sel(strain=strain_list).linkage(), row_colors=mpl.cm.coolwarm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 1, num=len(pvalues)), pvalues.sort_values().values)\n",
    "plt.plot([0, 1], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gene_list = idxwhere((pvalues > 1e-1))\n",
    "print(len(_gene_list))\n",
    "x = hits.loc[_gene_list]\n",
    "s = adjusted_scores.loc[_gene_list]\n",
    "vrange = max(s.max(), -s.min())\n",
    "c = (s + vrange) / (vrange * 2)\n",
    "\n",
    "sns.clustermap(x, col_linkage=refit.genotype.sel(strain=strain_list).linkage(), row_colors=mpl.cm.coolwarm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_strain_list = list(best_match_inf_geno.unique())\n",
    "nstrains = len(ref_strain_list)\n",
    "ref_gdist = ref_geno_pdist.loc[ref_strain_list, ref_strain_list]\n",
    "n_permutations = 10_000\n",
    "# Slow if n_permutations is much higher than 10_000\n",
    "ref_permutation_scores = null_pairwise_similarity_scores(ref_gdist, n_permutations=n_permutations, pdist_transformation=np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, sharex=True, sharey=True)\n",
    "for i in ref_permutation_scores.columns:\n",
    "    if i / nstrains <= 0.5:\n",
    "        ax = axs[0]\n",
    "    else:\n",
    "        ax = axs[1]\n",
    "    sns.kdeplot(ref_permutation_scores[i], c=mpl.cm.coolwarm(i / nstrains), ax=ax)\n",
    "    \n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "# for i in permutation_scores.columns:\n",
    "#     plt.plot([], [], color=mpl.cm.coolwarm(i / nstrains), label=i)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = reference_hit.loc[gene_list, ref_strain_list]\n",
    "ref_scores = pd.Series(pairwise_similarity_scores(ref_gdist, hits, pdist_transformation=np.sqrt), index=hits.index)\n",
    "ref_pvalues = permutations_to_pvalues(ref_scores, hits.sum(1), ref_permutation_scores, decimals=4, test='two-sided')\n",
    "\n",
    "ref_expected_scores = hits.sum(1).map(ref_permutation_scores.mean())\n",
    "ref_adjusted_scores = ref_scores - ref_expected_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    ref_adjusted_scores,\n",
    "    -np.log10(ref_pvalues),\n",
    "    s=5,\n",
    "    c=hits.sum(1),\n",
    "    cmap=mpl.cm.viridis,\n",
    "    # alpha=0.1\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.axvline(0, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ref_adjusted_scores, adjusted_scores, s=2, alpha=0.5)\n",
    "sp.stats.spearmanr(ref_adjusted_scores, adjusted_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hits = reference_hit.loc[gene_list, ref_strain_list]\n",
    "\n",
    "for i in np.arange(nstrains + 1):\n",
    "    sns.kdeplot(ref_adjusted_scores[hits.sum(1) == i])\n",
    "    plt.yscale('log')\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gene_list = idxwhere((ref_pvalues < 1e-2))\n",
    "print(len(_gene_list))\n",
    "x = hits.loc[_gene_list]\n",
    "s = ref_adjusted_scores.loc[_gene_list]\n",
    "vrange = max(s.max(), -s.min())\n",
    "c = (s + vrange) / (vrange * 2)\n",
    "\n",
    "sns.clustermap(x, col_linkage=ref_geno.sel(strain=ref_strain_list).genotype.linkage(), row_colors=mpl.cm.coolwarm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = set(idxwhere(pvalues < 1e-2))\n",
    "ref_hits = set(idxwhere(ref_pvalues < 1e-2))\n",
    "\n",
    "len(hits), len(ref_hits), len(hits & ref_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annotation.loc[list(hits & ref_hits)].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
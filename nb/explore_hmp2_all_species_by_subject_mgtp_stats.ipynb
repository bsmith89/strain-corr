{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfacts as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import scipy as sp\n",
    "from operator import eq\n",
    "from itertools import cycle\n",
    "from lib.pandas_util import idxwhere\n",
    "import lib.plot\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen = pd.read_table('meta/hmp2/mgen.tsv', index_col='library_id')\n",
    "preparation = pd.read_table('meta/hmp2/preparation.tsv', index_col='preparation_id')\n",
    "stool = pd.read_table('meta/hmp2/stool.tsv', index_col='stool_id')\n",
    "visit = pd.read_table('meta/hmp2/visit.tsv', index_col='visit_id')\n",
    "subject = pd.read_table('meta/hmp2/subject.tsv', index_col='subject_id')\n",
    "\n",
    "meta_all = (\n",
    "    mgen\n",
    "    .join(preparation.drop(columns='library_type'), on='preparation_id')\n",
    "    .join(stool, on='stool_id')\n",
    "    .join(visit, on='visit_id', rsuffix='_')\n",
    "    .join(subject, on='subject_id')\n",
    "    .assign(new_name=lambda x: (\n",
    "        x[['subject_id', 'week_number']]\n",
    "        .assign(library_id=x.index)\n",
    "        .assign(week_number=lambda x: x.week_number.fillna(999).astype(int))\n",
    "        .apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    ))\n",
    "    # .reset_index()\n",
    "    # .set_index('new_name')\n",
    ")\n",
    "\n",
    "library_id_to_new_name = meta_all.new_name\n",
    "\n",
    "assert not any(meta_all.subject_id.isna())\n",
    "\n",
    "# TODO: Rename samples based on subject and visit number\n",
    "# TODO: Drop duplicate stools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = (\n",
    "    pd.read_table(\"meta/species_group.tsv\")[\n",
    "        lambda x: x.species_group_id == \"hmp2\"\n",
    "    ]\n",
    "    .species_id.astype(str)\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "missing_species = []\n",
    "for species_id in species_list:\n",
    "    inpath = f'data/group/hmp2/species/sp-{species_id}/r.proc.gtpro.filt-poly05-cvrg05.mgtp.nc'\n",
    "    if not os.path.exists(inpath):\n",
    "        missing_species.append(species_id)\n",
    "        continue\n",
    "    mgtp1 = sf.Metagenotype.load(inpath)\n",
    "    # mgtp1.data['sample'] = library_id_to_new_name.loc[mgtp1.sample].to_list()\n",
    "    meta1 = meta_all.loc[mgtp1.sample]\n",
    "\n",
    "    heterogeneity_stats1 = {}\n",
    "    for subject_id in meta1.subject_id.unique():\n",
    "        sample_list = idxwhere(meta1.sort_values('week_number').subject_id == subject_id)\n",
    "        mgtp2 = mgtp1.sel(sample=sample_list)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            heterogeneity_stats1[subject_id] = dict(\n",
    "                num_samples = len(sample_list),\n",
    "                mean_pairwise_mgen_diss = np.mean(sp.spatial.distance.squareform(mgtp2.pdist())),\n",
    "                mean_entropy = ((mgtp2.entropy() * mgtp2.mean_depth()).sum() / mgtp2.mean_depth().sum()).values,\n",
    "                mean_squared_entropy = ((mgtp2.entropy().pipe(np.square) * mgtp2.mean_depth()).sum() / mgtp2.mean_depth().sum()).values,\n",
    "                mean_depth = mgtp2.mean_depth().values.mean(),\n",
    "            )\n",
    "\n",
    "    heterogeneity_stats1 = pd.DataFrame(heterogeneity_stats1).T.assign(\n",
    "        multiple_samples=lambda x: x.num_samples > 1,\n",
    "        probable_strain_heterogeneity=lambda x: x.mean_entropy > 0.025,\n",
    "        probable_strain_transition=lambda x: x.mean_pairwise_mgen_diss > 0.1,\n",
    "        species_id=species_id\n",
    "    )\n",
    "    all_stats.append(heterogeneity_stats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = pd.concat(all_stats).rename_axis(index='subject_id').reset_index().set_index(['species_id', 'subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_stats[lambda x: x.multiple_samples].groupby(['species_id', 'probable_strain_heterogeneity']).apply(len).to_frame(name='tally').reset_index().set_index(['species_id', 'probable_strain_heterogeneity']).tally.unstack(fill_value=0).assign(num=lambda x: x[False] + x[True]).assign(het_frac=lambda x: x[True] / x.num).rename(columns={True: 'het', False: 'nohet'})\n",
    "d2 = all_stats[lambda x: x.multiple_samples].groupby(['species_id', 'probable_strain_transition']).apply(len).to_frame(name='tally').reset_index().set_index(['species_id', 'probable_strain_transition']).tally.unstack(fill_value=0).assign(num=lambda x: x[False] + x[True]).assign(trans_frac=lambda x: x[True] / x.num).rename(columns={True: 'trans', False: 'notrans'})\n",
    "\n",
    "d = d1.join(d2[['notrans', 'trans', 'trans_frac']])\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(60, 10), sharex=True)\n",
    "d[d.num > 5].sort_values('num', ascending=False)[['het', 'nohet']].plot.bar(stacked=True, ax=axs[0])\n",
    "d[d.num > 5].sort_values('num', ascending=False)[['trans', 'notrans']].plot.bar(stacked=True, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('het_frac', 'trans_frac', data=d, c='num')\n",
    "sns.regplot('het_frac', 'trans_frac', data=d, scatter=False, lowess=True)\n",
    "plt.xscale('logit')\n",
    "plt.yscale('logit')\n",
    "print(sp.stats.spearmanr(d['het_frac'], d['trans_frac']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102478'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "print(_mgtp.sizes)\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    _mgtp.random_sample(position=min(_mgtp.sizes['position'], 500)),\n",
    "    col_linkage_func=lambda w: w.metagenotype.linkage(),\n",
    "    col_colors_func=lambda w: w.metagenotype.entropy() > 0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102517'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "print(_mgtp.sizes)\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    _mgtp.random_sample(position=min(_mgtp.sizes['position'], 500)),\n",
    "    col_linkage_func=lambda w: _mgtp.linkage(),\n",
    "    col_colors_func=lambda w: _mgtp.entropy() > 0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102327'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "print(_mgtp.sizes)\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    _mgtp.random_sample(position=min(_mgtp.sizes['position'], 500)),\n",
    "    col_linkage_func=lambda w: _mgtp.linkage(),\n",
    "    col_colors_func=lambda w: _mgtp.entropy() > 0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy = pd.read_table('ref/gtpro/species_taxonomy_ext.tsv', names=['genome_id', 'species_id', 'taxonomy_string']).assign(species_id=lambda x: x.species_id.astype(str)).set_index('species_id')[['taxonomy_string']].assign(taxonomy_split=lambda x: x.taxonomy_string.str.split(';'))\n",
    "\n",
    "for level_name, level_number in [('p__', 1), ('c__', 2), ('o__', 3), ('f__', 4), ('g__', 5), ('s__', 6)]:\n",
    "    species_taxonomy = species_taxonomy.assign(**{level_name: species_taxonomy.taxonomy_split.apply(lambda x: x[level_number])}) \n",
    "species_taxonomy = species_taxonomy.drop(columns=['taxonomy_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy.loc[all_stats.index.get_level_values('species_id').unique()]['p__'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_stats[lambda x: x.multiple_samples].groupby(['species_id', 'probable_strain_heterogeneity']).apply(len).to_frame(name='tally').reset_index().set_index(['species_id', 'probable_strain_heterogeneity']).tally.unstack(fill_value=0).assign(num=lambda x: x[False] + x[True]).assign(het_frac=lambda x: x[True] / x.num).rename(columns={True: 'het', False: 'nohet'})\n",
    "d2 = all_stats[lambda x: x.multiple_samples].groupby(['species_id', 'probable_strain_transition']).apply(len).to_frame(name='tally').reset_index().set_index(['species_id', 'probable_strain_transition']).tally.unstack(fill_value=0).assign(num=lambda x: x[False] + x[True]).assign(trans_frac=lambda x: x[True] / x.num).rename(columns={True: 'trans', False: 'notrans'})\n",
    "\n",
    "d = (\n",
    "    d1\n",
    "    .join(d2[['notrans', 'trans', 'trans_frac']])\n",
    "    .join(species_taxonomy)\n",
    "    # [lambda x: x.taxonomy_string.str.startswith('d__Bacteria;p__Firmicutes_A')]\n",
    "    .sort_values(['p__', 'num'])\n",
    "    .reset_index().assign(species_and_tax=lambda x: x.species_id + '_' + x.p__).set_index('species_and_tax')\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(60, 10), sharex=True)\n",
    "d[d.num > 5][['het', 'nohet']].plot.bar(stacked=True, ax=axs[0])\n",
    "d[d.num > 5][['trans', 'notrans']].plot.bar(stacked=True, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '103682'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "_mgtp.data['sample'] = library_id_to_new_name.loc[_mgtp.sample].to_list()\n",
    "print(_mgtp.sizes)\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    _mgtp.random_sample(position=min(_mgtp.sizes['position'], 500)).mlift('sortby', 'sample'),\n",
    "    col_linkage_func=lambda w: _mgtp.linkage(),\n",
    "    col_colors_func=lambda w: _mgtp.entropy() > 0.05,\n",
    "    col_cluster=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_by_species_stats = (\n",
    "    all_stats\n",
    "     .reset_index()\n",
    "     .rename(columns=dict(\n",
    "         num_samples='num_mgtp_samples',\n",
    "         mean_pairwise_mgen_diss='mean_pairwise_mgtp_diss',\n",
    "         mean_entropy='mean_mgtp_entropy',\n",
    "         mean_depth='mean_mgtp_depth',\n",
    "     ))\n",
    "    .drop(columns=[\n",
    "        'multiple_samples',\n",
    "        'probable_strain_heterogeneity',\n",
    "        'probable_strain_transition',\n",
    "        'mean_squared_entropy',\n",
    "    ])\n",
    ")\n",
    "\n",
    "subject_by_species_stats.to_csv('data/hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.subject_by_species_stats.tsv', sep='\\t', index=False)\n",
    "subject_by_species_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_by_species_stats = pd.read_table(\n",
    "    'data/hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.subject_by_species_stats.tsv',\n",
    "    dtype=dict(species_id=str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_depth_uncleaned = pd.read_table(\n",
    "    'data/hmp2.a.r.proc.gtpro.species_depth.tsv',\n",
    "    dtype=dict(sample=str, species_id=str, depth=float)\n",
    ").rename(columns=dict(sample='library_id')).set_index(['library_id', 'species_id']).depth.unstack(fill_value=0)\n",
    "species_depth = species_depth_uncleaned.drop(idxwhere(species_depth_uncleaned.sum(1) < 100))\n",
    "species_rabund = species_depth.divide(species_depth.sum(1), axis=0)\n",
    "species_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_depth_uncleaned = pd.read_table(\n",
    "    'data/hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts18-s75-seed0.clean-diss05-abund05-entr100.strain_depth.tsv',\n",
    "    dtype=dict(sample=str, strain=str, depth=float)\n",
    ").rename(columns=dict(sample='library_id')).set_index(['library_id', 'strain']).depth.unstack(fill_value=0)\n",
    "strain_depth = strain_depth_uncleaned.drop(idxwhere(strain_depth_uncleaned.sum(1) < 100))\n",
    "strain_rabund = strain_depth.divide(strain_depth.sum(1), axis=0)\n",
    "strain_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_genome_length = pd.read_table('ref_temp/midasdb_uhgg.metadata.tsv', dtype=dict(species_id=str, Length=int), index_col='species_id').rename(columns={'Length': 'genome_length'}).genome_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    species_depth_uncleaned\n",
    "    .sum(1)\n",
    "    .to_frame('total_species_depth')\n",
    "    .join(mgen.sequenced_reads)\n",
    "    .assign(expect_total_sequence=(species_depth_uncleaned * species_genome_length).fillna(0).sum(1))\n",
    ")\n",
    "plt.scatter('sequenced_reads', 'expect_total_sequence', data=d, s=1)\n",
    "plt.plot([0, 1e7], [0, 1e7 * 95])\n",
    "sp.stats.pearsonr(d.sequenced_reads, d.total_species_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mgtp_samples_matrix = subject_by_species_stats.set_index(['subject_id', 'species_id']).num_mgtp_samples.unstack(fill_value=0)\n",
    "num_depth_samples_matrix = (species_depth > 0.05).groupby(meta_all.subject_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_subject_prevalence = (species_depth > 0.05).groupby(meta_all.subject_id).any().sum().sort_values(ascending=False)\n",
    "most_prevalent_species = idxwhere((species_subject_prevalence > 85))\n",
    "len(most_prevalent_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = subject_by_species_stats.join(meta_all.groupby('subject_id')['ibd_diagnosis'].first(), on='subject_id')\n",
    "sns.boxplot(\n",
    "    x='species_id',\n",
    "    y='mean_mgtp_entropy',\n",
    "    hue='ibd_diagnosis',\n",
    "    data=d0[d0.species_id.isin(most_prevalent_species)]\n",
    ")\n",
    "lib.plot.rotate_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = subject_by_species_stats.join(meta_all.groupby('subject_id')['ibd_diagnosis'].first(), on='subject_id')\n",
    "d1 = d0[d0.species_id == '102492']\n",
    "sp.stats.mannwhitneyu(\n",
    "    d1[d1.ibd_diagnosis == 'nonIBD'].mean_mgtp_entropy.astype(float).dropna(),\n",
    "    d1[d1.ibd_diagnosis != 'nonIBD'].mean_mgtp_entropy.astype(float).dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = 'ibd_diagnosis'\n",
    "\n",
    "d0 = subject_by_species_stats.join(meta_all.groupby('subject_id')[feat].first() != 'nonIBD', on='subject_id')\n",
    "d1 = d0[d0.species_id == '102492']\n",
    "\n",
    "sns.boxplot(\n",
    "    x='species_id',\n",
    "    y='mean_mgtp_entropy',\n",
    "    hue=feat,\n",
    "    data=d1,\n",
    ")\n",
    "lib.plot.rotate_xticklabels()\n",
    "\n",
    "lib.stats.mannwhitneyu(feat, 'mean_mgtp_entropy', data=d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_taxonomy.loc['102492']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = subject.assign(mean_rabund_102492=species_rabund.groupby(meta_all.subject_id).mean()['102492']).join(subject_by_species_stats[lambda x: x.species_id == '102492'].set_index('subject_id'))\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "sns.boxplot('ibd_diagnosis', 'mean_rabund_102492', data=d, ax=axs[0])\n",
    "sns.boxplot('ibd_diagnosis', 'mean_mgtp_entropy', data=d, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102492'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "_mgtp.data['sample'] = library_id_to_new_name.loc[_mgtp.sample].to_list()\n",
    "print(_mgtp.sizes)\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    _mgtp.random_sample(position=min(_mgtp.sizes['position'], 500)).mlift('sortby', 'sample'),\n",
    "    col_linkage_func=lambda w: _mgtp.linkage(),\n",
    "    col_colors_func=lambda w: _mgtp.entropy() > 0.05,\n",
    "    col_cluster=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102492'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "d = _mgtp.entropy().to_series().to_frame().join(meta_all)\n",
    "plt.hist(d[~d.status_antibiotics].entropy, density=True)\n",
    "plt.hist(d[d.status_antibiotics].entropy, density=True)\n",
    "\n",
    "lib.stats.mannwhitneyu('status_antibiotics', 'entropy', data=d)\n",
    "# sns.stripplot('status_antibiotics', 'entropy', data=d, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fit = sf.World.load('data_temp/sp-102492.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts27-s75-seed0.world.nc')\n",
    "\n",
    "\n",
    "d = pd.DataFrame(dict(mgtp_entropy=_fit.metagenotype.entropy(), comm_entropy=_fit.community.entropy(), mgtp_depth=_fit.metagenotype.mean_depth()))\n",
    "plt.scatter('mgtp_entropy', 'comm_entropy', data=d, s=5, c='mgtp_depth', norm=mpl.colors.LogNorm())\n",
    "sns.regplot('mgtp_entropy', 'comm_entropy', data=d, scatter=False)\n",
    "\n",
    "# plt.yscale('symlog', linthresh=1e-5)\n",
    "# plt.xscale('symlog', linthresh=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.mannwhitneyu(d1[d1[feat] == False].mean_mgtp_entropy, d1[d1[feat] == True].mean_mgtp_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = subject_by_species_stats.set_index(['subject_id', 'species_id']).mean_pairwise_mgtp_diss.astype(float).unstack().fillna(0)\n",
    "sns.clustermap(d[most_prevalent_species] + 1e-5, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = subject_by_species_stats.set_index(['subject_id', 'species_id']).mean_mgtp_entropy.astype(float).unstack().fillna(0)\n",
    "sns.clustermap(d[most_prevalent_species] + 1e-5, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = subject_by_species_stats.set_index(['subject_id', 'species_id']).mean_pairwise_mgtp_diss.to_frame().join(subject_by_species_stats.set_index(['subject_id', 'species_id']).mean_mgtp_entropy).dropna()\n",
    "plt.scatter('mean_mgtp_entropy', 'mean_pairwise_mgtp_diss', data=d.xs('100022', level='species_id'), s=1)\n",
    "plt.xscale('symlog', linthresh=1e-5)\n",
    "plt.yscale('symlog', linthresh=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "r = strain_rabund\n",
    "all_strain_bc_diss = pd.DataFrame(squareform(pdist(r, metric='braycurtis')), index=r.index, columns=r.index)\n",
    "all_strain_jc_diss = pd.DataFrame(squareform(pdist(r, metric='jaccard')), index=r.index, columns=r.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "r = species_rabund\n",
    "all_species_bc_diss = pd.DataFrame(squareform(pdist(r, metric='braycurtis')), index=r.index, columns=r.index)\n",
    "all_species_jc_diss = pd.DataFrame(squareform(pdist(r, metric='jaccard')), index=r.index, columns=r.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = meta_all['subject_id'].to_frame()\n",
    "diff_subj = pd.DataFrame(squareform(pdist(m, metric=lambda x, y: x != y)), index=m.index, columns=m.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102492'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "mgtp_102492_diss = _mgtp.pdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '102506'\n",
    "_mgtp = sf.Metagenotype.load(f'data/sp-{species_id}.hmp2.a.r.proc.gtpro.filt-poly05-cvrg05.mgen.nc')\n",
    "mgtp_102506_diss = _mgtp.pdist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_strain_bc_diss\n",
    "y = mgtp_102492_diss\n",
    "z = diff_subj.astype(bool)\n",
    "\n",
    "idx = list(set(x.index) & set(y.index) & set(z.index))\n",
    "d = pd.DataFrame(dict(\n",
    "    x=squareform(x.loc[idx, idx]),\n",
    "    y=squareform(y.loc[idx, idx]),\n",
    "    z=squareform(z.loc[idx, idx]),\n",
    "))\n",
    "\n",
    "plt.scatter('x', 'y', data=d, s=1, c='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_strain_bc_diss\n",
    "y = mgtp_102506_diss\n",
    "z = diff_subj.astype(bool)\n",
    "\n",
    "idx = list(set(x.index) & set(y.index) & set(z.index))\n",
    "d = pd.DataFrame(dict(\n",
    "    x=squareform(x.loc[idx, idx]),\n",
    "    y=squareform(y.loc[idx, idx]),\n",
    "    z=squareform(z.loc[idx, idx]),\n",
    "))\n",
    "\n",
    "plt.scatter('x', 'y', data=d, s=1, c='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_strain_bc_diss\n",
    "y = mgtp_102506_diss\n",
    "z = diff_subj.astype(bool)\n",
    "\n",
    "idx = list(set(x.index) & set(y.index) & set(z.index))\n",
    "d = pd.DataFrame(dict(\n",
    "    x=squareform(x.loc[idx, idx]),\n",
    "    y=squareform(y.loc[idx, idx]),\n",
    "    z=squareform(z.loc[idx, idx]),\n",
    "))\n",
    "\n",
    "\n",
    "bins = np.linspace(0, 1.4, num=51)\n",
    "plt.hist(d.y[d.z], bins=bins, label='diff')\n",
    "plt.hist(d.y[~d.z], bins=bins, label='same', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_strain_bc_diss\n",
    "y = mgtp_102492_diss\n",
    "z = diff_subj.astype(bool)\n",
    "\n",
    "idx = list(set(x.index) & set(y.index) & set(z.index))\n",
    "d = pd.DataFrame(dict(\n",
    "    x=squareform(x.loc[idx, idx]),\n",
    "    y=squareform(y.loc[idx, idx]),\n",
    "    z=squareform(z.loc[idx, idx]),\n",
    "))\n",
    "\n",
    "\n",
    "bins = np.linspace(0, 1.4, num=51)\n",
    "plt.hist(d.y[d.z], bins=bins, label='diff')\n",
    "plt.hist(d.y[~d.z], bins=bins, label='same', alpha=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_species_bc_diss\n",
    "y = all_strain_bc_diss\n",
    "z = diff_subj.astype(bool)\n",
    "\n",
    "idx = list(set(x.index) & set(y.index) & set(z.index))\n",
    "d = pd.DataFrame(dict(\n",
    "    x=squareform(x.loc[idx, idx]),\n",
    "    y=squareform(y.loc[idx, idx]),\n",
    "    z=squareform(z.loc[idx, idx]),\n",
    "))\n",
    "\n",
    "plt.scatter('x', 'y', data=d, s=1, c='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfacts",
   "language": "python",
   "name": "sfacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
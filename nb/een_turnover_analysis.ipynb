{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir(_os.environ[\"PROJECT_ROOT\"])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import chain, product\n",
    "from tempfile import mkstemp\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sfacts as sf\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.plot\n",
    "import lib.thisproject.data\n",
    "from lib.pandas_util import align_indexes, aligned_index, idxwhere, invert_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\")\n",
    "plt.rcParams[\"figure.dpi\"] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_2tailed_pvalue_from_perm(obs, perms):\n",
    "    hypoth_left = perms > obs\n",
    "    hypoth_right = perms < obs\n",
    "    null_p_left = (hypoth_left.sum() + 1) / (len(hypoth_left) + 1)\n",
    "    null_p_right = (hypoth_right.sum() + 1) / (len(hypoth_right) + 1)\n",
    "    return np.minimum(null_p_left, null_p_right) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkage_order(linkage, labels):\n",
    "    return labels[sp.cluster.hierarchy.to_tree(linkage).pre_order(lambda x: x.id)]\n",
    "\n",
    "\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def iterate_primes_up_to(n, return_index=False):\n",
    "    n = int(np.ceil(n))\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        if is_prime(i):\n",
    "            if return_index:\n",
    "                yield (idx, i)\n",
    "            else:\n",
    "                yield i\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def maximally_shuffled_order(sorted_order):\n",
    "    n = len(sorted_order)\n",
    "    primes_list = list(iterate_primes_up_to(np.sqrt(n)))\n",
    "    table = pd.DataFrame(np.arange(n), index=sorted_order, columns=[\"original_order\"])\n",
    "    for prime in primes_list:\n",
    "        table[prime] = table.original_order % prime\n",
    "    table.sort_values(primes_list).original_order.values\n",
    "    table = table.assign(new_order=table.sort_values(primes_list).original_order.values)\n",
    "    z = table.sort_values(\"new_order\").original_order.values\n",
    "    table[\"delta\"] = [np.nan] + list(z[1:] - z[:-1])\n",
    "    return table.sort_values(\"new_order\").index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Metadata"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOTE: If I decide that it's the filenames that are wrong, then I need to swap labels in the metagenomic results (including sfacts worlds and\n",
    "# species relative abundances).\n",
    "\n",
    "SAMPLE_SWAP_CORRECTION = {\n",
    "    # CF_667 through CF_672 should actually be labeled CF_531 - CF_537\n",
    "    'CF_667': 'CF_531',\n",
    "    'CF_668': 'CF_532',\n",
    "    'CF_669': 'CF_533',\n",
    "    'CF_670': 'CF_534',\n",
    "    'CF_671': 'CF_535',\n",
    "    'CF_672': 'CF_536',\n",
    "\n",
    "    # CF_11 <-> CF_15\n",
    "    'CF_11': 'CF_15',\n",
    "    'CF_15': 'CF_11',\n",
    "\n",
    "    # Some/half of the newly shared samples\n",
    "    CF_379\n",
    "    CF_380\n",
    "    CF_381\n",
    "    CF_384\n",
    "    CF_385\n",
    "    CF_386\n",
    "    CF_426\n",
    "    CF_427\n",
    "    CF_428\n",
    "    CF_429\n",
    "    CF_430\n",
    "    CF_431\n",
    "    CF_395\n",
    "    CF_397\n",
    "    CF_402\n",
    "    CF_406\n",
    "    CF_409\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_type_palette={'Transition': 'plum', 'EEN': 'pink', 'PostEEN': 'lightblue'}\n",
    "\n",
    "diet_palette = {\n",
    "    \"EEN\": \"lightgreen\",\n",
    "    \"PostEEN\": \"lightblue\",\n",
    "    \"InVitro\": \"plum\",\n",
    "    \"PreEEN\": \"lightpink\",\n",
    "}\n",
    "\n",
    "subject_order = [\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"H\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "]\n",
    "\n",
    "# NOTE: Requires a dummy value because I want exactly 20 items.\n",
    "subject_palette = lib.plot.construct_ordered_palette(\n",
    "    subject_order + [f\"dummy{i}\" for i in range(20 - len(subject_order))], cm=\"tab20\"\n",
    ")\n",
    "subject_palette[\"X\"] = \"black\"\n",
    "pair_type_order = [\"EEN\", \"Transition\", \"PostEEN\"]\n",
    "pair_type_marker_palette = {\"EEN\": \"s\", \"Transition\": \">\", \"PostEEN\": \"o\"}\n",
    "pair_type_linestyle_palette = {\"EEN\": \":\", \"Transition\": \"-.\", \"PostEEN\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (\n",
    "    pd.read_table(\"meta/een-mgen/sample.tsv\")\n",
    "    .assign(\n",
    "        label=lambda x: x[\n",
    "            [\"collection_date_relative_een_end\", \"diet_or_media\", \"sample_id\"]\n",
    "        ].apply(tuple, axis=1)\n",
    "    )\n",
    "    .set_index(\"sample_id\")\n",
    ")\n",
    "subject = pd.read_table(\"meta/een-mgen/subject.tsv\", index_col=\"subject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotu_counts = pd.read_table(\n",
    "    \"data/group/een/a.proc.zotu_counts.tsv\", index_col=\"#OTU ID\"\n",
    ").rename_axis(index=\"zotu\", columns=\"sample_id\")\n",
    "rotu_taxonomy = rotu_counts.taxonomy\n",
    "rotu_counts = rotu_counts.drop(columns=[\"taxonomy\"]).T\n",
    "rotu_rabund = rotu_counts.divide(rotu_counts.sum(1), axis=0)\n",
    "\n",
    "sample_rotu_bc_linkage = sp.cluster.hierarchy.linkage(\n",
    "    rotu_rabund, method=\"average\", metric=\"braycurtis\", optimal_ordering=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_samples = sorted(idxwhere(~rotu_counts.index.to_series().isin(sample.index)))\n",
    "print(len(missing_samples), \", \".join(missing_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rotu_rabund\n",
    "row_colors = pd.DataFrame(\n",
    "    dict(\n",
    "        subj=sample.subject_id.map(subject_palette),\n",
    "        swap=sample.index.to_series()\n",
    "        .isin([\"CF_11\", \"CF_15\"])\n",
    "        .replace({False: \"grey\", True: \"black\"}),\n",
    "    )\n",
    ")\n",
    "row_linkage = sample_rotu_bc_linkage\n",
    "\n",
    "sns.clustermap(\n",
    "    rotu_rabund,\n",
    "    norm=mpl.colors.PowerNorm(1 / 5),\n",
    "    row_colors=row_colors,\n",
    "    row_linkage=row_linkage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(\n",
    "    \"data/group/een/r.proc.gtpro.species_depth.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtpro_depth = (pd.read_table(\n",
    "    \"data/group/een/r.proc.gtpro.species_depth.tsv\",\n",
    "    index_col=['sample', \"species_id\"],\n",
    "    )\n",
    "    .depth.unstack(fill_value=0)\n",
    "    .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .rename({'CF_15': 'CF_11', 'CF_11': 'CF_15'})  # Sample swap\n",
    ")\n",
    "gtpro_rabund = gtpro_depth.divide(gtpro_depth.sum(1), axis=0)\n",
    "\n",
    "gtpro_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_depth = (pd.read_table(\n",
    "    \"data/group/een/r.proc.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    "    names=['sample', \"species_id\", 'depth'], index_col=['sample', \"species_id\"],\n",
    "    )\n",
    "    .depth.unstack(fill_value=0)\n",
    "    .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .rename({'CF_15': 'CF_11', 'CF_11': 'CF_15'})  # Sample swap\n",
    ")\n",
    "motu_rabund = motu_depth.divide(motu_depth.sum(1), axis=0)\n",
    "\n",
    "motu_rabund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = align_indexes(motu_rabund, rotu_rabund)\n",
    "\n",
    "\n",
    "x_linkage = linkage(x, method=\"average\", metric=\"braycurtis\", optimal_ordering=True)\n",
    "y_linkage = linkage(y, method=\"average\", metric=\"braycurtis\", optimal_ordering=True)\n",
    "colors = pd.DataFrame(\n",
    "    dict(\n",
    "        subj=sample.subject_id.map(subject_palette),\n",
    "        swap=sample.index.to_series()\n",
    "        .isin([\"CF_11\", \"CF_15\"])\n",
    "        .replace({False: \"grey\", True: \"black\"}),\n",
    "    )\n",
    ")\n",
    "\n",
    "x_pdist = pd.DataFrame(\n",
    "    squareform(pdist(x, metric=\"braycurtis\")), index=x.index, columns=x.index\n",
    ")\n",
    "sns.clustermap(\n",
    "    x_pdist,\n",
    "    row_linkage=y_linkage,\n",
    "    col_linkage=x_linkage,\n",
    "    row_colors=colors,\n",
    "    col_colors=colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = align_indexes(motu_rabund, gtpro_rabund)\n",
    "\n",
    "\n",
    "x_linkage = linkage(x, method=\"average\", metric=\"braycurtis\", optimal_ordering=True)\n",
    "y_linkage = linkage(y, method=\"average\", metric=\"braycurtis\", optimal_ordering=True)\n",
    "colors = pd.DataFrame(\n",
    "    dict(\n",
    "        subj=sample.subject_id.map(subject_palette),\n",
    "        swap=sample.index.to_series()\n",
    "        .isin([\"CF_11\", \"CF_15\"])\n",
    "        .replace({False: \"grey\", True: \"black\"}),\n",
    "    )\n",
    ")\n",
    "\n",
    "x_pdist = pd.DataFrame(\n",
    "    squareform(pdist(x, metric=\"braycurtis\")), index=x.index, columns=x.index\n",
    ")\n",
    "sns.clustermap(\n",
    "    x_pdist,\n",
    "    row_linkage=y_linkage,\n",
    "    col_linkage=x_linkage,\n",
    "    row_colors=colors,\n",
    "    col_colors=colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 30_000, num=200)\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True)\n",
    "\n",
    "for (title, x), ax in zip(\n",
    "    dict(\n",
    "        total_depth_by_sample=motu_depth.sum(1),\n",
    "        total_depth_by_species=motu_depth.sum(0),\n",
    "    ).items(),\n",
    "    axs.flatten(),\n",
    "):\n",
    "    ax.hist(x, bins=np.logspace(-1, 5, num=100))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xscale(\"log\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_rabund.mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = 10\n",
    "top_motus = (\n",
    "    (motu_rabund > 1e-5).sum().sort_values(ascending=False).head(n_species).index\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    n_species, figsize=(5, 0.3 * n_species), sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "bins = np.logspace(-8, 1, num=51)\n",
    "\n",
    "for species_id, ax in zip(top_motus, axs):\n",
    "    # ax.hist(rabund_subset[species_id], bins=bins, alpha=0.7)\n",
    "    ax.hist(motu_rabund[species_id], bins=bins, alpha=0.7)\n",
    "    ax.set_xscale(\"log\")\n",
    "    prevalence = (motu_rabund[species_id] > 1e-5).mean()\n",
    "    ax.set_title(\"\")\n",
    "    # ax.set_xticks()\n",
    "    # ax.set_yticks()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    for spine in [\"left\", \"right\", \"top\", \"bottom\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.annotate(\n",
    "        f\"{species_id} ({prevalence:0.0%})\",\n",
    "        xy=(0.05, 0.1),\n",
    "        ha=\"left\",\n",
    "        xycoords=\"axes fraction\",\n",
    "    )\n",
    "    ax.set_xlim(left=1e-9)\n",
    "    ax.set_ylim(top=20)\n",
    "    ax.axvline(1e-5, lw=1, linestyle=\":\", color=\"k\")\n",
    "\n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines[\"bottom\"].set_visible(True)\n",
    "ax.set_xticks([1e-4, 1e-2, 1e-0])\n",
    "ax.set_xticklabels([\"0.01%\", \"1%\", \"100%\"])\n",
    "ax.set_xlabel(\"Relative Abundance\")\n",
    "\n",
    "# fig.subplots_adjust(hspace=-0.75)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motu_taxonomy = lib.thisproject.data.load_species_taxonomy(\n",
    "    \"ref/gtpro/species_taxonomy_ext.tsv\"\n",
    ")\n",
    "# motu_taxonomy.loc[\"102506\", \"s__\"] = \"s__Escherichia coli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_taxonomy_string(taxonomy_string):\n",
    "    values = taxonomy_string.split(\";\")\n",
    "    return pd.Series(values, index=[\"d__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\", \"s__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_taxonomy_inpath = \"ref/uhgg_genomes_all_v2.tsv\"\n",
    "\n",
    "_motu_taxonomy = (\n",
    "    pd.read_table(motu_taxonomy_inpath)[lambda x: x.Genome == x.Species_rep]\n",
    "    .assign(species_id=lambda x: \"1\" + x.MGnify_accession.str.split(\"-\").str[2])\n",
    "    .set_index(\"species_id\")\n",
    ")\n",
    "\n",
    "# motu_lineage_string = _motu_taxonomy.Lineage\n",
    "\n",
    "motu_taxonomy = _motu_taxonomy.Lineage.apply(\n",
    "    parse_taxonomy_string\n",
    ")  # .assign(taxonomy_string=motu_lineage_string)\n",
    "motu_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _species_id in top_motus.astype(str):\n",
    "    print(_species_id, \":\", \";\".join(motu_taxonomy.loc[_species_id].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_depth = []\n",
    "missing_files = []\n",
    "for species_id in motu_depth.columns:\n",
    "    path = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.comm.tsv\"\n",
    "    try:\n",
    "        d = (\n",
    "            pd.read_table(path, index_col=[\"sample\", \"strain\"])\n",
    "            .squeeze()\n",
    "            .unstack()\n",
    "            .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "            .rename({'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap.\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        missing_files.append(path)\n",
    "        d = pd.DataFrame([])\n",
    "    _keep_strains = idxwhere(d.sum() > 0.05)\n",
    "    assert d.index.isin(motu_depth.index).all()\n",
    "    d = d.reindex(index=motu_depth.index, columns=_keep_strains, fill_value=0)\n",
    "    d = d.assign(__other=lambda x: 1 - x.sum(1)).rename(columns={\"__other\": -1})\n",
    "    d[d < 0] = 0\n",
    "    d = d.divide(d.sum(1), axis=0)\n",
    "    d = d.multiply(motu_depth[species_id], axis=0)\n",
    "    d = d.rename(columns=lambda s: f\"{species_id}_{s}\")\n",
    "    sotu_depth.append(d)\n",
    "sotu_depth = pd.concat(sotu_depth, axis=1)\n",
    "sotu_rabund = sotu_depth.divide(sotu_depth.sum(1), axis=0)\n",
    "len(motu_depth.columns), len(missing_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Test Prototype #3\n",
    "\n",
    "This permutation test differs from earlier versions in that\n",
    "- it permutes the pair labels,\n",
    "- it fits a cubic spline (with 4 knots) to the time data\n",
    "- it's run on the compositional data (instead of metagenomics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnover_analysis3(\n",
    "    _rabund,\n",
    "    _meta,\n",
    "    _rabund_ctrl=None,  # e.g. control for species-level turnover\n",
    "    pair_type_palette=pair_type_palette,\n",
    "    pair_type_marker_palette=pair_type_marker_palette,\n",
    "    pair_type_linestyle_palette=pair_type_linestyle_palette,\n",
    "    subject_palette=subject_palette,\n",
    "    subject_order=subject_order,\n",
    "    pair_type_order=pair_type_order,\n",
    "    _dmat=None,\n",
    "    n_perm=999,\n",
    "):\n",
    "    # Select data\n",
    "    _rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "    # Calculate pairwise comparisons\n",
    "    if _dmat is None:\n",
    "        _dmat = pdist(_rabund, metric=\"braycurtis\")\n",
    "        if _rabund_ctrl is not None:\n",
    "            # NOTE: bc stands for bray-curtis and is used as a stand-in for\n",
    "            # dissimilarity throughout because\n",
    "            # the default is to use bc dissimilarity.\n",
    "            bc_cdist_ctrl = pdist(_rabund_ctrl.loc[_rabund.index], metric='braycurtis')\n",
    "            _dmat = _dmat - bc_cdist_ctrl\n",
    "    else:\n",
    "        assert _rabund_ctrl is None\n",
    "        assert _dmat.shape[0] == _rabund.shape[0]\n",
    "        assert _dmat.shape[1] == _rabund.shape[0]\n",
    "        _dmat = squareform(_dmat)\n",
    "        # But it's the users responsibility to sort the dmat correctly.\n",
    "\n",
    "    time_cdist = pdist(\n",
    "        _meta[[\"collection_date_relative_een_end\"]], metric=lambda x, y: np.abs(x - y)\n",
    "    )\n",
    "    depth_min_cdist = pdist(_meta[['depth']], metric=lambda x, y: min(x, y))\n",
    "    diff_subject_cdist = pdist(_meta[[\"subject_id\"]], metric=lambda x, y: x != y)\n",
    "    same_subject_cdist = (1 - diff_subject_cdist).astype(bool)\n",
    "    type_transition_indicator = pdist(\n",
    "        _meta[[\"diet_or_media\"]],\n",
    "        metric=lambda x, y: (x == \"PostEEN\").astype(float)\n",
    "        + (y == \"PostEEN\").astype(float),\n",
    "    )\n",
    "    # same_type_cdist = (1 - diff_type_cdist).astype(bool)\n",
    "    pairs = (\n",
    "        pd.DataFrame(\n",
    "            squareform(diff_subject_cdist),\n",
    "            index=_meta.index,\n",
    "            columns=_meta.index,\n",
    "        )\n",
    "        .rename_axis(index=\"sampleA\", columns=\"sampleB\")\n",
    "        .unstack()\n",
    "        .index.to_frame()\n",
    "        .assign(pair=lambda x: x[[\"sampleA\", \"sampleB\"]].apply(tuple, axis=1))\n",
    "        .pair.unstack()\n",
    "    )\n",
    "    pairs = pd.Series(pairs.values[np.triu_indices_from(pairs.values, k=1)])\n",
    "    d0 = pd.DataFrame(\n",
    "        dict(\n",
    "            sampleA=pairs.str[0],\n",
    "            sampleB=pairs.str[1],\n",
    "            bc=_dmat,  # Really this should be generic for any dissimilarity, not only BC.\n",
    "            same_subject=same_subject_cdist,\n",
    "            type_transition_indicator=type_transition_indicator,\n",
    "            diff_type=type_transition_indicator == 1,\n",
    "            time_delta=time_cdist,\n",
    "            depth_min=depth_min_cdist,\n",
    "        )\n",
    "    ).assign(\n",
    "        pair_type=lambda x: x.type_transition_indicator.map(\n",
    "            {0: \"EEN\", 1: \"Transition\", 2: \"PostEEN\"}\n",
    "        ),\n",
    "        subject_id=lambda x: x.sampleA.map(_meta.subject_id),\n",
    "        subject_id_other=lambda x: x.sampleB.map(_meta.subject_id),\n",
    "    )\n",
    "    d1 = d0[lambda x: x.same_subject]\n",
    "\n",
    "    # Plot and observed relationship\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    ax = axs[0]\n",
    "    sns.boxenplot(\n",
    "        y=\"bc\",\n",
    "        x=\"same_subject\",\n",
    "        hue=\"pair_type\",\n",
    "        data=d0,\n",
    "        ax=ax,\n",
    "        palette=pair_type_palette,\n",
    "        order=[False, True],\n",
    "        hue_order=pair_type_order,\n",
    "    )\n",
    "    # ax.legend()\n",
    "    ax = axs[1]\n",
    "    sns.stripplot(\n",
    "        y=\"bc\",\n",
    "        x=\"pair_type\",\n",
    "        hue=\"subject_id\",\n",
    "        data=d1,\n",
    "        ax=ax,\n",
    "        palette=subject_palette,\n",
    "        order=pair_type_order,\n",
    "    )\n",
    "    ax.legend_.set_visible(False)\n",
    "\n",
    "    # Fit observed relationship\n",
    "    # formula = \"bc ~ 0 + C(pair_type) + cr(time_delta, 4) + C(subject_id, Sum) + cr(depth_min, 4)\"\n",
    "    formula = \"bc ~ 0 + C(pair_type) + cr(time_delta, 4) + C(subject_id, Sum)\"\n",
    "    fit = smf.ols(formula, data=d1).fit()\n",
    "    observed_stat = fit.params\n",
    "    observed_stat[\"PostEEN - EEN\"] = (\n",
    "        observed_stat[\"C(pair_type)[PostEEN]\"] - observed_stat[\"C(pair_type)[EEN]\"]\n",
    "    )\n",
    "    observed_stat[\"Transition - EEN\"] = (\n",
    "        observed_stat[\"C(pair_type)[Transition]\"] - observed_stat[\"C(pair_type)[EEN]\"]\n",
    "    )\n",
    "    observed_stat[\"Transition - PostEEN\"] = (\n",
    "        observed_stat[\"C(pair_type)[Transition]\"]\n",
    "        - observed_stat[\"C(pair_type)[PostEEN]\"]\n",
    "    )\n",
    "    print(observed_stat[[\"Transition - EEN\", \"Transition - PostEEN\", \"PostEEN - EEN\"]])\n",
    "\n",
    "    # Calculate permutations\n",
    "    np.random.seed(1)\n",
    "    perm_stat = {}\n",
    "    for i in tqdm(range(n_perm)):\n",
    "        # Permute sample-pair labels within subjects\n",
    "        _perm_type = (\n",
    "            d0.assign(mgen_id=lambda x: x.index)\n",
    "            .groupby(\"subject_id\")\n",
    "            .pair_type.transform(np.random.permutation)\n",
    "        )\n",
    "        perm_fit = smf.ols(\n",
    "            formula,\n",
    "            data=d0.assign(\n",
    "                pair_type=_perm_type,\n",
    "            )[lambda x: x.same_subject],\n",
    "        ).fit()\n",
    "        _stat = perm_fit.params\n",
    "        _stat[\"PostEEN - EEN\"] = (\n",
    "            _stat[\"C(pair_type)[PostEEN]\"] - _stat[\"C(pair_type)[EEN]\"]\n",
    "        )\n",
    "        _stat[\"Transition - EEN\"] = (\n",
    "            _stat[\"C(pair_type)[Transition]\"] - _stat[\"C(pair_type)[EEN]\"]\n",
    "        )\n",
    "        _stat[\"Transition - PostEEN\"] = (\n",
    "            _stat[\"C(pair_type)[Transition]\"] - _stat[\"C(pair_type)[PostEEN]\"]\n",
    "        )\n",
    "        perm_stat[i] = _stat\n",
    "    perm_stat = pd.DataFrame(perm_stat).T\n",
    "\n",
    "    perm_pvalues = _calculate_2tailed_pvalue_from_perm(observed_stat, perm_stat)\n",
    "\n",
    "    fig, axs = plt.subplots(3)\n",
    "    # Plot permutation tests\n",
    "    ax = axs[0]\n",
    "    param_name = \"Transition - EEN\"\n",
    "    ax.set_title(param_name)\n",
    "    ax.hist(perm_stat[param_name], bins=20)\n",
    "    ax.axvline(observed_stat[param_name])\n",
    "    ax.annotate(\n",
    "        perm_pvalues[param_name],\n",
    "        xy=(0.95, 0.95),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax = axs[1]\n",
    "    param_name = \"Transition - PostEEN\"\n",
    "    ax.set_title(param_name)\n",
    "    ax.hist(perm_stat[param_name], bins=20)\n",
    "    ax.axvline(observed_stat[param_name])\n",
    "    hypoth = perm_stat[param_name] > observed_stat[param_name]\n",
    "    null_p = (hypoth.sum() + 1) / (len(hypoth) + 1)\n",
    "    ax.annotate(\n",
    "        perm_pvalues[param_name],\n",
    "        xy=(0.95, 0.95),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax = axs[2]\n",
    "    param_name = \"PostEEN - EEN\"\n",
    "    ax.set_title(param_name)\n",
    "    ax.hist(perm_stat[param_name], bins=20)\n",
    "    ax.axvline(observed_stat[param_name])\n",
    "    hypoth = perm_stat[param_name] > observed_stat[param_name]\n",
    "    null_p = (hypoth.sum() + 1) / (len(hypoth) + 1)\n",
    "    ax.annotate(\n",
    "        perm_pvalues[param_name],\n",
    "        xy=(0.95, 0.95),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "\n",
    "    d2 = d1.assign(\n",
    "        # predict=fit.predict(),\n",
    "        # predict_mean_subject=fit.predict(d1.assign(subject_id=_arbitrary_subject))\n",
    "        # - fit.params[f\"C(subject_id, Sum)[S.{_arbitrary_subject}]\"],\n",
    "        resid_pearson=fit.resid_pearson,\n",
    "        influence=fit.get_influence().summary_frame().cooks_d,\n",
    "    ).sort_values(\"time_delta\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    art = ax.scatter(\n",
    "        \"time_delta\",\n",
    "        \"resid_pearson\",\n",
    "        c=\"influence\",\n",
    "        data=d2,\n",
    "    )\n",
    "    fig.colorbar(art, label=\"Cook's D\")\n",
    "    # ax.set_ylabel(\"Residual BC\\n(standardized)\")\n",
    "    ax.set_xlabel(\"Within-Subjects Days between Samples\")\n",
    "    ax.set_xscale(\"symlog\")\n",
    "\n",
    "    fit.summary()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Within-subject Pairwise Turnover\")\n",
    "    for pair_type in pair_type_order:\n",
    "        d3 = d1[lambda x: (x.pair_type == pair_type)]\n",
    "        ax.scatter(\n",
    "            \"time_delta\",\n",
    "            \"bc\",\n",
    "            label=\"__nolegend__\",\n",
    "            color=pair_type_palette[pair_type],\n",
    "            data=d3,\n",
    "            marker=pair_type_marker_palette[pair_type],\n",
    "            edgecolor='grey', lw=0.5,\n",
    "        )\n",
    "\n",
    "    _arbitrary_subject = d1.subject_id.unique()[1]\n",
    "    predict_data = pd.DataFrame(\n",
    "        product(\n",
    "            [_arbitrary_subject],\n",
    "            [\"EEN\", \"PostEEN\", \"Transition\"],\n",
    "            np.logspace(1.0, 2.6),\n",
    "            [1.0]\n",
    "        ),\n",
    "        columns=[\"subject_id\", \"pair_type\", \"time_delta\", \"depth_min\"],\n",
    "    )\n",
    "    predict_data = predict_data.assign(\n",
    "        prediction=fit.predict(predict_data),\n",
    "        predict_mean_subject=lambda x: x.prediction\n",
    "        - fit.params[f\"C(subject_id, Sum)[S.{_arbitrary_subject}]\"],\n",
    "    )\n",
    "    for pair_type in pair_type_order:\n",
    "        d4 = predict_data[lambda x: x.pair_type == pair_type]\n",
    "        left, right = d1[lambda x: x.pair_type == pair_type].time_delta.quantile(\n",
    "            [0.05, 0.95]\n",
    "        )\n",
    "        ax.plot(\n",
    "            \"time_delta\",\n",
    "            \"predict_mean_subject\",\n",
    "            label=\"__nolegend__\",\n",
    "            data=d4[lambda x: (x.time_delta > left) & (x.time_delta < right)],\n",
    "            color='black',\n",
    "            linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        )\n",
    "    ax.set_ylabel(\"Pairwise Dissimilarity\")\n",
    "    ax.set_xlabel(\"Days between Samples\")\n",
    "    ax.set_xscale(\"symlog\", linthresh=1e-1)\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(2.5, 1.5))\n",
    "    for pair_type in pair_type_order:\n",
    "        ax.plot(\n",
    "            [],\n",
    "            [],\n",
    "            label=pair_type,\n",
    "            color=pair_type_palette[pair_type],\n",
    "            marker=pair_type_marker_palette[pair_type],\n",
    "            linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        )\n",
    "    ax.legend()\n",
    "\n",
    "    d2 = d1.assign(\n",
    "        predict=fit.predict(),\n",
    "        predict_mean_subject=fit.predict(d1.assign(subject_id=_arbitrary_subject))\n",
    "        - fit.params[f\"C(subject_id, Sum)[S.{_arbitrary_subject}]\"],\n",
    "        resid_pearson=fit.resid_pearson,\n",
    "        influence=fit.get_influence().summary_frame().cooks_d,\n",
    "    ).sort_values(\"time_delta\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Within-subject Pairwise Turnover\")\n",
    "    for subject_id, pair_type in product(subject_order, pair_type_order):\n",
    "        d3 = d2[lambda x: (x.subject_id == subject_id) & (x.pair_type == pair_type)]\n",
    "        ax.scatter(\n",
    "            \"time_delta\",\n",
    "            \"bc\",\n",
    "            label=\"__nolegend__\",\n",
    "            color=subject_palette[subject_id],\n",
    "            data=d3,\n",
    "            marker=pair_type_marker_palette[pair_type],\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "    predict_data = pd.DataFrame(\n",
    "        product(\n",
    "            [_arbitrary_subject],\n",
    "            [\"EEN\", \"PostEEN\", \"Transition\"],\n",
    "            np.logspace(1.1, 2.6),\n",
    "            [1.0],\n",
    "        ),\n",
    "        columns=[\"subject_id\", \"pair_type\", \"time_delta\", \"depth_min\"],\n",
    "    )\n",
    "    predict_data = predict_data.assign(\n",
    "        prediction=fit.predict(predict_data),\n",
    "        predict_mean_subject=lambda x: x.prediction\n",
    "        - fit.params[f\"C(subject_id, Sum)[S.{_arbitrary_subject}]\"],\n",
    "    )\n",
    "\n",
    "    for pair_type in pair_type_order:\n",
    "        d4 = predict_data[lambda x: x.pair_type == pair_type]\n",
    "        left, right = d1[lambda x: x.pair_type == pair_type].time_delta.quantile(\n",
    "            [0.05, 0.95]\n",
    "        )\n",
    "        ax.plot(\n",
    "            \"time_delta\",\n",
    "            \"predict_mean_subject\",\n",
    "            label=\"__nolegend__\",\n",
    "            data=d4[lambda x: (x.time_delta > left) & (x.time_delta < right)],\n",
    "            color=\"black\",\n",
    "            linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        )\n",
    "    ax.set_ylabel(\"Bray-Curtis Dissimilarity\")\n",
    "    ax.set_xlabel(\"Days between Samples\")\n",
    "    ax.set_xscale(\"symlog\", linthresh=1e-1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 2))\n",
    "    # Legends\n",
    "    for subject_id in subject_order:\n",
    "        ax.scatter(\n",
    "            [], [], label=subject_id, color=subject_palette[subject_id], marker=\"s\"\n",
    "        )\n",
    "    ax.legend(ncols=5, title=\"Subject\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(2.5, 1.5))\n",
    "    for pair_type in pair_type_order:\n",
    "        ax.plot(\n",
    "            [],\n",
    "            [],\n",
    "            label=pair_type,\n",
    "            color=\"black\",\n",
    "            marker=pair_type_marker_palette[pair_type],\n",
    "            linestyle=pair_type_linestyle_palette[pair_type],\n",
    "        )\n",
    "    ax.legend()\n",
    "    return fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metagenomic Species Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_analysis3(\n",
    "    _rabund=motu_rabund,\n",
    "    _meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zOTU Species Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_analysis3(\n",
    "    _rabund=rotu_rabund,\n",
    "    _meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zOTU Species Turnover using Generalized Unifrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmat_gunifrac = pd.read_excel('raw/een-mgen/2023-09-28_deborah.haecker@tum-create.edu.sg/distance-matrix-gunif_Byron.xlsx', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = rotu_rabund\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "_rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "_dmat = dmat_gunifrac.loc[_meta.index, _meta.index]\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    "    _dmat=_dmat,\n",
    "    n_perm=999,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zOTU Species Turnover (but same samples as Metagenomic Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_analysis3(\n",
    "    _rabund=rotu_rabund.loc[motu_rabund.index],\n",
    "    _meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zOTU Species Turnover using Generalized Unifrac (but same samples as Metagenomic Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rabund = rotu_rabund.loc[motu_rabund.index]\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "_rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "_dmat = dmat_gunifrac.loc[_meta.index, _meta.index]\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    "    _dmat=_dmat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_analysis3(\n",
    "    _rabund=sotu_rabund,\n",
    "    _meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Turnover while Controlling for Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_analysis3(\n",
    "    _rabund=sotu_rabund,\n",
    "    _rabund_ctrl=motu_rabund,\n",
    "    _meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual strain turnover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g__Escherichia coli_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"102506\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"102506\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "_rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "_dmat = _world.unifrac_pdist(discretized=False).loc[_meta.index, _meta.index]\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    "    _dmat=_dmat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s__Eggerthella lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"102544\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta = sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"102544\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "_rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "_dmat = _world.unifrac_pdist(discretized=False).loc[_meta.index, _meta.index]\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    "    _dmat=_dmat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s__Flavonifractor plautii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"100099\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta = sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"102544\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta=sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "_rabund, _meta = lib.pandas_util.align_indexes(_rabund, _meta)\n",
    "\n",
    "_dmat = _world.unifrac_pdist(discretized=False).loc[_meta.index, _meta.index]\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    "    _dmat=_dmat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s__Bacteroides uniformis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"101346\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta = sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_species_id = \"101378\"\n",
    "_world = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{_species_id}/r.proc.gtpro.sfacts-fit.world.nc\",\n",
    "        validate=False,\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={'CF_11': 'CF_15', 'CF_15': 'CF_11'})  # Sample swap\n",
    ")\n",
    "_rabund = _world.community.sel(sample=_world.metagenotype.mean_depth() > 1e-1).to_pandas()\n",
    "_meta = sample[\n",
    "        sample.diet_or_media.isin([\"EEN\", \"PostEEN\"])\n",
    "        & ~sample.collection_date_relative_een_end.isna()\n",
    "    ].assign(depth=0)\n",
    "\n",
    "turnover_analysis3(\n",
    "    _rabund=_rabund,\n",
    "    _meta=_meta,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz2",
   "language": "python",
   "name": "toolz2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
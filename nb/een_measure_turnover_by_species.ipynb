{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "\n",
    "_os.chdir(_os.environ[\"PROJECT_ROOT\"])\n",
    "_os.path.realpath(_os.path.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import chain, product\n",
    "from tempfile import mkstemp\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import sfacts as sf\n",
    "import statsmodels.formula.api as smf\n",
    "import xarray as xr\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lib.plot\n",
    "import lib.thisproject.data\n",
    "from lib.pandas_util import align_indexes, aligned_index, idxwhere, invert_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkage_order(linkage, labels):\n",
    "    return labels[sp.cluster.hierarchy.to_tree(linkage).pre_order(lambda x: x.id)]\n",
    "\n",
    "def label_een_experiment_sample(x):\n",
    "    if x.sample_type == \"human\":\n",
    "        label = f\"[{x.name}] {x.collection_date_relative_een_end} {x.diet_or_media}\"\n",
    "    elif x.sample_type in [\"Fermenter_inoculum\"]:\n",
    "        label = f\"[{x.name}] {x.source_samples} inoc {x.diet_or_media}\"\n",
    "    elif x.sample_type in [\"Fermenter\"]:\n",
    "        # label = f\"[{x.name}] {x.source_samples} frmnt {x.diet_or_media}\"\n",
    "        label = f\"[{x.name}] {x.source_samples} {x.diet_or_media}\"\n",
    "    elif x.sample_type in [\"mouse\"]:\n",
    "        if x.status_mouse_inflamed == 'Inflamed':\n",
    "            # label = f\"[{x.name}] {x.source_samples} \ud83d\udc2d {x.mouse_genotype} {x.diet_or_media} inflam\"\n",
    "            label = f\"[{x.name}] {x.source_samples} {x.diet_or_media} inflam\"\n",
    "        elif x.status_mouse_inflamed == 'not_Inflamed':\n",
    "            # label = f\"[{x.name}] {x.source_samples} \ud83d\udc2d {x.mouse_genotype} {x.diet_or_media} not_inf\"\n",
    "            label = f\"[{x.name}] {x.source_samples} {x.diet_or_media} not_inf\"\n",
    "        else:\n",
    "            raise ValueError(f\"sample type {x.status_mouse_inflamed} not understood\")\n",
    "    else:\n",
    "        raise ValueError(f\"sample type {x.sample_type} not understood\")\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.dpi\"] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_order = [\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"H\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (\n",
    "    pd.read_table(\"meta/een-mgen/sample.tsv\")\n",
    "    .assign(\n",
    "        label=lambda x: x[\n",
    "            [\"collection_date_relative_een_end\", \"diet_or_media\", \"sample_id\"]\n",
    "        ].apply(tuple, axis=1)\n",
    "    )\n",
    "    .set_index(\"sample_id\")\n",
    "    .assign(full_label=lambda d: d.apply(label_een_experiment_sample, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotu_counts = pd.read_table(\n",
    "    \"data/group/een/a.proc.zotu_counts.tsv\", index_col=\"#OTU ID\"\n",
    ").rename_axis(index=\"zotu\", columns=\"sample_id\")\n",
    "rotu_taxonomy = rotu_counts.taxonomy\n",
    "rotu_counts = rotu_counts.drop(columns=[\"taxonomy\"]).T\n",
    "rotu_rabund = rotu_counts.divide(rotu_counts.sum(1), axis=0)\n",
    "\n",
    "sample_rotu_bc_linkage = sp.cluster.hierarchy.linkage(\n",
    "    rotu_rabund, method=\"average\", metric=\"braycurtis\", optimal_ordering=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_depth = (pd.read_table(\n",
    "    \"data/group/een/r.proc.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    "    names=['sample', \"species_id\", 'depth'], index_col=['sample', \"species_id\"],\n",
    "    )\n",
    "    .depth.unstack(fill_value=0)\n",
    "    .rename(columns=str, index=lambda x: \"CF_\" + str(int(x.split(\"_\")[1])))\n",
    "    .rename({'CF_15': 'CF_11', 'CF_11': 'CF_15'})  # Sample swap\n",
    ")\n",
    "motu_rabund = motu_depth.divide(motu_depth.sum(1), axis=0)\n",
    "\n",
    "motu_rabund"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motu_depth = pd.read_table(\n",
    "    \"data/group/een/species/sp-102506/r.proc.gene99_new-v22-agg75.spgc_specgene-ref-t25-p95.species_depth.tsv\",\n",
    ").rename_axis(index=\"species_id\", columns=\"sample_id\")\n",
    "rotu_rabund = rotu_counts.divide(rotu_counts.sum(1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Enrichment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_test(d):\n",
    "    try:\n",
    "        res = sp.stats.wilcoxon(d[\"EEN\"], d[\"PostEEN\"])\n",
    "    except ValueError:\n",
    "        res = (np.nan, np.nan)\n",
    "    log2_ratio = np.log2(d[\"PostEEN\"] / d[\"EEN\"])\n",
    "    return pd.Series(\n",
    "        [log2_ratio.mean(), d[\"EEN\"].mean(), d[\"PostEEN\"].mean(), res[1]],\n",
    "        index=[\"log2_ratio\", \"mean_EEN\", \"mean_PostEEN\", \"pvalue\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motu_enrichment_results = (\n",
    "    motu_rabund.apply(lambda x: x + x.replace({0: np.inf}).min())\n",
    "    .join(sample[[\"subject_id\", \"diet_or_media\"]])\n",
    "    .groupby([\"subject_id\", \"diet_or_media\"])\n",
    "    .mean()\n",
    "    .stack()\n",
    "    .unstack(\"diet_or_media\")[[\"EEN\", \"PostEEN\"]]\n",
    "    .dropna()\n",
    "    .assign(log2_ratio=lambda x: np.log2(x[\"PostEEN\"] / x[\"EEN\"]))\n",
    "    .rename_axis(index=[\"subject_id\", \"motu_id\"])\n",
    "    .groupby(level=\"motu_id\")\n",
    "    .apply(enrichment_test)\n",
    ")\n",
    "motu_enrichment_results.sort_values(\"pvalue\", ascending=True).head(20)\n",
    "# fig, ax = plt.subplots()\n",
    "# print(d.log2_ratio.mean())\n",
    "# print(sp.stats.wilcoxon(d['PostEEN'], d['EEN']))\n",
    "# ax.hist(d.log2_ratio, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strain Time-series"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motu_id = \"100099\"\n",
    "# rotu_id = \"Zotu4\"\n",
    "drop_strains_thresh = 0.5\n",
    "ylinthresh = 1e-4\n",
    "bar_width = 1.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf_fit = (\n",
    "    sf.data.World.load(\n",
    "        f\"data/group/een/species/sp-{motu_id}/r.proc.gtpro.filt-poly05-cvrg05.ss-g10000-block0-seed0.fit-sfacts48-s85-seed0.world.nc\"\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    .drop_low_abundance_strains(0.01)\n",
    "    .rename_coords(strain=str)\n",
    ")\n",
    "print(sf_fit.sizes)\n",
    "mgtp_error = sf.evaluation.metagenotype_error2(sf_fit, discretized=False)[1]\n",
    "entrp_error = sf.evaluation.metagenotype_entropy_error(\n",
    "    sf_fit, discretized=False, p=1, montecarlo_draws=10\n",
    ")[1]\n",
    "comm_entrp = sf_fit.community.entropy().to_series()\n",
    "# high_mgtp_error = mgtp_error >= 0.1\n",
    "# high_entrp_error = entrp_error >= 0.2\n",
    "# high_comm_entrp = comm_entrp >= 1.5\n",
    "\n",
    "position_ss = sf_fit.random_sample(position=min(2000, sf_fit.sizes['position'])).position\n",
    "\n",
    "# Genotype similarity ordered palette:\n",
    "strain_linkage = sf_fit.genotype.linkage(optimal_ordering=True)\n",
    "sample_linkage = sf_fit.metagenotype.linkage(optimal_ordering=True)\n",
    "strain_order = list(\n",
    "    linkage_order(\n",
    "        strain_linkage,\n",
    "        sf_fit.strain.values,\n",
    "    )\n",
    ")\n",
    "strain_order.remove(\"-1\")  # Drop \"other\" strain.\n",
    "strain_palette = lib.plot.construct_ordered_palette(\n",
    "    strain_order,\n",
    "    cm=\"rainbow\",\n",
    ")\n",
    "\n",
    "sample_colors = xr.Dataset(dict(mg_err=mgtp_error, en_err=entrp_error, cen=comm_entrp))\n",
    "\n",
    "sf.plot.plot_metagenotype(\n",
    "    sf_fit.sel(position=position_ss),\n",
    "    scalex=0.4,\n",
    "    col_linkage_func=lambda w: sample_linkage,\n",
    "    col_colors_func=lambda w: sample_colors,\n",
    ")\n",
    "\n",
    "sf.plot.plot_community(\n",
    "    sf_fit,\n",
    "    scalex=0.4,\n",
    "    scaley=0.6,\n",
    "    row_linkage_func=lambda w: strain_linkage,\n",
    "    row_colors=sf_fit.strain.to_series().map(strain_palette),\n",
    "    col_linkage_func=lambda w: sample_linkage,\n",
    "    col_colors_func=lambda w: sample_colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d0 = (\n",
    "    sample.loc[\n",
    "        lambda x: (\n",
    "            True\n",
    "            # x.index.isin(sf_fit.sample.values)\n",
    "            & x.sample_type.isin([\"human\", \"Fermenter\", \"mouse\"])\n",
    "            & x.subject_id.isin([\"A\", \"B\", \"H\"])\n",
    "            # & (x.sample_type == \"Fermenter\")\n",
    "        ),\n",
    "        [\n",
    "            \"subject_id\",\n",
    "            \"collection_date_relative_een_end\",\n",
    "            \"sample_type\",\n",
    "            \"diet_or_media\",\n",
    "            \"mouse_genotype\",\n",
    "            \"source_samples\",\n",
    "            \"status_mouse_inflamed\",\n",
    "            \"full_label\",\n",
    "        ],\n",
    "    ]\n",
    "    .sort_values(\n",
    "        [\n",
    "            \"subject_id\",\n",
    "            \"collection_date_relative_een_end\",\n",
    "            \"sample_type\",\n",
    "            \"diet_or_media\",\n",
    "            \"mouse_genotype\",\n",
    "            \"source_samples\",\n",
    "            \"status_mouse_inflamed\",\n",
    "        ]\n",
    "    )\n",
    "    .assign(\n",
    "        rabund=motu_rabund[motu_id],\n",
    "    )\n",
    "    .dropna(subset=['rabund'])\n",
    ")\n",
    "\n",
    "sample_type_order = [\"human\", \"Fermenter\", \"mouse\"]\n",
    "subject_order = [\"A\", \"B\", \"H\"]\n",
    "\n",
    "\n",
    "_grid_sample_counts = (\n",
    "    d0[[\"subject_id\", \"sample_type\"]]\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    "    .reindex(columns=sample_type_order)\n",
    ")\n",
    "fig, axs = plt.subplots(\n",
    "    *_grid_sample_counts.shape,\n",
    "    figsize=(20, 15),\n",
    "    width_ratios=_grid_sample_counts.max().values,\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(wspace=0.1, hspace=3)\n",
    ")\n",
    "\n",
    "for subject_id, ax_row in zip(subject_order, axs):\n",
    "    d1 = d0[lambda x: (x.subject_id == subject_id)]\n",
    "    strain_frac_sample_list = list(set(d1.index) & set(sf_fit.sample.values))\n",
    "    if len(strain_frac_sample_list) == 0:\n",
    "        print(f\"No strain analysis for {subject_id}.\")\n",
    "        comm = []\n",
    "        _strain_order = []\n",
    "    else:\n",
    "        w = (\n",
    "            sf_fit.sel(sample=strain_frac_sample_list)\n",
    "            .drop_low_abundance_strains(drop_strains_thresh)\n",
    "            .rename_coords(strain=str)\n",
    "        )\n",
    "        _strain_order = [s for s in strain_order if s in w.strain] + [\"-1\"]\n",
    "        comm = w.community.to_pandas()\n",
    "    d2 = d1.join(comm)\n",
    "    for sample_type, ax in zip(sample_type_order, ax_row):\n",
    "        d3 = d2[lambda x: (x.sample_type == sample_type)].assign(xpos=lambda x: np.arange(len(x.index)))\n",
    "        ax.scatter(\"xpos\", \"rabund\", data=d3, color='k', s=10, label='__nolegend__')\n",
    "        # ax.set_aspect(700, adjustable=\"datalim\", anchor=\"NW\")\n",
    "        ax.set_ylim(-1e-3, 1)\n",
    "        ax.set_yscale(\"symlog\", linthresh=1e-4, linscale=0.1)\n",
    "        ax.set_xlim(-0.5, _grid_sample_counts[sample_type].max())\n",
    "        ax.set_xticks(d3.xpos)\n",
    "        ax.set_xticklabels(d3.full_label)\n",
    "        \n",
    "        # Plot stacked barplot\n",
    "        ax1 = ax.twinx()\n",
    "        top_last = 0\n",
    "        for strain in _strain_order:\n",
    "            ax1.bar(\n",
    "                x='xpos',\n",
    "                height=strain,\n",
    "                data=d3,\n",
    "                bottom=top_last,\n",
    "                width=bar_width,\n",
    "                alpha=1.0,\n",
    "                color=strain_palette[strain],\n",
    "                edgecolor=\"k\",\n",
    "                lw=1,\n",
    "                label='__nolegend__',\n",
    "            )\n",
    "            top_last += d3[strain]\n",
    "            ax.scatter([], [], color=strain_palette[strain], label=strain, marker='s', s=80)\n",
    "        ax1.set_yticks([])\n",
    "        # Put strains behind points:\n",
    "        ax.set_zorder(ax1.get_zorder() + 1)  # put ax in front of ax1\n",
    "        ax.patch.set_visible(False)  # hide the 'canvas'\n",
    "        ax1.patch.set_visible(True)  # show the 'canvas'\n",
    "\n",
    "        ax1.set_ylim(0, 1)\n",
    "        lib.plot.rotate_xticklabels(ax=ax)\n",
    "        if sample_type == 'mouse':\n",
    "            ax.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d0 = (\n",
    "    sample.loc[\n",
    "        lambda x: (\n",
    "            True\n",
    "            # x.index.isin(sf_fit.sample.values)\n",
    "            & x.sample_type.isin([\"human\", \"Fermenter\", \"mouse\"])\n",
    "            & x.subject_id.isin([\"A\", \"B\", \"H\"])\n",
    "            # & (x.sample_type == \"Fermenter\")\n",
    "        ),\n",
    "        [\n",
    "            \"subject_id\",\n",
    "            \"collection_date_relative_een_end\",\n",
    "            \"sample_type\",\n",
    "            \"diet_or_media\",\n",
    "            \"mouse_genotype\",\n",
    "            \"source_samples\",\n",
    "            \"status_mouse_inflamed\",\n",
    "            \"full_label\",\n",
    "        ],\n",
    "    ]\n",
    "    .sort_values(\n",
    "        [\n",
    "            \"subject_id\",\n",
    "            \"collection_date_relative_een_end\",\n",
    "            \"sample_type\",\n",
    "            \"diet_or_media\",\n",
    "            \"mouse_genotype\",\n",
    "            \"source_samples\",\n",
    "            \"status_mouse_inflamed\",\n",
    "        ]\n",
    "    )\n",
    "    .assign(\n",
    "        rabund=motu_rabund[motu_id],\n",
    "    )\n",
    "    .dropna(subset=['rabund'])\n",
    ")\n",
    "\n",
    "subject_id = 'H'\n",
    "sample_type = \"human\"\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "d1 = d0[lambda x: (x.subject_id == subject_id)]\n",
    "strain_frac_sample_list = list(set(d1.index) & set(sf_fit.sample.values))\n",
    "if len(strain_frac_sample_list) == 0:\n",
    "    print(f\"No strain analysis for {subject_id}.\")\n",
    "    comm = []\n",
    "    _strain_order = []\n",
    "else:\n",
    "    w = (\n",
    "        sf_fit.sel(sample=strain_frac_sample_list)\n",
    "        # .drop_low_abundance_strains(drop_strains_thresh)\n",
    "        .rename_coords(strain=str)\n",
    "    )\n",
    "    _strain_order = [s for s in strain_order if s in w.strain] + [\"-1\"]\n",
    "    comm = w.community.to_pandas()\n",
    "d2 = d1.join(comm)\n",
    "\n",
    "d3 = d2[lambda x: (x.sample_type == sample_type)].assign(xpos=lambda x: np.arange(len(x.index)))\n",
    "ax.scatter(\"xpos\", \"rabund\", data=d3, color='k', s=10, label='__nolegend__')\n",
    "# ax.set_aspect(700, adjustable=\"datalim\", anchor=\"NW\")\n",
    "ax.set_ylim(-1e-3, 1)\n",
    "ax.set_yscale(\"symlog\", linthresh=1e-4, linscale=0.1)\n",
    "ax.set_xlim(-0.5, _grid_sample_counts[sample_type].max())\n",
    "ax.set_xticks(d3.xpos)\n",
    "ax.set_xticklabels(d3.full_label)\n",
    "\n",
    "# Plot stacked barplot\n",
    "ax1 = ax.twinx()\n",
    "top_last = 0\n",
    "for strain in _strain_order:\n",
    "    ax1.bar(\n",
    "        x='xpos',\n",
    "        height=strain,\n",
    "        data=d3,\n",
    "        bottom=top_last,\n",
    "        width=bar_width,\n",
    "        alpha=1.0,\n",
    "        color=strain_palette[strain],\n",
    "        edgecolor=\"k\",\n",
    "        lw=1,\n",
    "        label='__nolegend__',\n",
    "    )\n",
    "    top_last += d3[strain]\n",
    "    ax.scatter([], [], color=strain_palette[strain], label=strain, marker='s', s=80)\n",
    "ax1.set_yticks([])\n",
    "# Put strains behind points:\n",
    "ax.set_zorder(ax1.get_zorder() + 1)  # put ax in front of ax1\n",
    "ax.patch.set_visible(False)  # hide the 'canvas'\n",
    "ax1.patch.set_visible(True)  # show the 'canvas'\n",
    "\n",
    "ax1.set_ylim(0, 1)\n",
    "lib.plot.rotate_xticklabels(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_classifier(sample_typeA, sample_typeB):\n",
    "    return \":\".join(sorted(set([sample_typeA, sample_typeB])))\n",
    "\n",
    "\n",
    "def construct_turnover_analysis_data(\n",
    "    dmat,\n",
    "    meta,\n",
    "    sample_type_var,\n",
    "    stratum_var=None,\n",
    "    time_var=None,\n",
    "):\n",
    "    var_list = []\n",
    "    for var in [sample_type_var, stratum_var, time_var]:\n",
    "        if var is not None:\n",
    "            var_list.append(var)\n",
    "    meta = meta.reindex(dmat.index)[var_list].dropna()\n",
    "    dmat = dmat.loc[meta.index, meta.index]\n",
    "    data = []\n",
    "    for (i, idxA), (j, idxB) in product(enumerate(meta.index), repeat=2):\n",
    "        data.append(\n",
    "            [\n",
    "                idxA,\n",
    "                idxB,\n",
    "                meta.loc[idxA, stratum_var],\n",
    "                meta.loc[idxB, stratum_var],\n",
    "                meta.loc[idxA, time_var],\n",
    "                meta.loc[idxB, time_var],\n",
    "                meta.loc[idxA, sample_type_var],\n",
    "                meta.loc[idxB, sample_type_var],\n",
    "                dmat.loc[idxA, idxB],\n",
    "            ]\n",
    "        )\n",
    "    data = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"sampleA\",\n",
    "            \"sampleB\",\n",
    "            \"stratumA\",\n",
    "            \"stratumB\",\n",
    "            \"timeA\",\n",
    "            \"timeB\",\n",
    "            \"sample_typeA\",\n",
    "            \"sample_typeB\",\n",
    "            \"diss\",\n",
    "        ],\n",
    "    ).assign(\n",
    "        pair_type=lambda x: x.apply(\n",
    "            lambda y: pair_classifier(y.sample_typeA, y.sample_typeB), axis=1\n",
    "        ),\n",
    "        time_delta=lambda x: np.abs(x.timeB - x.timeA),\n",
    "    )[\n",
    "        lambda x: (x.stratumA == x.stratumB) & (x.sampleA < x.sampleB)\n",
    "    ].assign(stratum=lambda x: x.stratumA)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = '101378'\n",
    "inpath = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "sf_fit = (\n",
    "    sf.data.World.load(\n",
    "        inpath\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "    # .drop_low_abundance_strains(0.01)\n",
    "    # .rename_coords(strain=str)\n",
    ")\n",
    "\n",
    "comm = sf_fit.community.to_pandas()\n",
    "comm_bc_pdist = pd.DataFrame(squareform(pdist(comm, metric='braycurtis')), index=comm.index, columns=comm.index)\n",
    "\n",
    "turnover_data = construct_turnover_analysis_data(\n",
    "    comm_bc_pdist,\n",
    "    meta=sample[lambda x: x.diet_or_media.isin(['EEN', 'PostEEN'])],\n",
    "    sample_type_var=\"diet_or_media\",\n",
    "    stratum_var=\"subject_id\",\n",
    "    time_var=\"collection_date_relative_een_end\",\n",
    ")\n",
    "\n",
    "formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "fit = smf.ols(formula, data=turnover_data).fit()\n",
    "\n",
    "coef_list = []\n",
    "for coef in ['pair_type[EEN]', 'pair_type[PostEEN]', 'pair_type[EEN:PostEEN]']:\n",
    "    if coef in fit.params:\n",
    "        coef_list.append(fit.params[coef])\n",
    "    else:\n",
    "        coef_list.append(np.nan)        \n",
    "\n",
    "for pair_type, d1 in turnover_data.groupby('pair_type'):\n",
    "    plt.scatter('time_delta', 'diss', data=d1, label=pair_type)\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "fit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for species_id in motu_enrichment_results.index:\n",
    "    inpath = f\"data/group/een/species/sp-{species_id}/r.proc.gtpro.sfacts-fit.world.nc\"\n",
    "    if not os.path.exists(inpath):\n",
    "        print(f\"No sfacts fit for {species_id}.\")\n",
    "        continue\n",
    "    sf_fit = (\n",
    "        sf.data.World.load(\n",
    "            inpath\n",
    "        )\n",
    "        .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "        .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    "        # .drop_low_abundance_strains(0.01)\n",
    "        # .rename_coords(strain=str)\n",
    "    )\n",
    "    \n",
    "    comm = sf_fit.community.to_pandas()\n",
    "    comm_bc_pdist = pd.DataFrame(squareform(pdist(comm, metric='braycurtis')), index=comm.index, columns=comm.index)\n",
    "    \n",
    "    turnover_data = construct_turnover_analysis_data(\n",
    "        comm_bc_pdist,\n",
    "        meta=sample[lambda x: x.diet_or_media.isin(['EEN', 'PostEEN'])],\n",
    "        sample_type_var=\"diet_or_media\",\n",
    "        stratum_var=\"subject_id\",\n",
    "        time_var=\"collection_date_relative_een_end\",\n",
    "    )\n",
    "    if turnover_data.empty:\n",
    "        print(f\"No data for {species_id}.\")\n",
    "        continue\n",
    "    \n",
    "    formula = \"diss ~ 0 + pair_type + cr(time_delta, 4) + C(stratum, Sum)\"\n",
    "    try:\n",
    "        fit = smf.ols(formula, data=turnover_data).fit()\n",
    "    except ZeroDivisionError:\n",
    "        print(f\"OLS failed for {species_id}.\")\n",
    "        continue\n",
    "    except ValueError:\n",
    "        print(f\"OLS failed for {species_id}.\")\n",
    "        continue\n",
    "\n",
    "    coef_list = []\n",
    "    for coef in ['pair_type[EEN]', 'pair_type[PostEEN]', 'pair_type[EEN:PostEEN]']:\n",
    "        if coef in fit.params:\n",
    "            coef_list.append(fit.params[coef])\n",
    "        else:\n",
    "            coef_list.append(np.nan)        \n",
    "    results.append((species_id, *coef_list, turnover_data.shape[0]))\n",
    "    \n",
    "    # for pair_type, d1 in turnover_data.groupby('pair_type'):\n",
    "    #     plt.scatter('time_delta', 'diss', data=d1, label=pair_type)\n",
    "    # plt.xscale('log')\n",
    "    # plt.legend()\n",
    "    # fit.summary()\n",
    "results = pd.DataFrame(results, columns=['motu_id', 'EEN', 'PostEEN', 'Transition', 'num_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = motu_enrichment_results.join(results.set_index('motu_id')).assign(\n",
    "    relative_transition=lambda x: x['Transition'] - x['EEN'],\n",
    "    signif_enrich=lambda w: w.pvalue < 0.05,\n",
    ").dropna(subset=['relative_transition'])\n",
    "\n",
    "plt.scatter('mean_EEN', 'relative_transition', data=d, c='signif_enrich')\n",
    "plt.yscale('symlog', linthresh=1e-2)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[lambda x: (x.mean_EEN > 1e-3) & (x.relative_transition > 1e-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[lambda x: (x.mean_EEN > 1e-3)].sort_values('relative_transition', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.spearmanr(d['log2_ratio'], d['relative_transition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values('relative_transition', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_fit = (\n",
    "    sf.data.World.load(\n",
    "        inpath\n",
    "    )\n",
    "    .rename_coords(sample=lambda s: \"CF_{}\".format(int(s.split(\"_\")[1])))\n",
    "    .rename_coords(sample={\"CF_11\": \"CF_15\", \"CF_15\": \"CF_11\"})\n",
    ")\n",
    "\n",
    "subject_id = 'A'\n",
    "d = sample[lambda x: x.subject_id == subject_id]\n",
    "\n",
    "\n",
    "else:\n",
    "        w = (\n",
    "            sf_fit.sel(sample=strain_frac_sample_list)\n",
    "            .drop_low_abundance_strains(drop_strains_thresh)\n",
    "            .rename_coords(strain=str)\n",
    "        )\n",
    "        _strain_order = [s for s in strain_order if s in w.strain] + [\"-1\"]\n",
    "        comm = w.community.to_pandas()\n",
    "    d2 = d1.join(comm)\n",
    "    for sample_type, ax in zip(sample_type_order, ax_row):\n",
    "        d3 = d2[lambda x: (x.sample_type == sample_type)].assign(xpos=lambda x: np.arange(len(x.index)))\n",
    "        ax.scatter(\"xpos\", \"rabund\", data=d3, color='k', s=10, label='__nolegend__')\n",
    "        # ax.set_aspect(700, adjustable=\"datalim\", anchor=\"NW\")\n",
    "        ax.set_ylim(-1e-3, 1)\n",
    "        ax.set_yscale(\"symlog\", linthresh=1e-4, linscale=0.1)\n",
    "        ax.set_xlim(-0.5, _grid_sample_counts[sample_type].max())\n",
    "        ax.set_xticks(d3.xpos)\n",
    "        ax.set_xticklabels(d3.full_label)\n",
    "        \n",
    "        # Plot stacked barplot\n",
    "        ax1 = ax.twinx()\n",
    "        top_last = 0\n",
    "        for strain in _strain_order:\n",
    "            ax1.bar(\n",
    "                x='xpos',\n",
    "                height=strain,\n",
    "                data=d3,\n",
    "                bottom=top_last,\n",
    "                width=bar_width,\n",
    "                alpha=1.0,\n",
    "                color=strain_palette[strain],\n",
    "                edgecolor=\"k\",\n",
    "                lw=1,\n",
    "                label='__nolegend__',\n",
    "            )\n",
    "            top_last += d3[strain]\n",
    "            ax.scatter([], [], color=strain_palette[strain], label=strain, marker='s', s=80)\n",
    "        ax1.set_yticks([])\n",
    "        # Put strains behind points:\n",
    "        ax.set_zorder(ax1.get_zorder() + 1)  # put ax in front of ax1\n",
    "        ax.patch.set_visible(False)  # hide the 'canvas'\n",
    "        ax1.patch.set_visible(True)  # show the 'canvas'\n",
    "\n",
    "        ax1.set_ylim(0, 1)\n",
    "        lib.plot.rotate_xticklabels(ax=ax)\n",
    "        if sample_type == 'mouse':\n",
    "            ax.legend(bbox_to_anchor=(1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolz2",
   "language": "python",
   "name": "toolz2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}